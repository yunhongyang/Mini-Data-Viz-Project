{
    "search_metadata": {
        "id": "643dbb162fe3026efeedbf03",
        "status": "Success",
        "json_endpoint": "https://serpapi.com/searches/0568abb423fe8dd6/643dbb162fe3026efeedbf03.json",
        "created_at": "2023-04-17 21:33:10 UTC",
        "processed_at": "2023-04-17 21:33:10 UTC",
        "google_jobs_url": "https://www.google.com/search?q=big+data+and+cloud+computing&ibp=htl;jobs&uule=w+CAIQICINV2FzaGluZ3RvbiBEQw&hl=en&gl=us&start=0",
        "raw_html_file": "https://serpapi.com/searches/0568abb423fe8dd6/643dbb162fe3026efeedbf03.html",
        "total_time_taken": 2.99
    },
    "search_parameters": {
        "q": "big data and cloud computing",
        "engine": "google_jobs",
        "uule": "w+CAIQICINV2FzaGluZ3RvbiBEQw",
        "google_domain": "google.com",
        "hl": "en",
        "gl": "us",
        "start": 0
    },
    "jobs_results": [
        {
            "title": "Cloud Consultant, Big Data and Analytics, Google Cloud",
            "company_name": "Google",
            "location": "  Reston, VA   ",
            "via": "via Karkidi",
            "description": "Minimum qualifications:\n\u2022 Bachelor\u2019s degree in Computer Science, Engineering, technical field or equivalent practical experience.\n\u2022 3 years of experience project managing and delivering technical solutions...\n\u2022 Experience in systems design and architecting or communicating systems interactions, including data flows, interfaces, APIs, and methods.\n\u2022 Experience with architecting, developing, or maintaining technical solutions in virtualized environments.\n\nPreferred qualifications:\n\u2022 MBA or Master's degree in Computer Science or an engineering field.\n\u2022 Cloud certification.\n\u2022 7 years of experience demonstrating technical client service.\n\u2022 Experience with reading software code in one or more languages such as Java, JavaScript, Python.\n\u2022 Experience designing and deploying large scale distributed data processing systems with one or more technologies such as Oracle, SQL Server, MySQL, PostgreSQL, MongoDB, Cassandra, Redis, Hadoop, Spark, HBase, Vertica, Netezza, Teradata, Tableau, or MicroStrategy.\n\u2022 Excellent communication, presentation, and problem solving skills.\n\nAbout the job\n\nAs a Big Data and Analytics Cloud Consultant, you will work directly with Google\u2019s customers on critical projects to help them transform their businesses. You will provide management, consulting, and technical aptitude to customer engagements while working with client executives and key technical leaders to deploy solutions via Google Cloud Platform.\n\nYou will also work closely with key Google partners currently servicing top accounts to manage programs, deliver consulting services, and provide technical guidance and best practice expertise. You will also travel approximately 30% of the time for client engagements.\n\nGoogle Cloud provides organizations with leading infrastructure, platform capabilities and industry solutions. We deliver enterprise-grade cloud solutions that leverage Google\u2019s cutting-edge technology to help companies operate more efficiently and adapt to changing needs, giving customers a foundation for the future. Customers in more than 150 countries turn to Google Cloud as their trusted partner to solve their most critical business problems.\n\nResponsibilities\n\u2022 Work with customer technical leads, client executives, and partners to manage and deliver successful implementations of cloud solutions, becoming a trusted advisor to decision-makers throughout the engagement.\n\u2022 Work with internal specialists, product, and engineering teams to package best practices and lessons learned into thought leadership, methodologies, and published assets.\n\u2022 Interact with sales, partners, and customer technical stakeholders to manage project scope, priorities, deliverables, risks/issues, and timelines for successful client outcomes.\n\u2022 Advocate for customer needs in order to overcome adoption blockers and drive new feature development based on your field experience.\n\u2022 Propose solution architectures, manage the deployment of cloud based big data, analytics solutions according to customer requirements, and implementation best practices",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Bachelor\u2019s degree in Computer Science, Engineering, technical field or equivalent practical experience",
                        "3 years of experience project managing and delivering technical solutions",
                        "Experience in systems design and architecting or communicating systems interactions, including data flows, interfaces, APIs, and methods",
                        "Experience with architecting, developing, or maintaining technical solutions in virtualized environments"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "As a Big Data and Analytics Cloud Consultant, you will work directly with Google\u2019s customers on critical projects to help them transform their businesses",
                        "You will provide management, consulting, and technical aptitude to customer engagements while working with client executives and key technical leaders to deploy solutions via Google Cloud Platform",
                        "You will also travel approximately 30% of the time for client engagements",
                        "Work with customer technical leads, client executives, and partners to manage and deliver successful implementations of cloud solutions, becoming a trusted advisor to decision-makers throughout the engagement",
                        "Work with internal specialists, product, and engineering teams to package best practices and lessons learned into thought leadership, methodologies, and published assets",
                        "Interact with sales, partners, and customer technical stakeholders to manage project scope, priorities, deliverables, risks/issues, and timelines for successful client outcomes",
                        "Advocate for customer needs in order to overcome adoption blockers and drive new feature development based on your field experience",
                        "Propose solution architectures, manage the deployment of cloud based big data, analytics solutions according to customer requirements, and implementation best practices"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.google.com/",
                    "text": "google.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Google&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCM0J",
                    "text": "See web results for Google"
                }
            ],
            "extensions": [
                "120K\u2013190K a year",
                "Full-time"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time",
                "salary": "120K\u2013190K a year"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBDb25zdWx0YW50LCBCaWcgRGF0YSBhbmQgQW5hbHl0aWNzLCBHb29nbGUgQ2xvdWQiLCJodGlkb2NpZCI6IlBUTTNwX3hiRXRVQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVjJGemFHbHVaM1J2YmlCRVF3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVxRUNDdUlCUVVWek4ycE9VV1IyUjE4MmNYRTBSRVZQTTJOWVZraG9WVFJWVm14UVdrZDZXbXhrYkZjMU5saFVXV2xzVTI5eFdreHZhM1pvYzBWdWRHd3dPVzFaVWpCWllqSllhalowZFdGS1NFeEplVEZ2ZG5Oc1ZXUmpTVkZ4TXpCVGNtcG1PVlkwT0ZSbVRrNW5TbmxtWDAxWVJqTmZlRE41VldsYVV6SlJlbU5PYzJoZmFtTlJXVWhZV210WVYzUTRUVXcwTXpNd1NFMUtkMDlrU214cGExOXpabGhCY1ZkZk1VMUNOakJJTm05SFJsOUxhekoxVEZsaVJtUmlMV05wYUROYVdWaHVjekkzZFV0MU1HbEZaREJSUmxZMWJuRTRVMHBMY1Zsdk1tMXplRFZKZHhJV1IweHpPVnBPTlRaclpVaGhkV2RmUkdkeU4yOUJVUm9pUVU4dE1ISnNOVVV3T1Vob1pFSnpZbGx1VlhkQlpGSnNRMjR4UkcxWVNFODVadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgb24gS2Fya2lkaSIsImxpbmsiOiJodHRwczovL3d3dy5rYXJraWRpLmNvbS9qb2ItZGV0YWlscy81MDA3LWNsb3VkLWNvbnN1bHRhbnQtYmlnLWRhdGEtYW5kLWFuYWx5dGljcy1nb29nbGUtY2xvdWQtam9iP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Big Data Architect",
            "company_name": "Johnson Technology Systems Inc.",
            "location": "  Washington, DC   ",
            "via": "via Ladders",
            "description": "We are hiring for Big Data Architect candidates to support our Federal project.\nCompany Name: - JTSi (Johnson Technology Systems, Inc.)\nRole: Big Data Architect...\nLocation: Remote\nClient: Federal\nVisa Status: US Citizen\nClearance: Active Clearance (Open for Clearable Candidates)\nJob Description :\n\u00b7 A Big Data Architect is responsible for designing and implementing large-scale Big Data solutions that can process, store, and analyze vast amounts of data in real-time. A job description for a Big Data Architect may include the following responsibilities:\n\u00b7 Design and implement Big Data architectures, frameworks, and platforms that can process, store, and analyze large volumes of data from various sources, such as social media, sensors, and transactional systems.\n\u00b7 Develop data pipelines and ETL workflows that can transform and integrate data from multiple sources into a unified data lake or warehouse.\n\u00b7 Evaluate, select, and integrate Big Data technologies, such as Hadoop, Spark, and Flink, to optimize performance and scalability, including loading from disparate data sets, preprocessing using Hive and Pig\n\u00b7 Develop and deploy machine learning models and algorithms that can extract insights and patterns from Big Data.\n\u00b7 Design and implement data governance and security controls to ensure data quality, accuracy, privacy, and compliance.\n\u00b7 Collaborate with cross-functional teams, such as data scientists, data engineers, and business analysts, to understand their requirements and provide solutions that meet their needs.\n\u00b7 Develop and maintain data models and schema designs that optimize performance and meet business requirements.\n\u00b7 Monitor and tune performance of Big Data systems, including capacity planning and resource optimization.\n\u00b7 Stay up-to-date with emerging trends and best practices in Big Data technologies, such as cloud computing, serverless computing, and edge computing.\n\u00b7 Develop and maintain Big Data standards and guidelines for development, testing, deployment, and maintenance.\nRequirements for a Big Data Architect position:\n\u00b7 Minimum 8-12 years of experience in Data Modeling in Data Warehouse Environment\n\u00b7 U.S Citizens\n\u00b7 Demonstrated experience in various Big data architectures like Lambda / kappa with usage of automation / scheduling tool like Oozie or Cronacle or any other technologies\n\u00b7 Strong understanding of Big Data architectures, frameworks, and platforms, such as Hadoop, Spark, Flink, Cassandra, and Kafka.\n\u00b7 Proven experience in designing and implementing large-scale Big Data solutions for enterprise customers.\n\u00b7 Expertise in one or more programming languages, such as Java, Python, or Scala.\n\u00b7 In-depth knowledge of distributed computing and parallel processing concepts, such as MapReduce, YARN, and Spark RDD.\n\u00b7 Experience in data modeling and schema design for Big Data, including partitioning, clustering, and indexing strategies.\n\u00b7 Familiarity with Big Data monitoring tools, such as Ganglia, Nagios, and Ambari.\n\u00b7 Familiarity with Big Data frameworks and libraries, such as HDFS, Hive, Pig, and MahoutYAR\n\u00b7 Understanding of machine learning concepts and algorithms, such as regression, classification, clustering, and deep learning.\n\u00b7 Experience with cloud computing platforms, such as AWS, GCP, or Azure.\n\u00b7 Knowledge of data governance and security best practices, such as GDPR, HIPAA, and PCI DSS.\n\u00b7 Excellent communication, collaboration, leadership, and problem-solving skills.\nIf you are available, interested, planning to make a change, or know of a friend who might have the required qualifications and interest, please call me ASAP on 571 - 406 - 2272 / If you do respond via e-mail ( jinson.jose (at) jtsusa.com) please include a daytime phone number so I can reach you. In considering candidates, time is of the essence, so please respond ASAP with your updated resume.\nEstablished in 2003, JTSi is a Professional IT & Engineering Services provider with years of documented experience in the Information Technology and Engineering services field. JTSi has a proven track record for successfully delivering mission critical Professional services to the Government and the industry. JTSi SAP team delivers solutions to its clients by clearly understanding their core business problems. We deliver quality services at equitable rates and focus on constant improvement in all areas of our operation, austerely complying to the customer\u2019s desire. We view our-selves more as a business partner than a mere provider of consulting services. At JTSi \u201ccustomer is always first\u201d and partnering is our means to customer satisfaction. We do what we say",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum 8-12 years of experience in Data Modeling in Data Warehouse Environment",
                        "U.S Citizens",
                        "Demonstrated experience in various Big data architectures like Lambda / kappa with usage of automation / scheduling tool like Oozie or Cronacle or any other technologies",
                        "Strong understanding of Big Data architectures, frameworks, and platforms, such as Hadoop, Spark, Flink, Cassandra, and Kafka",
                        "Proven experience in designing and implementing large-scale Big Data solutions for enterprise customers",
                        "Expertise in one or more programming languages, such as Java, Python, or Scala",
                        "In-depth knowledge of distributed computing and parallel processing concepts, such as MapReduce, YARN, and Spark RDD",
                        "Experience in data modeling and schema design for Big Data, including partitioning, clustering, and indexing strategies",
                        "Familiarity with Big Data monitoring tools, such as Ganglia, Nagios, and Ambari",
                        "Familiarity with Big Data frameworks and libraries, such as HDFS, Hive, Pig, and MahoutYAR",
                        "Understanding of machine learning concepts and algorithms, such as regression, classification, clustering, and deep learning",
                        "Experience with cloud computing platforms, such as AWS, GCP, or Azure",
                        "Knowledge of data governance and security best practices, such as GDPR, HIPAA, and PCI DSS",
                        "Excellent communication, collaboration, leadership, and problem-solving skills",
                        "If you are available, interested, planning to make a change, or know of a friend who might have the required qualifications and interest, please call me ASAP on 571 - 406 - 2272 / If you do respond via e-mail ( jinson.jose (at) jtsusa.com) please include a daytime phone number so I can reach you"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "A Big Data Architect is responsible for designing and implementing large-scale Big Data solutions that can process, store, and analyze vast amounts of data in real-time",
                        "Design and implement Big Data architectures, frameworks, and platforms that can process, store, and analyze large volumes of data from various sources, such as social media, sensors, and transactional systems",
                        "Develop data pipelines and ETL workflows that can transform and integrate data from multiple sources into a unified data lake or warehouse",
                        "Evaluate, select, and integrate Big Data technologies, such as Hadoop, Spark, and Flink, to optimize performance and scalability, including loading from disparate data sets, preprocessing using Hive and Pig",
                        "Develop and deploy machine learning models and algorithms that can extract insights and patterns from Big Data",
                        "Design and implement data governance and security controls to ensure data quality, accuracy, privacy, and compliance",
                        "Collaborate with cross-functional teams, such as data scientists, data engineers, and business analysts, to understand their requirements and provide solutions that meet their needs",
                        "Develop and maintain data models and schema designs that optimize performance and meet business requirements",
                        "Monitor and tune performance of Big Data systems, including capacity planning and resource optimization",
                        "Stay up-to-date with emerging trends and best practices in Big Data technologies, such as cloud computing, serverless computing, and edge computing",
                        "Develop and maintain Big Data standards and guidelines for development, testing, deployment, and maintenance"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.jtsusa.com/",
                    "text": "jtsusa.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Johnson+Technology+Systems+Inc.&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCJIK",
                    "text": "See web results for Johnson Technology Systems Inc."
                }
            ],
            "extensions": [
                "4 days ago",
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "posted_at": "4 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBBcmNoaXRlY3QiLCJodGlkb2NpZCI6InJBU1BYUFdkNnpnQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVjJGemFHbHVaM1J2YmlCRVF3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVxRUNDdUlCUVVWek4ycE9VMHhPVVRSUWNWaEVhMFJSV2pGaVNsRjJRbEpGYWtrMmJEVTJZa1J3VVVjdFVFaFpVRkZqT0hjelRUTnllRTFrV2twdlQzTm1UVmhETmpObFpEUlVSSGxFWWpoaFYyZDZVVWN6TW5kVWEySmxiMHR3WjBkMlpGOXRXbVpxVmw5WGMyZDROVEZ1WDJkM2VETkhPSEprZDBGeGQzcDRaMngyWjNaVVpXWkthMWd0VVZCVFNFSlpaV0ppVmxwNGVtWlVNbGs0Vm5Ga2JGQjBVRlo0UnpOa01tZFhNMEZJVFd4WmJFa3RhbkJMYms4NVZETTJSWFF5VkcxaGVuTlFWa1pEVFc5R1lrOVpYMkkxYkV4UlRqSkRXSGhQYVRWUFZYUmZPRWxTVVJJV1IweHpPVnBPTlRaclpVaGhkV2RmUkdkeU4yOUJVUm9pUVU4dE1ISnNOVXMyTlhsWE1XNWhORzlyZVRGTFpWcFFSSHBJVkVoRmJFdFhkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gTGFkZGVycyIsImxpbmsiOiJodHRwczovL3d3dy50aGVsYWRkZXJzLmNvbS9qb2ItbGlzdGluZy9iaWctZGF0YS1hcmNoaXRlY3Qtam9obnNvbi10ZWNobm9sb2d5LXN5c3RlbXMtaW5jLXdhc2hpbmd0b24tZGlzdHJpY3Qtb2YtY29sdW1iaWEtX3YyXy0xMS0yMzkyODA2MjUyLmh0bWw/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Data Architect",
            "company_name": "Applied Information Sciences",
            "location": "  Reston, VA   ",
            "via": "via AIS Careers - Applied Information Sciences",
            "description": "As a Data Architect, you will use cutting-edge cloud and data technologies to help global brands and federal agencies solve challenging problems through innovative technology solutions. Work on exciting projects, future-proof your skills, and grow into your dream job alongside some of the industry's most talented, knowledgeable, and dedicated technologists.\n\nWhat You'll Be Doing...\n\u2022 Work in a team with other smart AIS employees and use cutting-edge technologies to solve challenging enterprise problems.\n\u2022 Design data platform solutions using Azure data services such as Data Factory, Azure Event Hub, Azure Synapse Analytics, and Azure Databricks.\n\u2022 Design scalable data processing and analytics solutions, including Big data storage for various data types and large-scale data processing using Databricks.\n\u2022 Apply your skills in Azure Cognitive Services, Azure P,aaS, and Machine Learning services.\n\u2022 Use experience working with Azure Data & Storage, Azure Analytics & Azure IoT tools, and the traditional Microsoft BI Stack.\n\u2022 Provide mentorship to more junior consultants.\n\nLocation and Travel Details\n\nThis is a remote position with occasional travel (if needed).\n\nProfile of Success\n\u2022 Minimum ten years of relational data background.\n\u2022 Minimum five years of data architecture experience.\n\u2022 Expert with Azure cloud computing, including big data technologies.\n\u2022 Proven experience developing Big Data solutions in the Azure space\n\u2022 Extensive experience with Azure Data services (Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Data Lake Analytics, HDInsight, Machine Learning, and Stream Analytics).\n\u2022 Expert in both traditional and modern data architecture and processing concepts, including relational databases, Data warehousing, big data, NoSQL, and business analytics.\n\u2022 Hands-on experience implementing Big Data solutions using Microsoft Data Platform and Azure Data Services.\n\u2022 Proven ability to work in a client-facing role, understand requirements and envision solutions.\n\nDesirable Skills\n\u2022 Experience with Azure cloud computing, including big data technologies such as Azure Databricks cluster management.\n\u2022 Background with Data Science tools such as R, Python, and SAS is a plus.\n\u2022 Experience with visualization tools such as Power BI or Tableau.\n\u2022 Desire to obtain or utilize relevant technical certifications as part of continuous professional growth.\n\nAbout AIS\n\nAIS, Dedicated to Our People\n\nAIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it.\n\nIt's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).\n\nOur employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.\n\nWe hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.\n\nWe Invest in Individuals Committed to Innovation\n\nAIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals.\n\nWe are looking for:\n\u2022 Smart people with a passion for technology\n\u2022 Strong technical capabilities with a consultancy mindset\n\u2022 Close involvement with local technical communities\n\u2022 A willingness to think outside of the box to provide innovative solutions to clients\n\u2022 Ability to solve challenging technical business problems\n\u2022 Self-directed professionals\n\nOur Core Values\n\u2022 Client Success\n\u2022 Continued Learning and Technical Excellence\n\u2022 Strong Client Relationships\n\u2022 Citizenship and Community\n\nEEO Statement\n\nApplied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status, or any other basis covered by law. Employment decisions are based solely on qualifications, merit, and business need",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum ten years of relational data background",
                        "Minimum five years of data architecture experience",
                        "Proven experience developing Big Data solutions in the Azure space",
                        "Extensive experience with Azure Data services (Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Data Lake Analytics, HDInsight, Machine Learning, and Stream Analytics)",
                        "Expert in both traditional and modern data architecture and processing concepts, including relational databases, Data warehousing, big data, NoSQL, and business analytics",
                        "Hands-on experience implementing Big Data solutions using Microsoft Data Platform and Azure Data Services",
                        "Proven ability to work in a client-facing role, understand requirements and envision solutions",
                        "Experience with Azure cloud computing, including big data technologies such as Azure Databricks cluster management",
                        "Experience with visualization tools such as Power BI or Tableau",
                        "Desire to obtain or utilize relevant technical certifications as part of continuous professional growth",
                        "Smart people with a passion for technology",
                        "Strong technical capabilities with a consultancy mindset",
                        "Close involvement with local technical communities",
                        "A willingness to think outside of the box to provide innovative solutions to clients",
                        "Ability to solve challenging technical business problems",
                        "Continued Learning and Technical Excellence"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Work in a team with other smart AIS employees and use cutting-edge technologies to solve challenging enterprise problems",
                        "Design data platform solutions using Azure data services such as Data Factory, Azure Event Hub, Azure Synapse Analytics, and Azure Databricks",
                        "Design scalable data processing and analytics solutions, including Big data storage for various data types and large-scale data processing using Databricks",
                        "Apply your skills in Azure Cognitive Services, Azure P,aaS, and Machine Learning services",
                        "Use experience working with Azure Data & Storage, Azure Analytics & Azure IoT tools, and the traditional Microsoft BI Stack",
                        "Provide mentorship to more junior consultants",
                        "This is a remote position with occasional travel (if needed)"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Applied+Information+Sciences&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCNYK",
                    "text": "See web results for Applied Information Sciences"
                }
            ],
            "extensions": [
                "5 days ago",
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "posted_at": "5 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJEYXRhIEFyY2hpdGVjdCIsImh0aWRvY2lkIjoiMTg0WTVMZmFfUEFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WMkZ6YUdsdVozUnZiaUJFUXciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXZZQkNyY0JRVVZ6TjJwT1VWOW5abHB0VHpKTFNqWlhiR1JxUVZsemFVb3plRmxmWkdWNVFUTk9kVEIwT0c0dFdYWlNhbFJaUlZCalFXaEdWWFpPV0UxR2RXVndSWGxQTVY5YVZVOXZlUzFzVWtSVVZuQnhTVGN6YW01ekxVVjZMVzVxUW1KRVVFdzJTMlJMTW1SQmRsZGFTakk0WVZKV1J6Tm5kM28zY1ZCeE5GQmZkbWRMYVhJemVFbHNZMHhsYURsRmR6SnBkR2gzU1VoaldVUndiV1ZZUmtKQ1QyZEVUMkV4YXpkcE1WVkZla3h6ZFZsc1MxVXdNRmRqRWhaSFRITTVXazQxTm10bFNHRjFaMTlFWjNJM2IwRlJHaUpCVHkwd2NtdzFjRmw2TFdNNFdrZzJZMDVNV25adFIwYzVOMHR3T0hweVJVcDMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY181IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IGRpcmVjdGx5IG9uIEFJUyBDYXJlZXJzIC0gQXBwbGllZCBJbmZvcm1hdGlvbiBTY2llbmNlcyIsImxpbmsiOiJodHRwczovL2NhcmVlcnMuYWlzLmNvbS9qb2JzLzI5MTE/bGFuZz1lbi11c1x1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Senior Cloud Solutions Architect Secret Clearance",
            "company_name": "inforeliance",
            "location": "  Washington, DC   ",
            "via": "via WayUp",
            "description": "InfoReliance is hiring!!!\n\nSenior Cloud Solutions Architect (Active Secret Clearance...\n\nLocation: Washington, DC Metro Area\n\nRequirements: US Citizenship & Minimum Secret Clearance\n\nIn order to meet the evolving needs of Federal Government, InfoReliance, an IT Consulting company founded in 2000, invested early to develop advanced analytics capabilities in Cloud Computing to remain competitive and has the expertise to help our customers achieve their goals and meet new Cloud-First mandates. Today, we stand out as a Cloud Leader.\n\nInfoReliance is an AWS Premier Partner, AWS Managed Service Provider, and AWS Approved Reseller. We are also a certified Microsoft Cloud Deployment Partner and regularly team with MCS to offer customers total confidence in migration to Office 365. InfoReliance is also member of the Microsoft Azure Circle partner program, able to assist customers in adopting IaaS and PaaS cloud solutions. Additionally, InfoReliance is a Google Partner.\n\nWE NOW HAVE AN EXCITING OPPORTUNITY FOR A SENIOR CLOUD SOLUTIONS ARCHITECT-SUBJECT MATTER EXPERT TO JOIN OUR TEAM\n\u2022 Responsible for collaborating on and setting cloud vision; providing thought leadership in cloud infrastructure and cloud services architecture to meet client's operational objectives for cloud solutions.\n\u2022 Consulting with our clients as a cloud technology evangelist around Cloud technologies including IaaS, SaaS, PaaS, Public/Hybrid/Community Cloud Service Provider offerings to develop advanced analytics solutions to solve real-world problems.\n\u2022 Designing technical architecture for cloud analytics solutions that meet customer needs for scalability, reliability and performance.\n\u2022 Identifying new cloud technologies and platforms to help solve technical challenges or limitations in the existing infrastructure.\n\u2022 The Senior Cloud Solution Architect is responsible, with our established team of SMEs, change managers, integration engineers, system engineers and business analysts, for discovery and assessment of the current environment, proposing architectures, and implementing solutions for our client and its sub-agencies to consume services from the cloud.\n\u2022 This role will serve as an advanced analytics solution architect providing strategic and technical leadership for client teams migrating, developing, or enriching applications in the cloud.\n\u2022 The Senior Cloud Solution Architect is responsible for supporting multiple customers to evaluate customers\u2019 current and anticipated needs, develop innovative solutions, support technical proposals, develop architectures, and evaluate cloud implementations according to industry best practices and standards.\n\nEssential Responsibilities\n\u2022 Provide thought and technical design leadership to cloud analytics solutions using cloud native and third party software.\n\u2022 Serve as a technical SME for big data, analytics, cloud services, providers, and platforms.\n\u2022 Act as a change agent for advanced analytics technologies and supporting processes to maximize results measured by performance and availability, business agility, technology freshness, and cost optimization.\n\u2022 Lead cloud application architecting/designing sessions with business partners evaluating tradeoffs between design, risk, and technology.\n\u2022 Execute prototypes and technical feasibility assessments for cloud analytics solutions.\n\u2022 Apply advanced technical knowledge and skills in developing solutions or problem solving where complexity, innovation and technical expertise are required.\n\nAS PART OF THE CLOUD SOLUTION TEAM, CANDIDATE WOULD FOCUS ON SOLUTION AND DEVELOPMENT:\n\u2022 Through various communication vehicles and methods (e.g., meetings, application demos, emails, workshops, etc.) develop, innovate and implement technical solutions for cloud projects including high performance computing, advanced analytics and big data.\n\u2022 Engage with the client to secure buy-in for the adoption of cloud-based solutions, through workshops and briefs as necessary.\n\u2022 Recommend technology strategy by understanding key client objectives; diagnosing and mapping client requirements; articulating solution risks and barriers; recommending delivery approaches; preparing time estimates; planning full project life cycle.\n\u2022 Develop, contribute, and evaluate technical proposals related to cloud analytics projects and implementations.\n\u2022 Provide expertise to construct the architecture and solutions to support current and future business needs, and to ensure the successful implementation and adoption of service.\n\u2022 Develop and implement activities, such as but not limited to, sequencing, architecture, assumptions, dependencies and customer buy-in that shall include an end-to-end view of the overall implementation approach to design and develop innovative analytics systems with cloud platform services.\n\u2022 Throughout the projects, you will participate in status meetings on progress, priorities, issues, performance issues, and future work.\n\nIN ORDER TO BE SUCCESSFUL IN THIS ROLE, WE EXPECT THAT QUALIFIED CANDIDATES WILL HAVE THE FOLLOWING SKILLS, EXPERIENCE, AND CREDENTIALS:\n\u2022 Minimum of 8 years enterprise IT application experience, including at least 3 years of architecting strategic, scalable BI, Big Data solutions, and data analytics.\n\u2022 Experience dealing with Federal government is necessary (must have, preference given to Law Enforcement experience).\n\u2022 Ability to understand \u201cBig Data\u201d use cases , and develop business outcome driven use-cases and what it means for both compute and storage resources in order to recommend the appropriate server and storage required in a Hadoop deployment\n\u2022 Hands-on with \u201cBig Data\u201d technologies with the Hadoop stack (e.g. Spark,MapReduce, Hive, Streaming) and practical experience that allows you distinguish between the implementation reality and the hype!\n\u2022 Minimum a Bachelor's degree in Computer Science, Information Systems Management or similar preferred.\n\u2022 Senior level with more then 10+ years of hands-on planning, designing, and engineering enterprise class systems and services.\n\u2022 Plan and establish Hadoop technology standards and usage frameworks within the BI Department.\n\u2022 Knowledge of data conversion strategy, capturing data, creating source to target definitions for ETL/ data flow process, data quality and data base management\n\u2022 Knowledge of image processing and image analytics including video analytics\n\u2022 Knowledge of AWS and Google analytics platforms\n\u2022 Work in concert with a team of ETL developers to ensure efficient and accurate data transfer within the entire EDW echo system with Big Data Platforms.\n\u2022 Build and optimize information models, physical data layouts, configuration, optimization and monitoring Hadoop environments and improve overall processing efficiencies to support the needs of the business.\n\u2022 In depth knowledge and hands on experience with the full range of cloud service providers/solutions, inclusive of AWS and Microsoft Azure offerings.\n\u2022 Amazon Web Services (AWS) Solutions Architect certifications (Associate or Professional) (or demonstrated ability and willingness to achieve certification shortly after hire).\n\u2022 * Must have proven success in consulting to CTO-level clients.\n\u2022 Proven experience in assessment, evaluation, and documentation of client environment, infrastructure, processes, and operations.\n\u2022 Proven experience in communicating and demonstrating the value of cloud solutions to a variety of stakeholders to address complex and competing drivers in complex technical environments, with a track record of buy-in and successful implementation, migration, change management, and full adoption.\n\u2022 Proven ability to lead change across large platforms using innovative technology solutions with federal government and commercial sectors.\n\u2022 Demonstrated abilities in strategic thinking and leadership with strong relationship management ability.\n\u2022 Demonstrated experience automating production cloud workloads.\n\u2022 Knowledge and experience with analytics tools and platforms including Apache Spark, Hive, Presto, HBase, Kafka, MongoDB etc.\n\u2022 Strong scripting skills (Python, Ruby, Perl, Bash, Powershell, etc.)\n\u2022 Strong knowledge of IP Networking including VPC's, VPN's, VRF, DNS, load-balancing, and firewalls.\n\u2022 Demonstrated experience with the Software Development Lifecycle.\n\u2022 Understanding of Service-Oriented Architecture (SOA and REST).\n\u2022 Proven ability to lead change across large platforms / functional areas using innovative technology solutions.\n\u2022 Demonstrated customer focus.\n\u2022 Strong analytical and strong real problem solving skills (not on paper only).\n\u2022 Communicates clearly and effectively evaluates information to make decisions.\n\u2022 Must have previous and strong experience in presentation and writing.\n\u2022 Anticipates risks and obstacles and develops plans for mitigation.\n\u2022 Creates actionable strategies and operational plans.\n\u2022 Champions and drives change initiatives.\n\u2022 Confronts difficult problems in a positive and creative way.\n\u2022 Balances multiple and competing priorities and executes accordingly",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum of 8 years enterprise IT application experience, including at least 3 years of architecting strategic, scalable BI, Big Data solutions, and data analytics",
                        "Experience dealing with Federal government is necessary (must have, preference given to Law Enforcement experience)",
                        "Ability to understand \u201cBig Data\u201d use cases , and develop business outcome driven use-cases and what it means for both compute and storage resources in order to recommend the appropriate server and storage required in a Hadoop deployment",
                        "Hands-on with \u201cBig Data\u201d technologies with the Hadoop stack (e.g",
                        "Spark,MapReduce, Hive, Streaming) and practical experience that allows you distinguish between the implementation reality and the hype!",
                        "Senior level with more then 10+ years of hands-on planning, designing, and engineering enterprise class systems and services",
                        "Plan and establish Hadoop technology standards and usage frameworks within the BI Department",
                        "Knowledge of image processing and image analytics including video analytics",
                        "Knowledge of AWS and Google analytics platforms",
                        "In depth knowledge and hands on experience with the full range of cloud service providers/solutions, inclusive of AWS and Microsoft Azure offerings",
                        "Amazon Web Services (AWS) Solutions Architect certifications (Associate or Professional) (or demonstrated ability and willingness to achieve certification shortly after hire)",
                        "Must have proven success in consulting to CTO-level clients",
                        "Proven experience in assessment, evaluation, and documentation of client environment, infrastructure, processes, and operations",
                        "Proven ability to lead change across large platforms using innovative technology solutions with federal government and commercial sectors",
                        "Demonstrated abilities in strategic thinking and leadership with strong relationship management ability",
                        "Demonstrated experience automating production cloud workloads",
                        "Knowledge and experience with analytics tools and platforms including Apache Spark, Hive, Presto, HBase, Kafka, MongoDB etc",
                        "Strong scripting skills (Python, Ruby, Perl, Bash, Powershell, etc.)",
                        "Strong knowledge of IP Networking including VPC's, VPN's, VRF, DNS, load-balancing, and firewalls",
                        "Demonstrated experience with the Software Development Lifecycle",
                        "Demonstrated customer focus",
                        "Strong analytical and strong real problem solving skills (not on paper only)",
                        "Communicates clearly and effectively evaluates information to make decisions",
                        "Must have previous and strong experience in presentation and writing",
                        "Confronts difficult problems in a positive and creative way"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Responsible for collaborating on and setting cloud vision; providing thought leadership in cloud infrastructure and cloud services architecture to meet client's operational objectives for cloud solutions",
                        "Consulting with our clients as a cloud technology evangelist around Cloud technologies including IaaS, SaaS, PaaS, Public/Hybrid/Community Cloud Service Provider offerings to develop advanced analytics solutions to solve real-world problems",
                        "Designing technical architecture for cloud analytics solutions that meet customer needs for scalability, reliability and performance",
                        "Identifying new cloud technologies and platforms to help solve technical challenges or limitations in the existing infrastructure",
                        "The Senior Cloud Solution Architect is responsible, with our established team of SMEs, change managers, integration engineers, system engineers and business analysts, for discovery and assessment of the current environment, proposing architectures, and implementing solutions for our client and its sub-agencies to consume services from the cloud",
                        "This role will serve as an advanced analytics solution architect providing strategic and technical leadership for client teams migrating, developing, or enriching applications in the cloud",
                        "The Senior Cloud Solution Architect is responsible for supporting multiple customers to evaluate customers\u2019 current and anticipated needs, develop innovative solutions, support technical proposals, develop architectures, and evaluate cloud implementations according to industry best practices and standards",
                        "Provide thought and technical design leadership to cloud analytics solutions using cloud native and third party software",
                        "Serve as a technical SME for big data, analytics, cloud services, providers, and platforms",
                        "Act as a change agent for advanced analytics technologies and supporting processes to maximize results measured by performance and availability, business agility, technology freshness, and cost optimization",
                        "Lead cloud application architecting/designing sessions with business partners evaluating tradeoffs between design, risk, and technology",
                        "Execute prototypes and technical feasibility assessments for cloud analytics solutions",
                        "Apply advanced technical knowledge and skills in developing solutions or problem solving where complexity, innovation and technical expertise are required",
                        "Through various communication vehicles and methods (e.g., meetings, application demos, emails, workshops, etc.) develop, innovate and implement technical solutions for cloud projects including high performance computing, advanced analytics and big data",
                        "Engage with the client to secure buy-in for the adoption of cloud-based solutions, through workshops and briefs as necessary",
                        "Recommend technology strategy by understanding key client objectives; diagnosing and mapping client requirements; articulating solution risks and barriers; recommending delivery approaches; preparing time estimates; planning full project life cycle",
                        "Develop, contribute, and evaluate technical proposals related to cloud analytics projects and implementations",
                        "Provide expertise to construct the architecture and solutions to support current and future business needs, and to ensure the successful implementation and adoption of service",
                        "Develop and implement activities, such as but not limited to, sequencing, architecture, assumptions, dependencies and customer buy-in that shall include an end-to-end view of the overall implementation approach to design and develop innovative analytics systems with cloud platform services",
                        "Throughout the projects, you will participate in status meetings on progress, priorities, issues, performance issues, and future work",
                        "Knowledge of data conversion strategy, capturing data, creating source to target definitions for ETL/ data flow process, data quality and data base management",
                        "Work in concert with a team of ETL developers to ensure efficient and accurate data transfer within the entire EDW echo system with Big Data Platforms",
                        "Build and optimize information models, physical data layouts, configuration, optimization and monitoring Hadoop environments and improve overall processing efficiencies to support the needs of the business",
                        "Creates actionable strategies and operational plans"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.ecstech.com/",
                    "text": "ecstech.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=inforeliance&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCJoL",
                    "text": "See web results for inforeliance"
                }
            ],
            "extensions": [
                "Full-time"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJTZW5pb3IgQ2xvdWQgU29sdXRpb25zIEFyY2hpdGVjdCBTZWNyZXQgQ2xlYXJhbmNlIiwiaHRpZG9jaWQiOiJJcUpLWmctcDh4OEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlYyRnphR2x1WjNSdmJpQkVRdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFcUVDQ3VJQlFVVnpOMnBPVTJoSWNGRmxSbDlVVFRGTVRUZDVXVWx2V0RkSlFreEJOVkZOYjNaRVpFeFBkRkpYTjBndFpUZFVVMDlqV1VZdFptRlFNVVpzYzA5WGVrWlpObWxwTlRkUGFsVjBObUV4UlU4MU9WVjNabEJOZEc1NFIwMXNTVmhxZEc4MVNEVXlaVkYyYzI1a2NHNWxSazV0ZEc1cVRETTJZMUpPV0Y5RE5rSXdjV0pVTldNelgyMVpiMFE1TFdrelpEaEZZVzVQVkZWVFVUVlJZMk4wTjJGWVUzazFlRE53Y0hCemJGSjBVbTlsYWtNNE1XZDFYM1psU3kxSlozSkRSR3RCUkVOeFNGRjBNRmw0V1VKa2QwOUlWV3RZT1dWemVEUnZZbGd0TUdJNFFSSVdSMHh6T1ZwT05UWnJaVWhoZFdkZlJHZHlOMjlCVVJvaVFVOHRNSEpzTjJ4S2JHaFpOR3RYZFdsemMwZ3dZakpDYldVeGExcHNUblJxZHciLCJmY3YiOiIzIiwiZmNfaWQiOiJmY182IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFdheVVwIiwibGluayI6Imh0dHBzOi8vd3d3LndheXVwLmNvbS9pLWotaW5mb3JlbGlhbmNlLTk2NTY0Njg0NzU3OTU4OS8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Cloud Software Engineer",
            "company_name": "WayUp",
            "location": "  Washington, DC   ",
            "via": "via JobLeads",
            "description": "Candidates must sit in the Washington DC metro area and must be US Citizens due to the nature of work performed.\n\nSecurity Clearance: Active TS/SCI FS Poly is required at the time of hire. Candidates with clearance that has been inactive for less than 2 years, will also be considered...\n\nOur Client, a software consultancy company heavily integrated with the Department of Defense, Intelligence and Civilian agencies is seeking an experienced Cloud Software Engineer\n\nWhat You'll Do:\n\u2022 The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements.\n\u2022 Directly contributes to all stages of back-end processing, analyzing, and indexing. Provides expertise in Cloud Computing, and Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\u2022 Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nWhat You'll Need:\n\u2022 Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required.\n\u2022 Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree.\n\u2022 Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\u2022 Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 Ingesting, Parsing, and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Security Clearance: Active TS/SCI FS Poly is required at the time of hire",
                        "Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelor's degree in computer science or related discipline from an accredited college or university is required",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree",
                        "Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing, and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, and Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.wayup.com/",
                    "text": "wayup.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=WayUp&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCN0L",
                    "text": "See web results for WayUp"
                }
            ],
            "extensions": [
                "6 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "6 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciIsImh0aWRvY2lkIjoiQ0Jyb2xVYl8ydWtBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WMkZ6YUdsdVozUnZiaUJFUXciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXZZQkNyY0JRVVZ6TjJwT1VtMXRXbXgxV210MVVIQlhWR2MwUkZKTFVuRmZTVXRUV0ZwM01Gb3lVbmRvY0dVNWVYZDBSbUZDYXpaR1QzcFZjakZQZDBGeWVuaEdZWGRGUjFCTFVtVjBjVnBOTVRoaVIzRldSbEZRWm1ZeFEwUTNRbEZZYmxwdVdtNDBVbEJuTlhWM1FtcExiV1pqZW1GWmVtcDJNWEJqTWt0R1RtTTFTR0ZDTUZrMGMweE9MUzFtY1cxSlgxZzJlVkUwUW01eGJteGFNV1pzVm1oWWVDMTJkbUpIYUZGbVV6aHhVbEJqUVcwNVRIQnVVMk5CRWhaSFRITTVXazQxTm10bFNHRjFaMTlFWjNJM2IwRlJHaUpCVHkwd2NtdzNlVzlmUVZOTU5FNW9XWE5ZVUZsVVFqbFRXWGR6UTJ4TmMwNTMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY184IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEpvYkxlYWRzIiwibGluayI6Imh0dHBzOi8vd3d3LmpvYmxlYWRzLmNvbS9lbi11cy9qb2IvZTFhYmNjNjMyODZiZmE5YjY0OTkwNWExNGFjZDg5ZWU3P3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Data Cloud Engineer, Senior",
            "company_name": "Booz Allen Hamilton",
            "location": "  Chantilly, VA   ",
            "via": "via Booz Allen Hamilton",
            "description": "Data Cloud Engineer, Senior\n\nThe Challenge...\n\nAre you looking for an opportunity to develop a data platform that will have an impact on rapid exploitation and sharing of multi-INT information across the intelligence community? Solid platform development is a critical part of any program\u2019s success, and you know how to do it right through scalable design with baked-in security. That\u2019s why we need you, a developer with the skills to build a platform that will transform the integrated intelligence mission.\n\nAs a data platform developer on our team, you\u2019ll design and develop the core data integration platform for our project from end to end. You\u2019ll work with customers and end-users to understand their mission, architecture, and security requirements. With a focus on the customer\u2019s goals, you\u2019ll build a design that will scale to meet their evolving needs. Your technical expertise will be vital as you recommend tools and capabilities based on your research of the environment and new technology. Your design will set the standard for future development, so you\u2019ll craft an architecture that smoothly works with existing infrastructure without compromising security.\n\nAs a technical leader, you\u2019ll identify new opportunities to build platform-based solutions to help your customers meet their toughest challenges. This is a chance to use your deep OS knowledge and broaden your skill set into areas like Cloud computing, large-scale data ingestion and processing, multiple data store types, including graph data, time series, spatial, and other NoSQL, high performance data streaming, data science, and supporting the integration of novel mission applications and analytics. Join us as we develop software-based solutions to make a difference for the integrated intelligence mission.\n\nEmpower change with us.\n\nYou Have:\n\u2022 Experience with Java, Spark, Scala, Hive, or ETL engineering\n\u2022 Experience with working in data ingestion, processing, and distribution\n\u2022 Experience in developing and deploying data ingestion, processing, and distribution systems with AWS technologies\n\u2022 Experience with using AWS datastores, including RDS Postgres, S3, or DynamoDB\n\u2022 Experience with Agile software development practices\n\u2022 TS/SCI clearance\n\u2022 Bachelor's degree\n\u2022 Ability to obtain Security+ CE, SSCP, CCNA-Security, or GSEC Certification within 6 months of hire\n\nNice If You Have:\n\u2022 2+ years of experience with cognitive computing, data integration, data mining, Natural Language Processing, Hadoop platforms, or automating machine learning components\n\u2022 1+ years of experience with data mining using current methods and tools\n\u2022 Experience in working with IC data sets and NoSQL databases, including Elasticsearch and HBase\n\u2022 Experience with graph data stores, time series database, and other NoSQL technologies\n\u2022 Experience with processing big data with Spark, Scala, or MapReduce\n\u2022 Knowledge of Jira, Git, Kafka, Kubernetes, OpenShift and OCP, or Docker\n\u2022 Knowledge of data science tools and their integration with big data stores\n\u2022 Knowledge of data security policies and guidelines\n\u2022 AWS Certification\n\u2022 Security+ CE, SSCP, CCNA-Security, or GSEC Certification\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.\n\nBuild Your Career:\n\nA challenging and dynamic work environment isn\u2019t all we have to offer. When you join Booz Allen, you\u2019ll have access to:\n\u2022 experts in virtually every field\n\u2022 a culture that focuses on supporting our employees\n\u2022 opportunities that provide stability while offering variety\n\nYou\u2019ll also be exposed to a wealth of training resources through our Digital University, an online learning portal featuring more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We\u2019ll help you develop the career you want as you chart your own course for success.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n\nWork Model\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nEEO Commitment\n\nWe\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Experience with Java, Spark, Scala, Hive, or ETL engineering",
                        "Experience in developing and deploying data ingestion, processing, and distribution systems with AWS technologies",
                        "Experience with using AWS datastores, including RDS Postgres, S3, or DynamoDB",
                        "Experience with Agile software development practices",
                        "Bachelor's degree",
                        "Ability to obtain Security+ CE, SSCP, CCNA-Security, or GSEC Certification within 6 months of hire",
                        "2+ years of experience with cognitive computing, data integration, data mining, Natural Language Processing, Hadoop platforms, or automating machine learning components",
                        "1+ years of experience with data mining using current methods and tools",
                        "Experience in working with IC data sets and NoSQL databases, including Elasticsearch and HBase",
                        "Experience with graph data stores, time series database, and other NoSQL technologies",
                        "Experience with processing big data with Spark, Scala, or MapReduce",
                        "Knowledge of Jira, Git, Kafka, Kubernetes, OpenShift and OCP, or Docker",
                        "Knowledge of data science tools and their integration with big data stores",
                        "Knowledge of data security policies and guidelines",
                        "AWS Certification"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "As a data platform developer on our team, you\u2019ll design and develop the core data integration platform for our project from end to end",
                        "You\u2019ll work with customers and end-users to understand their mission, architecture, and security requirements",
                        "With a focus on the customer\u2019s goals, you\u2019ll build a design that will scale to meet their evolving needs",
                        "Your technical expertise will be vital as you recommend tools and capabilities based on your research of the environment and new technology",
                        "Your design will set the standard for future development, so you\u2019ll craft an architecture that smoothly works with existing infrastructure without compromising security",
                        "As a technical leader, you\u2019ll identify new opportunities to build platform-based solutions to help your customers meet their toughest challenges",
                        "This is a chance to use your deep OS knowledge and broaden your skill set into areas like Cloud computing, large-scale data ingestion and processing, multiple data store types, including graph data, time series, spatial, and other NoSQL, high performance data streaming, data science, and supporting the integration of novel mission applications and analytics",
                        "If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "a culture that focuses on supporting our employees",
                        "opportunities that provide stability while offering variety",
                        "You\u2019ll also be exposed to a wealth of training resources through our Digital University, an online learning portal featuring more than 5000 functional and technical courses, certifications, and books",
                        "You may be able to take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips",
                        "At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being",
                        "Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care",
                        "The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD)"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.boozallen.com/",
                    "text": "boozallen.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Booz+Allen+Hamilton&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCKAM",
                    "text": "See web results for Booz Allen Hamilton"
                }
            ],
            "extensions": [
                "Full-time",
                "Health insurance"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJEYXRhIENsb3VkIEVuZ2luZWVyLCBTZW5pb3IiLCJodGlkb2NpZCI6ImYxaGpxM04yZ2JFQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVjJGemFHbHVaM1J2YmlCRVF3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVvc0NDc3dCUVVWek4ycE9VMGRxYVZOUVNuSm1RbTVMWmpoSGJ6RTFkRWxuWm1oalUxcHljekl6ZFd4bWRGYzVUR3hJV210cmNtMURUbk5hVUc5T2VISXlaMVJ1UTFkRFdtZEtZbVUyVUZrMlFtaGpkMWRuVTBReU1rZ3RUWGRLTFZJM1JVWnBRbWRSVkVacE5VRldUazB0TUZwSVVVMXNZelJWUnpGUGFUQmpOM1puTlVaa1pHWm1TblI0WlRodGFFVkNiR0ZQTFY5Q2RHcHROVTV5UVRnemNtbEpaMk10UmpCdWQwVkJVVGhXVDNGZmRWTklaWEpsTW5welgwMDBjRUpqVmt3MWIwUjVSRmRoV0dZNGMzbDJFaFpIVEhNNVdrNDFObXRsU0dGMVoxOUVaM0kzYjBGUkdpSkJUeTB3Y213MVdESlNOMlZ4V1hwcFptMVJhbkpmVFd0R2JrMUZiWFpIY21oUiIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEwIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEJvb3ogQWxsZW4gSGFtaWx0b24iLCJsaW5rIjoiaHR0cHM6Ly9jYXJlZXJzLmJvb3phbGxlbi5jb20vbG9jYXRpb25zL0pvYkRldGFpbC9DaGFudGlsbHktRGF0YS1DbG91ZC1FbmdpbmVlci1TZW5pb3ItUjAxNjA3NjkvNzIzMjg/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "390 Cloud Software Engineer 2",
            "company_name": "ARSIEM",
            "location": "  Laurel, MD   ",
            "via": "via ZipRecruiter",
            "description": "About ARSIEM Corporation\n\nAt ARSIEM Corporation we are committed to fostering a proven and trusted partnership with our government clients. We provide support to multiple agencies across the United States Government. ARSIEM has an experienced workforce of qualified professionals committed to providing the best possible support...\n\nAs demand increases, ARSIEM continues to provide reliable and cutting-edge technical solutions at the best value to our clients. That means a career packed with opportunities to grow and the ability to have an impact on every client you work with.\n\nARSIEM is currently looking for a Cloud Software Engineer. The position will support one of our Government clients in Laurel, MD.\n\nResponsibilities\n\u2022 Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements. Directly contributes to all stages of back-end processing, analyzing, and indexing.\n\u2022 Provides expertise in Cloud Computing and Hadoop Eco-System, including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\u2022 Works individually or as part of a team.\n\u2022 Reviews and tests software components to adhere to design requirements and document test results.\n\u2022 Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nMinimum Qualifications\n\u2022 NIFI\n\u2022 Eight (8) years of experience in software engineering experience in programs and contracts of similar scope, type, and complexity is required.\n\u2022 Two (2) years of experience in programs utilizing Big-Data Cloud technologies and Distributed Computing.\n\u2022 Bachelor's degree in Computer Science or a related discipline from an accredited college or university is required.\n\u2022 Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree.\n\u2022 Master's degree in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\u2022 Two (2) years of Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 One (1) year of experience implementing code that interacts with the implementation of Cloud Big Table.\n\u2022 One (1) year of experience implementing code that interacts with Cloud Distributed File System implementation.\n\u2022 One (1) year of experience implementing complex MapReduce analytics.\n\u2022 One (1) year of experience implementing code that interacts with Cloud Distributed Coordination Frameworks.\n\u2022 Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing\n\u2022 Multi-Node Management and Installation: Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies.\n\u2022 Experience with Information Assurance: Securing Cloud-Based and Distributed applications through industry-standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications\n\u2022 UNIX/LINUX, CentOS\n\u2022 Experience with at least one SIGINT collection discipline area (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, and ELINT)\n\u2022 Geolocation, emitter identification, and signal applications. 3. Joint program collection platforms and dataflow architectures; signals characterization analysis\n\u2022 CentOS and Linux/RedHat\n\u2022 Configuration management tools such as Subversion, ClearQuest, or Razor\n\nClearance Requirement: This position requires an active TS/SCI with a polygraph. You must be a US Citizen for consideration.\n\nCandidate Referral: Do you know someone who would be GREAT at this role? If you do, ARSIEM has a way for you to earn a bonus through our referral program for persons presenting NEW (not in our resume database) candidates who are successfully placed on one of our projects. The bonus for this position is $10,000, and the referrer is eligible to receive the sum for any applicant we place within 12 months of referral. The bonus is paid after the referred employee reaches 6 months of employment.\n\nARSIEM is proud to be an Equal Opportunity and Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age, or any other federally protected class",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "NIFI",
                        "Eight (8) years of experience in software engineering experience in programs and contracts of similar scope, type, and complexity is required",
                        "Two (2) years of experience in programs utilizing Big-Data Cloud technologies and Distributed Computing",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree",
                        "Master's degree in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Two (2) years of Cloud and Distributed Computing Information Retrieval (IR)",
                        "One (1) year of experience implementing code that interacts with Cloud Distributed File System implementation",
                        "One (1) year of experience implementing complex MapReduce analytics",
                        "Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing",
                        "Multi-Node Management and Installation: Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies",
                        "Experience with Information Assurance: Securing Cloud-Based and Distributed applications through industry-standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications",
                        "UNIX/LINUX, CentOS",
                        "Experience with at least one SIGINT collection discipline area (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, and ELINT)",
                        "Geolocation, emitter identification, and signal applications",
                        "Joint program collection platforms and dataflow architectures; signals characterization analysis",
                        "CentOS and Linux/RedHat",
                        "Configuration management tools such as Subversion, ClearQuest, or Razor",
                        "Clearance Requirement: This position requires an active TS/SCI with a polygraph",
                        "You must be a US Citizen for consideration"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing and Hadoop Eco-System, including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components to adhere to design requirements and document test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "The bonus for this position is $10,000, and the referrer is eligible to receive the sum for any applicant we place within 12 months of referral"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.arsiem.com/",
                    "text": "arsiem.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=ARSIEM&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCOAM",
                    "text": "See web results for ARSIEM"
                }
            ],
            "extensions": [
                "13 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "13 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiIzOTAgQ2xvdWQgU29mdHdhcmUgRW5naW5lZXIgMiIsImh0aWRvY2lkIjoieVdnQ0xsc21ZemtBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WMkZ6YUdsdVozUnZiaUJFUXciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRW9zQ0Nzd0JRVVZ6TjJwT1UzQnhMVXg2YnpSR2MzbDZWRVJ4V25KVWEydE1TRGh5U0VaUlJsWkVYM2R2Y1dsSGRVWkZRbTR4Vm5sTlpGOUpMVGN3WW5WaVJqRndibmhYTW1seU9HNTBVblpWTjFaVlJtdGhla1ZuWjBaUWNrdDNjMlYxZW1GVlkweHFUVk5NY0doTFpWQlllVTlCYWxWU01YQTFSVEZHYlRWWVUxZzNOR3BWTFhsWWQzQXdNWE10VFROaFltZG1NelI2Y1U1VGFHSmhNMU5ZVDJGNGRWcDJWR2RPTVc5S1FqVklWVXRFTmxKVlVHUkdhVzVzYldoblptOXliVGRvV1cwMlkwUlFSbHBQUkZKbkVoWkhUSE01V2s0MU5tdGxTR0YxWjE5RVozSTNiMEZSR2lKQlR5MHdjbXcyZFdkdldVbHRhbWx5YldORmVVUXdSazR4VW5vNWJEQlNTa0ozIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTIiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gWmlwUmVjcnVpdGVyIiwibGluayI6Imh0dHBzOi8vd3d3LnppcHJlY3J1aXRlci5jb20vYy9BUlNJRU0vSm9iLzM5MC1DbG91ZC1Tb2Z0d2FyZS1FbmdpbmVlci0yLy1pbi1MYXVyZWwsTUQ/amlkPTA0ZjgzNDI5MDZlMjUwODNcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        },
        {
            "title": "Cloud Software Engineer (Hybrid)",
            "company_name": "PerunHR",
            "location": "  Catonsville, MD   ",
            "via": "via Jobs By Workable",
            "description": "Since our inception, PerunHR has been focused on building a strategic, quality outsourcing practice. We offer recruitment process outsourcing services by implementing a modern recruitment system, using the latest recruiting and screening solutions, modern online job boards, and Applicant Tracking Systems. We help our clients find perfect fits for their vacancies and support candidates to connect... with our clients and achieve their goals together. In a market with numerous service providers, by nurturing our core values, our staff apply and improve specialized knowledge in the required field while ensuring high expertise in providing services.\n\nFor our client, a company that provides outstanding program management, consulting, and infrastructure support to both private and commercial businesses, we are looking for a Cloud Software Engineer to support the current and future projects.\n\nJob Description:\n\u2022 Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements.\n\u2022 Directly contributes to all stages of back-end processing, analyzing, and indexing.\n\u2022 Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\u2022 Works individually or as part of a team.\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\u2022 Candidates must sit in the Washington DC metro area or within in 90 mins driving time (include Maryland, Virginia, and Washington DC).\n\u2022 Security Clearance: Active TS/SCI FS Poly is required at the time of hire or if the clearance has been inactive for less than 2 years, the candidates will be consider. The candidates must complete a security verification and their start date would be pending the reactivation of their clearance.\n\u2022 U.S. citizenship.\n\u2022 8 years of experience in software engineering, in programs and contracts of similar scope, type, and complexity is required; 2 years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required; 4 years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree; Master in Computer Science or related discipline from an accredited college or university may be substituted for 2 years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for 1 year of Cloud experience.\n\u2022 Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB.\n\u2022 Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies.\n\u2022 Aspect Oriented Design and Development.\n\u2022 Debugging and Profiling Cloud and Distributed Installations.\n\u2022 Salary: $131,000 - $140,000 / yearly",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Security Clearance: Active TS/SCI FS Poly is required at the time of hire or if the clearance has been inactive for less than 2 years, the candidates will be consider",
                        "The candidates must complete a security verification and their start date would be pending the reactivation of their clearance",
                        "U.S. citizenship",
                        "8 years of experience in software engineering, in programs and contracts of similar scope, type, and complexity is required; 2 years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelor's degree in computer science or related discipline from an accredited college or university is required; 4 years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree; Master in Computer Science or related discipline from an accredited college or university may be substituted for 2 years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for 1 year of Cloud experience",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Salary: $131,000 - $140,000 / yearly"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=PerunHR&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCJ4N",
                    "text": "See web results for PerunHR"
                }
            ],
            "extensions": [
                "13 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "13 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciAoSHlicmlkKSIsImh0aWRvY2lkIjoiRzZOaGFVcUdhS1FBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WMkZ6YUdsdVozUnZiaUJFUXciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXZZQkNyY0JRVVZ6TjJwT1VrbFhVMmhCV0dwSlRFSmFkbEIxYmxFelNYWjBSa1JWVGxFeVdFUjNZa3BzUjB4aVZEQjVXSFpWU0VGYU5tSjROakpKWkMweUxXMVdPR2x2YW5oWFRqSTNkVnBmTm1KTU4yWkRlbEYyV0dSUk9YWmFUbGM1YUVReWVESkxSMk41Vm1OblJGUXhkVTFGTUdkRGVqRmxhbkJpVWtKa01ucFFWREY1TVZsa05XWkpUMDloZUV4V1gwaFRlbmx2VkhwaVpIQm5RMFkwTlVsZmRGVkRhekYyVnpSTlREQXhXa3d0ZW00NVEwZHpMVTV2RWhaSFRITTVXazQxTm10bFNHRjFaMTlFWjNJM2IwRlJHaUpCVHkwd2NtdzBZVmhtY0dGWlRYVjVjMkozZDNNNGR6aHBYM0JQZEc1TE0yZEIiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBKb2JzIEJ5IFdvcmthYmxlIiwibGluayI6Imh0dHBzOi8vYXBwbHkud29ya2FibGUuY29tL3BlcnVuaHIvai8yMUNGREJCMjQ2Lz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        },
        {
            "title": "Cloud Design Engineer 2 - Security Clearance Required",
            "company_name": "Raytheon Technologies",
            "location": "  Annapolis, MD   ",
            "via": "via FOX44 News Jobs",
            "description": "Date Posted:2022-11-03-07:00\n\nCountry:United States of America...\n\nLocation:MD233: 420 National Business Parkway 420 National Business Parkway Suite 400, Annapolis Junction, MD, 20701 USA\n\nPosition Role Type:Onsite\n\nRaytheon Technologies' CODEX (Cyber Offense and Defense Experts) division brings together an elite team of mission-focused industry experts who are well known for their ability to overcome the most advanced technical challenges. The team comprises engineers of multiple disciplines including vulnerability research, reverse engineering, CNO/CNE development, hardware emulation, system engineering, and data analytics. Our engineers do more than just work with cutting-edge technology-they ensure the missions succeed for the customers! CODEX offices span the nation and offer its engineers the ability to advance their careers through mentorship, training, and an expansive technical portfolio that covers every side of cyber. If you want to be part of a collaborative team that supports challenging, meaningful work that is vital to our national security, apply today!\n\nJob Overview: Cloud Software Engineer\n\nDevelops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements\n\nDirectly contributes to all stages of Web-based User Interfaces that expose data for Big Data Cloud Based infrastructure using Hadoop ecosystem.\n\nProvides expertise in Cloud Computing, Distributed Computing, and how best to display data produced by these technologies.\n\nImplements Graphical Web-Based User Interface with usability, security, and performance in mind.\n\nReviews and tests software components for adherence to the design requirements and documents test results\n\nResolves software problem reports\n\nUtilizes software development and software design methodologies appropriate to the development environment\n\nProvides specific input to the software components of system design to include hardware/software trade-offs, software reuse.\n\nThe Cloud Design Engineer shall possess the following capabilities:\n\nProvide in-depth knowledge of Information Retrieval\n\nAssisting the software development team in designing, developing and testing Cloud Information\n\nPropose new ways of analyzing data stored in Cloud Big Table\n\nPropose new ways of analyzing data stored in Cloud Distributed File System\n\nOversee one or more software development tasks and ensures the work is completed in accordance with the constraints of the software development process being used on any particular project\n\nEnsure quality control of all developed and modified software\n\nMake recommendations for improving documentation and software development process standards.\n\nPosition Requirements:\n\nEight (8) years' experience software engineering experience on programs and contracts of similar scope, type, and complexity is required.\n\nTwo (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\nEducation Requirements\n\nTypically requires Bachelor's degree in Computer Science or related discipline from an accredited college or university.\n\nClearance Requirements: This position requires a TS/SCI w/current polygraph.\n\nRelocation Eligible\n\nThis position is not relocation eligible.\n\nReferral Award Eligibility: Only employees currently within RMD and RI&S have the potential to receive a Referral Award for submitting a referral to RMD and RI&S roles. ALL eligibility requirements must be met to receive the Referral Awarding.\n\n#RISTB\n\n#RISCODEX\n\nRaytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\n\nPrivacy Policy and Terms:\n\nClick on this link to read the Policy and Terms",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Eight (8) years' experience software engineering experience on programs and contracts of similar scope, type, and complexity is required",
                        "Two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Typically requires Bachelor's degree in Computer Science or related discipline from an accredited college or university",
                        "Clearance Requirements: This position requires a TS/SCI w/current polygraph"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of Web-based User Interfaces that expose data for Big Data Cloud Based infrastructure using Hadoop ecosystem",
                        "Provides expertise in Cloud Computing, Distributed Computing, and how best to display data produced by these technologies",
                        "Implements Graphical Web-Based User Interface with usability, security, and performance in mind",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse",
                        "Provide in-depth knowledge of Information Retrieval",
                        "Assisting the software development team in designing, developing and testing Cloud Information",
                        "Propose new ways of analyzing data stored in Cloud Big Table",
                        "Propose new ways of analyzing data stored in Cloud Distributed File System",
                        "Oversee one or more software development tasks and ensures the work is completed in accordance with the constraints of the software development process being used on any particular project",
                        "Ensure quality control of all developed and modified software",
                        "Make recommendations for improving documentation and software development process standards"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.rtx.com/",
                    "text": "rtx.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Raytheon+Technologies&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCN8N",
                    "text": "See web results for Raytheon Technologies"
                }
            ],
            "extensions": [
                "5 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "5 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBEZXNpZ24gRW5naW5lZXIgMiAtIFNlY3VyaXR5IENsZWFyYW5jZSBSZXF1aXJlZCIsImh0aWRvY2lkIjoiOXVnUzltVFpUcUFBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WMkZ6YUdsdVozUnZiaUJFUXciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXJZQ0N2Y0JRVVZ6TjJwT1VXOXFTM1o2WTFkak1FOVBSa3h2UldKQlNWRkNjVmxGTm1WR2VqVjFWREZCYjBoaVQzTTNkVEp4VWt0UVJrZHBZMkZJT1dwUmMxcGtjMjFtVVc4dGR6aDRlWFJpYVRoR1kyWmpRV3A2ZHpjMmIzZGxVbkpNWWprelNDMWxkMGxKY2sxbmRtWTVZMjVQVTBOellVNUxWa2R4TnpSeU9YSXdkekpVUjIxdVIwRnRjRTlEZUdsMWIyUjVSbmQ0WTJGYWJuZzJRVlE1U0VkUVJ6bG9SamR2TFZCWldFaGlWMlpKTFMxRFZGbE5UalF6VjJOT1dXMDJRa0pKTlZNNVFYUklia1F4T1ZCMk5UTk1PV1IxVkZVMGJsbzBYMXBITXpRMldIVm5ZVzV5ZWtkMUxVcGxNMjFvUkVrelgyRkZibFk1UlJJV1IweHpPVnBPTlRaclpVaGhkV2RmUkdkeU4yOUJVUm9pUVU4dE1ISnNOMU52VEhWVlZucGlSVmRpVFZaQlgxbHNhRmhsUTNFMGNsbzVadyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzE1IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIEZPWDQ0IE5ld3MgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMuZm94NDRuZXdzLmNvbS9qb2JzL2Nsb3VkLWRlc2lnbi1lbmdpbmVlci0yLXNlY3VyaXR5LWNsZWFyYW5jZS1yZXF1aXJlZC1hbm5hcG9saXMtbWFyeWxhbmQvOTc1OTYxMDU1LTIvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Cloud Software Engineer Jobs",
            "company_name": "ManTech International",
            "location": "  Hanover, MD   ",
            "via": "via Clearance Jobs",
            "description": "Secure our Nation, Ignite your Future\n\nAre you interested in detecting internal and external threats? Do you have the ability to protect and defend the most coveted targets in the world to ensure the safety of information systems assets, and protect systems from intentional or inadvertent access or destruction? ManTech International Corporation is seeking individuals who are interested in joining... our team and helping protect our national security, while working on innovative projects that offer opportunities for advancement.\n\nManTech is currently looking for Cloud Software Engineers to join our team in the Ft. Meade, MD area. In this role, you will develop, maintain, and enhance complex and diverse Big-Data cloud systems based upon documented requirements and provide expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\nResponsibilities include, but are not limited to:\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the-shelf (COTS)/Government Offthe-shelf (GOTS).\n\nNOTE: Multiple levels of seniority are available dependent on qualifications/experience.\n\nMinimum Qualifications:\n\u2022 5 years of related experience. A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience.\n\u2022 4 years of experience developing software with high level languages such as Java, C, C++\n\u2022 3 years of experience in each of the following:\n\u2022 Developing software for Windows or UNIX/Linux/RH operating systems\n\u2022 Software integration and software testing, to include developing and implementing test plans and test scripts.\n\u2022 Ability to work with OpenSource (NoSQL) products that support highly distributed, massively parallel computation needs such as Hbase, CloudBase/Acumulo, Big Table, etc.\n\u2022 Demonstrated experience with the Map Reduce programming model and technologies such as Hadoop, Hive, Pig, etc\n\u2022 Demonstrated experience with the following\n\u2022 Hadoop Distributed File System (HDFS)\n\u2022 Serialization, such as JSON and/or BSON\n\u2022 Developing Restful services\n\u2022 Design and development of at least one Object Oriented system.\n\u2022 Developing solutions integrating and extending FOSS/COTS products.\n\u2022 Technical writing skills and shall have generated technical documents in support of a software development project\n\u2022 Source Code Management (e.g. Git, Stash, or Subversion, etc.)\n\u2022 Demonstrated experience or college level courses in at least 2 of the following:\n\u2022 Experience deploying applications in a cloud environment\n\u2022 Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)\n\u2022 Hadoop/Cloud Developer Certification\n\u2022 Experience designing and developing automated analytic software, techniques, and algorithms. Experience with taxonomy construction for analytic disciplines, knowledge areas and skills. Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines\n\u2022 Experience with linguistics (grammar, morphology, concepts\n\u2022 Experience developing and deploying analytics that discover and exploit social networks\n\u2022 Experience documenting ontologies, data models, schemas, formats, data element\n\nPreferred Qualifications:\n\u2022 8 years of related experience. A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience.\n\u2022 6 years of experience developing software with high level languages such as Java, C, C++\n\u2022 4 years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloubBase/Accumulo, Big Table, etc.\n\u2022 3 years of experience in each of the following:\n\u2022 Developing software for UNIX/Linux/RH operating systems and in software integration and software testing, to include developing and implementing test plans and test scripts\n\u2022 Software integration and software testing, to include developing and implementing test plans and test scripts.\n\u2022 2 years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc.\n\u2022 Demonstrated experience with Source Code Management (e.g. Git, Stash, or Subversion, etc.)\n\u2022 Demonstrated experience in at least 4 of the following:\n\u2022 Experience deploying applications in a cloud environment\n\u2022 Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)\n\u2022 Hadoop/Cloud Developer Certification\n\u2022 Experience designing and developing automated analytic software, techniques, and algorithms. Experience with taxonomy construction for analytic disciplines, knowledge areas and skills. Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines\n\u2022 Experience with linguistics (grammar, morphology, concepts\n\u2022 Experience developing and deploying analytics that discover and exploit social networks\n\u2022 Experience documenting ontologies, data models, schemas, formats, data element\n\nSecurity Clearance Requirements:\n\u2022 Current/Active TS/SCI with Polygraph.\n\nPhysical Requirements:\n\u2022 Must be able to remain in a stationary position 50%.\n\u2022 Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.\n\u2022 The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations.\n\nFor all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license.The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone.\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "5 years of related experience",
                        "A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience",
                        "4 years of experience developing software with high level languages such as Java, C, C++",
                        "3 years of experience in each of the following:",
                        "Ability to work with OpenSource (NoSQL) products that support highly distributed, massively parallel computation needs such as Hbase, CloudBase/Acumulo, Big Table, etc",
                        "Serialization, such as JSON and/or BSON",
                        "Design and development of at least one Object Oriented system",
                        "Demonstrated experience or college level courses in at least 2 of the following:",
                        "Experience deploying applications in a cloud environment",
                        "Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)",
                        "Hadoop/Cloud Developer Certification",
                        "Experience designing and developing automated analytic software, techniques, and algorithms",
                        "Experience with taxonomy construction for analytic disciplines, knowledge areas and skills",
                        "Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines",
                        "Experience developing and deploying analytics that discover and exploit social networks",
                        "4 years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloubBase/Accumulo, Big Table, etc",
                        "Developing software for UNIX/Linux/RH operating systems and in software integration and software testing, to include developing and implementing test plans and test scripts",
                        "2 years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc",
                        "Demonstrated experience with Source Code Management (e.g",
                        "Experience with linguistics (grammar, morphology, concepts",
                        "Current/Active TS/SCI with Polygraph",
                        "Must be able to remain in a stationary position 50%",
                        "Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer",
                        "For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "In this role, you will develop, maintain, and enhance complex and diverse Big-Data cloud systems based upon documented requirements and provide expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the-shelf (COTS)/Government Offthe-shelf (GOTS)",
                        "Developing Restful services",
                        "The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.mantech.com/",
                    "text": "mantech.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=ManTech+International&sa=X&ved=0ahUKEwje5syA77H-AhWRsFYBHUOBDx0QmJACCKMO",
                    "text": "See web results for ManTech International"
                }
            ],
            "extensions": [
                "2 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "2 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciBKb2JzIiwiaHRpZG9jaWQiOiJBNmxvcUF3eFdZSUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlYyRnphR2x1WjNSdmJpQkVRdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFb3NDQ3N3QlFVVnpOMnBPVVc1VFVteFFVbTB0U2xkVlJFdEZZell4U25aMVJFMDJUWEJuUkcxUE5VWkNNamx4TTNaMU5WWnpjelJ0TWpCVFdrcEhjMkZXWWxwNlpGbEZSVzFwTld0NVVrMXNNVkpEYWs5VmNFcGxOamc1YTJScVFrcDZSRFExT0doQmRXWm1WMVpqWldjdFNrcFBiMVEwT0VSd1JrVjJlSEIzY21SUGVXeHZUekl6YUdoM2VXVlRUM05HYkdoaFQwMTBRelpaTUhKS09WZ3haV1oyUW1zMGRsSnNRMDVtTURObE1WUkhVM2hMZUVoVWRuVk1NMk50YWtGdlZEUjJOVTVYYm1NMVZESmZNMjUzRWhaSFRITTVXazQxTm10bFNHRjFaMTlFWjNJM2IwRlJHaUpCVHkwd2NtdzBMWHBrY25GTFZtNVhTSEJXVWpac2NHZG5lWHBHZGs0d1dtZDMiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBDbGVhcmFuY2UgSm9icyIsImxpbmsiOiJodHRwczovL3d3dy5jbGVhcmFuY2Vqb2JzLmNvbS9qb2JzLzcxMjU0MzQvY2xvdWQtc29mdHdhcmUtZW5naW5lZXI/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        }
    ],
    "chips": [
        {
            "type": "Title",
            "param": "job_family_1",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Software engineer",
                    "value": "software engineer"
                },
                {
                    "text": "Design engineer",
                    "value": "design engineer"
                },
                {
                    "text": "Data architect",
                    "value": "data architect"
                },
                {
                    "text": "Customer engineer",
                    "value": "customer engineer"
                },
                {
                    "text": "Support engineer",
                    "value": "support engineer"
                },
                {
                    "text": "Cloud architect",
                    "value": "cloud architect"
                },
                {
                    "text": "Data consultant",
                    "value": "data consultant"
                },
                {
                    "text": "Sales engineer",
                    "value": "sales engineer"
                },
                {
                    "text": "Senior",
                    "value": "senior"
                },
                {
                    "text": "Solutions architect",
                    "value": "solutions architect"
                },
                {
                    "text": "Analyst",
                    "value": "analyst"
                },
                {
                    "text": "Cloud consultant",
                    "value": "cloud consultant"
                },
                {
                    "text": "Cloud engineer",
                    "value": "cloud engineer"
                },
                {
                    "text": "Data engineer",
                    "value": "data engineer"
                },
                {
                    "text": "Engineering",
                    "value": "engineering"
                },
                {
                    "text": "Manager",
                    "value": "manager"
                },
                {
                    "text": "Solution manager",
                    "value": "solution manager"
                },
                {
                    "text": "Technical",
                    "value": "technical"
                }
            ]
        },
        {
            "type": "Location",
            "param": "city",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Annapolis Junction, MD",
                    "value": "zW-xYyLnt4mqAms5YL-SKQ=="
                },
                {
                    "text": "Annapolis, MD",
                    "value": "1S9ncGX2t4lLJ6jT_VT4Qw=="
                },
                {
                    "text": "Atlanta, GA",
                    "value": "jQmTaV0E9YgLYwuZL97-Zg=="
                },
                {
                    "text": "Baltimore, MD",
                    "value": "t4P01q4DyIlY5yNCqJZIBA=="
                },
                {
                    "text": "Salt Lake City, UT",
                    "value": "7THRiJQ9UofKMU1IoLdTWw=="
                },
                {
                    "text": "Washington, DC",
                    "value": "W-T2Wt7Gt4kqXYjUIkVSwg=="
                },
                {
                    "text": "Catonsville, MD",
                    "value": "TYwOyT0cyImNcyTcDrP1IQ=="
                },
                {
                    "text": "Herndon, VA",
                    "value": "Q6ZdDwY4tol9NWwctSKAkg=="
                },
                {
                    "text": "Palo Alto, CA",
                    "value": "ORy6nXuwj4DPdvU1UvUfDg=="
                },
                {
                    "text": "Reston, VA",
                    "value": "5WUWJkdAtomfrnGo6K_fYw=="
                },
                {
                    "text": "San Francisco, CA",
                    "value": "IQBpAG2ahYD_rXbwZxNQSg=="
                },
                {
                    "text": "Weehawken, NJ",
                    "value": "AdCFFTBYwomUmggtWZ9PJQ=="
                },
                {
                    "text": "Boston, MA",
                    "value": "GzE9DS1l44mg6GIBJL98eA=="
                },
                {
                    "text": "Chantilly, VA",
                    "value": "GXJnGVZBtomDrRZD_PBBQA=="
                },
                {
                    "text": "Charlotte, NC",
                    "value": "gRo4_MQfVIhk0UO_5lBGiA=="
                },
                {
                    "text": "Chicago, IL",
                    "value": "7cv00DwsDogAwMAJrabgrw=="
                },
                {
                    "text": "Columbia, MD",
                    "value": "UaBpY7Dft4ldY4e2Zb3W8A=="
                },
                {
                    "text": "Crownsville, MD",
                    "value": "tds0e1_wt4lD8Gl4tkPWrw=="
                },
                {
                    "text": "Dallas, TX",
                    "value": "S5dFe_cZTIaPZ0f2pJvsuQ=="
                },
                {
                    "text": "Dearing, KS",
                    "value": "OfJxMhSCt4eyx6-l5eqDwg=="
                },
                {
                    "text": "Edison, NJ",
                    "value": "maG-aH_Tw4nq1INvpsUr8g=="
                },
                {
                    "text": "Fort Meade, MD",
                    "value": "jdor14Tmt4l3A9bF4c3sbg=="
                },
                {
                    "text": "Hanover, MD",
                    "value": "CR8SmSTit4kd1ecDfu3Bcw=="
                },
                {
                    "text": "Laurel, MD",
                    "value": "0dxJ6BDdt4n8ks39Ll7NmA=="
                },
                {
                    "text": "Los Gatos, CA",
                    "value": "PwN3UzY0joCmjHSsAVNn7w=="
                },
                {
                    "text": "Moline, IL",
                    "value": "a0TjeKAw4ocnMg_Pp6fQLg=="
                },
                {
                    "text": "New York, NY",
                    "value": "Owg_06VPwoli_nfhBo8LyA=="
                },
                {
                    "text": "Ohio, IL",
                    "value": "4a34ENmeCYiVXj8uMgu1Jg=="
                },
                {
                    "text": "San Jose, CA",
                    "value": "9T_5iuTKj4B7cZ_KCoyduQ=="
                },
                {
                    "text": "San Mateo, CA",
                    "value": "RVWp72Cej4CnG8wt9PyO_Q=="
                },
                {
                    "text": "White Plains, NY",
                    "value": "2TWj4iKUwols_FsaEAQUVA=="
                },
                {
                    "text": "Wilmington, DE",
                    "value": "b69GXBgPx4kAjDB3UNoWhQ=="
                }
            ]
        },
        {
            "type": "Date posted",
            "param": "date_posted",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Past day",
                    "value": "today"
                },
                {
                    "text": "Past 3 days",
                    "value": "3days"
                },
                {
                    "text": "Past week",
                    "value": "week"
                },
                {
                    "text": "Past month",
                    "value": "month"
                }
            ]
        },
        {
            "type": "Requirements",
            "param": "requirements",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "No degree",
                    "value": "no_degree"
                },
                {
                    "text": "No experience",
                    "value": "no_experience"
                },
                {
                    "text": "Under 3 years of experience",
                    "value": "years3under"
                },
                {
                    "text": "3+ years of experience",
                    "value": "years3plus"
                }
            ]
        },
        {
            "type": "Type",
            "param": "employment_type",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Full-time",
                    "value": "FULLTIME"
                },
                {
                    "text": "Contractor",
                    "value": "CONTRACTOR"
                },
                {
                    "text": "Internship",
                    "value": "INTERN"
                },
                {
                    "text": "Part-time",
                    "value": "PARTTIME"
                }
            ]
        },
        {
            "type": "Company type",
            "param": "industry.id",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Computer Services",
                    "value": "/business/naics2007/5415"
                },
                {
                    "text": "Information",
                    "value": "/business/naics2007/51"
                },
                {
                    "text": "Consulting",
                    "value": "/business/naics2007/5416"
                },
                {
                    "text": "Health Care",
                    "value": "/business/naics2007/62"
                },
                {
                    "text": "Finance",
                    "value": "/business/naics2007/52"
                },
                {
                    "text": "Manufacturing",
                    "value": "/business/naics2007/31"
                },
                {
                    "text": "Rental",
                    "value": "/business/naics2007/532"
                }
            ]
        },
        {
            "type": "Employer",
            "param": "organization_mid",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Google",
                    "value": "/m/045c7b"
                },
                {
                    "text": "ARSIEM",
                    "value": "/g/11fy22b_1s"
                },
                {
                    "text": "Amazon Web Services, Inc.",
                    "value": "/m/0rznzt1"
                },
                {
                    "text": "Base-2 Solutions",
                    "value": "/g/11gxm4c0tt"
                },
                {
                    "text": "NiSUS Technologies Corporation",
                    "value": "/g/11g705zkln"
                },
                {
                    "text": "Amazon.com Services LLC",
                    "value": "/g/11f00sjtl5"
                },
                {
                    "text": "CACI",
                    "value": "/m/0310bt"
                },
                {
                    "text": "Elevance Health",
                    "value": "/m/04xtkp"
                },
                {
                    "text": "IntelliGenesis LLC",
                    "value": "/g/11c73hfqj8"
                },
                {
                    "text": "Raytheon Technologies",
                    "value": "/g/11c6qvm0kj"
                },
                {
                    "text": "Snowflake Computing",
                    "value": "/g/11b8krtt2g"
                },
                {
                    "text": "Avid Technology Professionals, LLC",
                    "value": "/g/11g9n060lk"
                },
                {
                    "text": "Booz Allen Hamilton",
                    "value": "/m/05jlg3"
                },
                {
                    "text": "BrainTrust Holdings",
                    "value": "/g/11fy267mw4"
                },
                {
                    "text": "Castaway Research",
                    "value": "/g/11jp54p9k7"
                },
                {
                    "text": "JPMorgan Chase",
                    "value": "/m/01hlwv"
                },
                {
                    "text": "Johnson Technology Systems Inc.",
                    "value": "/g/11f7p9xc6j"
                },
                {
                    "text": "Keylent",
                    "value": "/g/11rvbr_y2l"
                },
                {
                    "text": "ManTech International",
                    "value": "/m/03crmnd"
                },
                {
                    "text": "Netflix",
                    "value": "/m/017rf_"
                },
                {
                    "text": "Novetta",
                    "value": "/g/11g9m_jqt2"
                },
                {
                    "text": "Open Systems Technologies",
                    "value": "/g/11b7c7x3lx"
                },
                {
                    "text": "Orion Consortium",
                    "value": "/g/11g9mp3gx4"
                },
                {
                    "text": "Rakuten USA, Inc.",
                    "value": "/g/11f00sztwj"
                },
                {
                    "text": "Super Micro Computer",
                    "value": "/m/03p3m28"
                },
                {
                    "text": "Synechron Inc.",
                    "value": "/m/027hdqs"
                },
                {
                    "text": "The DarkStar Group",
                    "value": "/g/11fy1qp5kx"
                },
                {
                    "text": "Trigyn",
                    "value": "/m/0cp7t9v"
                },
                {
                    "text": "Triumph Tech",
                    "value": "/g/11ry5h_t46"
                },
                {
                    "text": "WayUp",
                    "value": "/g/11gfj67hvn"
                },
                {
                    "text": "Inforeliance",
                    "value": "/g/1dv3111b"
                }
            ]
        }
    ]
}
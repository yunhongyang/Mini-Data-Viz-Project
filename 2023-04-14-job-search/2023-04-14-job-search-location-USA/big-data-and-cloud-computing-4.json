{
    "search_metadata": {
        "id": "643db9a9f55d779be0f9822e",
        "status": "Success",
        "json_endpoint": "https://serpapi.com/searches/b9a465714e5f8532/643db9a9f55d779be0f9822e.json",
        "created_at": "2023-04-17 21:27:05 UTC",
        "processed_at": "2023-04-17 21:27:05 UTC",
        "google_jobs_url": "https://www.google.com/search?q=big+data+and+cloud+computing&ibp=htl;jobs&uule=w+CAIQICINVW5pdGVkIFN0YXRlcw&hl=en&gl=us&start=40",
        "raw_html_file": "https://serpapi.com/searches/b9a465714e5f8532/643db9a9f55d779be0f9822e.html",
        "total_time_taken": 2.7
    },
    "search_parameters": {
        "q": "big data and cloud computing",
        "engine": "google_jobs",
        "uule": "w+CAIQICINVW5pdGVkIFN0YXRlcw",
        "google_domain": "google.com",
        "hl": "en",
        "gl": "us",
        "start": 40
    },
    "jobs_results": [
        {
            "title": "Cloud Software Engineer 2 - Security Clearance Required",
            "company_name": "Raytheon Technologies",
            "location": "  Annapolis, MD   ",
            "via": "via FOX44 News Jobs",
            "description": "Date Posted:2023-02-08-08:00\n\nCountry:United States of America...\n\nLocation:MD233: 420 National Business Parkway 420 National Business Parkway Suite 400, Annapolis Junction, MD, 20701 USA\n\nPosition Role Type:Onsite\n\nRaytheon CODEX\n\nRaytheon Technologies' CODEX (Cyber Offense and Defense EXperts) division brings together an elite team of mission-focused experts who are well known for their ability to overcome the most advanced technical challenges. The team comprises of multiple disciplines including vulnerability research, reverse engineering, CNO development, hardware emulation, system engineering, data analytics, cloud development, infrastructure design and development, and test engineering.\n\nCODEX Culture\n\nHere at CODEX, we are passionate about technical excellence and innovation. That's why we only take on work that is hard, engaging and meaningful. We foster an environment where pushing the limits of our technical ability is the norm. Occasional failure does not deter us. True innovation comes from trying new things and seeing what works. We strive to create a relaxed culture with an unmatched rate of mission results.\n\nBenefits\n\nIn addition to competitive salaries, CODEX offers excellent benefits for you and your family: competitive medical, dental and vision plans, child, elderly and dependent-care programs, mental health resources, tuition assistance, employee discount programs, 401k matching, flexible work schedules (depending on program), a peer recognition and reward system and bonuses.\n\nPosition Details- Cloud Software Engineer 2\n\nThe Cloud Software Engineer (CSW2) develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements. The ideal candidate will directly contributes to all stages of back-end processing, analyzing, and indexing.\n\nYou will Provide expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\nPosition Requirements:\n\nTypically requires Bachelor's degree in Computer Science or related discipline from an accredited college or university and eight (8) years' experience in software engineering on programs and contracts of similar scope, type, and complexity.\n\nTwo (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\nClearance Requirements: This position requires a TS/SCI w/current polygraph.\n\n#CODEXTB #CODEXBLITZ #S5TB #CODEX\n\nEmployee Referral Award Eligibility: Only employees currently within RMD and RI&S have the potential to receive a Referral Award for submitting a referral to RMD and RI&S roles. ALL eligibility requirements must be met to receive the Referral Awarding.\n\nRaytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\n\n.\n\nRaytheon Technologies is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\n\nPrivacy Policy and Terms:\n\nClick on this link to read the Policy and Terms",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Typically requires Bachelor's degree in Computer Science or related discipline from an accredited college or university and eight (8) years' experience in software engineering on programs and contracts of similar scope, type, and complexity",
                        "Two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Clearance Requirements: This position requires a TS/SCI w/current polygraph"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Software Engineer (CSW2) develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "The ideal candidate will directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "You will Provide expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "In addition to competitive salaries, CODEX offers excellent benefits for you and your family: competitive medical, dental and vision plans, child, elderly and dependent-care programs, mental health resources, tuition assistance, employee discount programs, 401k matching, flexible work schedules (depending on program), a peer recognition and reward system and bonuses",
                        "Employee Referral Award Eligibility: Only employees currently within RMD and RI&S have the potential to receive a Referral Award for submitting a referral to RMD and RI&S roles"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.rtx.com/",
                    "text": "rtx.com"
                },
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Raytheon+Technologies&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIIzAk",
                    "text": "See web results for Raytheon Technologies"
                }
            ],
            "extensions": [
                "7 days ago",
                "Full-time",
                "Health insurance",
                "Dental insurance"
            ],
            "detected_extensions": {
                "posted_at": "7 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciAyIC0gU2VjdXJpdHkgQ2xlYXJhbmNlIFJlcXVpcmVkIiwiaHRpZG9jaWQiOiJfc1dQdlhfTHB4TUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFc3dDQ293Q1FVVnpOMnBPVTFBNFdUUkRUM0l0TFdWcE5uTm1XbEF5TjFCRlN6a3haMkZGT0V4eU0yOVpia3M0ZUZKeFptUmtSbFo1UkhKVU1HNXhialJrVFU5NmFteExibGR1VGxFMmJtMVNURU5FYzBzMlYzcG1hMVI1YTBWSGFGQlJhbk5VU0c5Q2VYaE9aVFk1ZFRWc1ZXeGZWak5sYVV0bWNETlhWalJQTmtwU1FWWnROMVIwVjNSa1UwSmtkRzVmTkRZeU1FcFdVRll0WjBkRWEyVmlaVkpGTkZOQ09FRTBWa2xMWkVseFQxVllObTFUYlRObmFUbEtWMkZ5TFhSU1JVMDFhM2N0UkRaTE5VSmFUMFEwTkU5QmNEVkdTSE5uYWxKQ1VYTlVRakZsU0dOTExUUkNjVmhJTlhGb1NHWTRXbVY1Tlhnd1VUTlZkbUp0TlhwaU5VdDBiSFJVTW5JNFduWTBZWFJEZVJJWGNUZHJPVnBOV0dwQ0xVOXNOVTV2VUhkak5tRXRRVFFhSWtGUExUQnliRFppWWpKQ1RqZHpZMmMwUXpKNU5HTkZPVTlFUkZOMFltVTJSbEUiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6Ii5uRmcyZWJ7Zm9udC13ZWlnaHQ6NTAwfS5CaTZEZGN7Zm9udC13ZWlnaHQ6NTAwfUFwcGx5IG9uIEZPWDQ0IE5ld3MgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMuZm94NDRuZXdzLmNvbS9qb2JzL2Nsb3VkLXNvZnR3YXJlLWVuZ2luZWVyLTItc2VjdXJpdHktY2xlYXJhbmNlLXJlcXVpcmVkLWFubmFwb2xpcy1tYXJ5bGFuZC85NzM2OTIxNDctMi8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Cloud Software Engineer",
            "company_name": "WayUp",
            "location": "  Washington, DC   ",
            "via": "via JobLeads",
            "description": "Candidates must sit in the Washington DC metro area and must be US Citizens due to the nature of work performed.\n\nSecurity Clearance: Active TS/SCI FS Poly is required at the time of hire. Candidates with clearance that has been inactive for less than 2 years, will also be considered...\n\nOur Client, a software consultancy company heavily integrated with the Department of Defense, Intelligence and Civilian agencies is seeking an experienced Cloud Software Engineer\n\nWhat You'll Do:\n\u2022 The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements.\n\u2022 Directly contributes to all stages of back-end processing, analyzing, and indexing. Provides expertise in Cloud Computing, and Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\u2022 Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nWhat You'll Need:\n\u2022 Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required.\n\u2022 Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree.\n\u2022 Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\u2022 Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 Ingesting, Parsing, and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Security Clearance: Active TS/SCI FS Poly is required at the time of hire",
                        "Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelor's degree in computer science or related discipline from an accredited college or university is required",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree",
                        "Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing, and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based on documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, and Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.wayup.com/",
                    "text": "wayup.com"
                },
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=WayUp&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIIkgo",
                    "text": "See web results for WayUp"
                }
            ],
            "extensions": [
                "6 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "6 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciIsImh0aWRvY2lkIjoiQ0Jyb2xVYl8ydWtBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WVzVwZEdWa0lGTjBZWFJsY3ciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVVZ6TjJwT1UyaGxZbDlUT1VreWRuZDRia3BQUm5SYVRYZGFSRGR6T0hCMFdtSlNTRWMwY2xvdFdqWTJaVk0wWlRFdGVtd3piams1ZVdReWFrZ3hTRFZ2U0dKSFh6RlphbE5QUWtKM1IxcHdiVUpEWkdkeGFrOUVXVll6WWxkTlNtcDZOR1kzWHpKMVdrODVhV2xIWDBWYUxYaHdiRFpvTWtzNFNXMXJUalZoYm05dGRtSXdkelpHVUdwVU1XSnNRbDlPWlVsQlVUaE5kSEpvUm1GVlZrcHFjMGN4Y0ZaSk5IVkxhWHBuYlVWUFkwSkhhbWRSRWhkeE4yczVXazFZYWtJdFQydzFUbTlRZDJNMllTMUJOQm9pUVU4dE1ISnNOREU1ZEd4bWJrMWZiVWhtWVRsbWJXcG9aM05LYnpORWRsVlFVUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzMiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9iTGVhZHMiLCJsaW5rIjoiaHR0cHM6Ly93d3cuam9ibGVhZHMuY29tL2VuLXVzL2pvYi9lMWFiY2M2MzI4NmJmYTliNjQ5OTA1YTE0YWNkODllZTc/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Senior Cloud Solutions Architect Secret Clearance",
            "company_name": "inforeliance",
            "location": "  Washington, DC   ",
            "via": "via WayUp",
            "description": "InfoReliance is hiring!!!\n\nSenior Cloud Solutions Architect (Active Secret Clearance...\n\nLocation: Washington, DC Metro Area\n\nRequirements: US Citizenship & Minimum Secret Clearance\n\nIn order to meet the evolving needs of Federal Government, InfoReliance, an IT Consulting company founded in 2000, invested early to develop advanced analytics capabilities in Cloud Computing to remain competitive and has the expertise to help our customers achieve their goals and meet new Cloud-First mandates. Today, we stand out as a Cloud Leader.\n\nInfoReliance is an AWS Premier Partner, AWS Managed Service Provider, and AWS Approved Reseller. We are also a certified Microsoft Cloud Deployment Partner and regularly team with MCS to offer customers total confidence in migration to Office 365. InfoReliance is also member of the Microsoft Azure Circle partner program, able to assist customers in adopting IaaS and PaaS cloud solutions. Additionally, InfoReliance is a Google Partner.\n\nWE NOW HAVE AN EXCITING OPPORTUNITY FOR A SENIOR CLOUD SOLUTIONS ARCHITECT-SUBJECT MATTER EXPERT TO JOIN OUR TEAM\n\u2022 Responsible for collaborating on and setting cloud vision; providing thought leadership in cloud infrastructure and cloud services architecture to meet client's operational objectives for cloud solutions.\n\u2022 Consulting with our clients as a cloud technology evangelist around Cloud technologies including IaaS, SaaS, PaaS, Public/Hybrid/Community Cloud Service Provider offerings to develop advanced analytics solutions to solve real-world problems.\n\u2022 Designing technical architecture for cloud analytics solutions that meet customer needs for scalability, reliability and performance.\n\u2022 Identifying new cloud technologies and platforms to help solve technical challenges or limitations in the existing infrastructure.\n\u2022 The Senior Cloud Solution Architect is responsible, with our established team of SMEs, change managers, integration engineers, system engineers and business analysts, for discovery and assessment of the current environment, proposing architectures, and implementing solutions for our client and its sub-agencies to consume services from the cloud.\n\u2022 This role will serve as an advanced analytics solution architect providing strategic and technical leadership for client teams migrating, developing, or enriching applications in the cloud.\n\u2022 The Senior Cloud Solution Architect is responsible for supporting multiple customers to evaluate customers\u2019 current and anticipated needs, develop innovative solutions, support technical proposals, develop architectures, and evaluate cloud implementations according to industry best practices and standards.\n\nEssential Responsibilities\n\u2022 Provide thought and technical design leadership to cloud analytics solutions using cloud native and third party software.\n\u2022 Serve as a technical SME for big data, analytics, cloud services, providers, and platforms.\n\u2022 Act as a change agent for advanced analytics technologies and supporting processes to maximize results measured by performance and availability, business agility, technology freshness, and cost optimization.\n\u2022 Lead cloud application architecting/designing sessions with business partners evaluating tradeoffs between design, risk, and technology.\n\u2022 Execute prototypes and technical feasibility assessments for cloud analytics solutions.\n\u2022 Apply advanced technical knowledge and skills in developing solutions or problem solving where complexity, innovation and technical expertise are required.\n\nAS PART OF THE CLOUD SOLUTION TEAM, CANDIDATE WOULD FOCUS ON SOLUTION AND DEVELOPMENT:\n\u2022 Through various communication vehicles and methods (e.g., meetings, application demos, emails, workshops, etc.) develop, innovate and implement technical solutions for cloud projects including high performance computing, advanced analytics and big data.\n\u2022 Engage with the client to secure buy-in for the adoption of cloud-based solutions, through workshops and briefs as necessary.\n\u2022 Recommend technology strategy by understanding key client objectives; diagnosing and mapping client requirements; articulating solution risks and barriers; recommending delivery approaches; preparing time estimates; planning full project life cycle.\n\u2022 Develop, contribute, and evaluate technical proposals related to cloud analytics projects and implementations.\n\u2022 Provide expertise to construct the architecture and solutions to support current and future business needs, and to ensure the successful implementation and adoption of service.\n\u2022 Develop and implement activities, such as but not limited to, sequencing, architecture, assumptions, dependencies and customer buy-in that shall include an end-to-end view of the overall implementation approach to design and develop innovative analytics systems with cloud platform services.\n\u2022 Throughout the projects, you will participate in status meetings on progress, priorities, issues, performance issues, and future work.\n\nIN ORDER TO BE SUCCESSFUL IN THIS ROLE, WE EXPECT THAT QUALIFIED CANDIDATES WILL HAVE THE FOLLOWING SKILLS, EXPERIENCE, AND CREDENTIALS:\n\u2022 Minimum of 8 years enterprise IT application experience, including at least 3 years of architecting strategic, scalable BI, Big Data solutions, and data analytics.\n\u2022 Experience dealing with Federal government is necessary (must have, preference given to Law Enforcement experience).\n\u2022 Ability to understand \u201cBig Data\u201d use cases , and develop business outcome driven use-cases and what it means for both compute and storage resources in order to recommend the appropriate server and storage required in a Hadoop deployment\n\u2022 Hands-on with \u201cBig Data\u201d technologies with the Hadoop stack (e.g. Spark,MapReduce, Hive, Streaming) and practical experience that allows you distinguish between the implementation reality and the hype!\n\u2022 Minimum a Bachelor's degree in Computer Science, Information Systems Management or similar preferred.\n\u2022 Senior level with more then 10+ years of hands-on planning, designing, and engineering enterprise class systems and services.\n\u2022 Plan and establish Hadoop technology standards and usage frameworks within the BI Department.\n\u2022 Knowledge of data conversion strategy, capturing data, creating source to target definitions for ETL/ data flow process, data quality and data base management\n\u2022 Knowledge of image processing and image analytics including video analytics\n\u2022 Knowledge of AWS and Google analytics platforms\n\u2022 Work in concert with a team of ETL developers to ensure efficient and accurate data transfer within the entire EDW echo system with Big Data Platforms.\n\u2022 Build and optimize information models, physical data layouts, configuration, optimization and monitoring Hadoop environments and improve overall processing efficiencies to support the needs of the business.\n\u2022 In depth knowledge and hands on experience with the full range of cloud service providers/solutions, inclusive of AWS and Microsoft Azure offerings.\n\u2022 Amazon Web Services (AWS) Solutions Architect certifications (Associate or Professional) (or demonstrated ability and willingness to achieve certification shortly after hire).\n\u2022 * Must have proven success in consulting to CTO-level clients.\n\u2022 Proven experience in assessment, evaluation, and documentation of client environment, infrastructure, processes, and operations.\n\u2022 Proven experience in communicating and demonstrating the value of cloud solutions to a variety of stakeholders to address complex and competing drivers in complex technical environments, with a track record of buy-in and successful implementation, migration, change management, and full adoption.\n\u2022 Proven ability to lead change across large platforms using innovative technology solutions with federal government and commercial sectors.\n\u2022 Demonstrated abilities in strategic thinking and leadership with strong relationship management ability.\n\u2022 Demonstrated experience automating production cloud workloads.\n\u2022 Knowledge and experience with analytics tools and platforms including Apache Spark, Hive, Presto, HBase, Kafka, MongoDB etc.\n\u2022 Strong scripting skills (Python, Ruby, Perl, Bash, Powershell, etc.)\n\u2022 Strong knowledge of IP Networking including VPC's, VPN's, VRF, DNS, load-balancing, and firewalls.\n\u2022 Demonstrated experience with the Software Development Lifecycle.\n\u2022 Understanding of Service-Oriented Architecture (SOA and REST).\n\u2022 Proven ability to lead change across large platforms / functional areas using innovative technology solutions.\n\u2022 Demonstrated customer focus.\n\u2022 Strong analytical and strong real problem solving skills (not on paper only).\n\u2022 Communicates clearly and effectively evaluates information to make decisions.\n\u2022 Must have previous and strong experience in presentation and writing.\n\u2022 Anticipates risks and obstacles and develops plans for mitigation.\n\u2022 Creates actionable strategies and operational plans.\n\u2022 Champions and drives change initiatives.\n\u2022 Confronts difficult problems in a positive and creative way.\n\u2022 Balances multiple and competing priorities and executes accordingly",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum of 8 years enterprise IT application experience, including at least 3 years of architecting strategic, scalable BI, Big Data solutions, and data analytics",
                        "Experience dealing with Federal government is necessary (must have, preference given to Law Enforcement experience)",
                        "Ability to understand \u201cBig Data\u201d use cases , and develop business outcome driven use-cases and what it means for both compute and storage resources in order to recommend the appropriate server and storage required in a Hadoop deployment",
                        "Hands-on with \u201cBig Data\u201d technologies with the Hadoop stack (e.g",
                        "Spark,MapReduce, Hive, Streaming) and practical experience that allows you distinguish between the implementation reality and the hype!",
                        "Senior level with more then 10+ years of hands-on planning, designing, and engineering enterprise class systems and services",
                        "Plan and establish Hadoop technology standards and usage frameworks within the BI Department",
                        "Knowledge of image processing and image analytics including video analytics",
                        "Knowledge of AWS and Google analytics platforms",
                        "In depth knowledge and hands on experience with the full range of cloud service providers/solutions, inclusive of AWS and Microsoft Azure offerings",
                        "Amazon Web Services (AWS) Solutions Architect certifications (Associate or Professional) (or demonstrated ability and willingness to achieve certification shortly after hire)",
                        "Must have proven success in consulting to CTO-level clients",
                        "Proven experience in assessment, evaluation, and documentation of client environment, infrastructure, processes, and operations",
                        "Proven ability to lead change across large platforms using innovative technology solutions with federal government and commercial sectors",
                        "Demonstrated abilities in strategic thinking and leadership with strong relationship management ability",
                        "Demonstrated experience automating production cloud workloads",
                        "Knowledge and experience with analytics tools and platforms including Apache Spark, Hive, Presto, HBase, Kafka, MongoDB etc",
                        "Strong scripting skills (Python, Ruby, Perl, Bash, Powershell, etc.)",
                        "Strong knowledge of IP Networking including VPC's, VPN's, VRF, DNS, load-balancing, and firewalls",
                        "Demonstrated experience with the Software Development Lifecycle",
                        "Demonstrated customer focus",
                        "Strong analytical and strong real problem solving skills (not on paper only)",
                        "Communicates clearly and effectively evaluates information to make decisions",
                        "Must have previous and strong experience in presentation and writing",
                        "Confronts difficult problems in a positive and creative way"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Responsible for collaborating on and setting cloud vision; providing thought leadership in cloud infrastructure and cloud services architecture to meet client's operational objectives for cloud solutions",
                        "Consulting with our clients as a cloud technology evangelist around Cloud technologies including IaaS, SaaS, PaaS, Public/Hybrid/Community Cloud Service Provider offerings to develop advanced analytics solutions to solve real-world problems",
                        "Designing technical architecture for cloud analytics solutions that meet customer needs for scalability, reliability and performance",
                        "Identifying new cloud technologies and platforms to help solve technical challenges or limitations in the existing infrastructure",
                        "The Senior Cloud Solution Architect is responsible, with our established team of SMEs, change managers, integration engineers, system engineers and business analysts, for discovery and assessment of the current environment, proposing architectures, and implementing solutions for our client and its sub-agencies to consume services from the cloud",
                        "This role will serve as an advanced analytics solution architect providing strategic and technical leadership for client teams migrating, developing, or enriching applications in the cloud",
                        "The Senior Cloud Solution Architect is responsible for supporting multiple customers to evaluate customers\u2019 current and anticipated needs, develop innovative solutions, support technical proposals, develop architectures, and evaluate cloud implementations according to industry best practices and standards",
                        "Provide thought and technical design leadership to cloud analytics solutions using cloud native and third party software",
                        "Serve as a technical SME for big data, analytics, cloud services, providers, and platforms",
                        "Act as a change agent for advanced analytics technologies and supporting processes to maximize results measured by performance and availability, business agility, technology freshness, and cost optimization",
                        "Lead cloud application architecting/designing sessions with business partners evaluating tradeoffs between design, risk, and technology",
                        "Execute prototypes and technical feasibility assessments for cloud analytics solutions",
                        "Apply advanced technical knowledge and skills in developing solutions or problem solving where complexity, innovation and technical expertise are required",
                        "Through various communication vehicles and methods (e.g., meetings, application demos, emails, workshops, etc.) develop, innovate and implement technical solutions for cloud projects including high performance computing, advanced analytics and big data",
                        "Engage with the client to secure buy-in for the adoption of cloud-based solutions, through workshops and briefs as necessary",
                        "Recommend technology strategy by understanding key client objectives; diagnosing and mapping client requirements; articulating solution risks and barriers; recommending delivery approaches; preparing time estimates; planning full project life cycle",
                        "Develop, contribute, and evaluate technical proposals related to cloud analytics projects and implementations",
                        "Provide expertise to construct the architecture and solutions to support current and future business needs, and to ensure the successful implementation and adoption of service",
                        "Develop and implement activities, such as but not limited to, sequencing, architecture, assumptions, dependencies and customer buy-in that shall include an end-to-end view of the overall implementation approach to design and develop innovative analytics systems with cloud platform services",
                        "Throughout the projects, you will participate in status meetings on progress, priorities, issues, performance issues, and future work",
                        "Knowledge of data conversion strategy, capturing data, creating source to target definitions for ETL/ data flow process, data quality and data base management",
                        "Work in concert with a team of ETL developers to ensure efficient and accurate data transfer within the entire EDW echo system with Big Data Platforms",
                        "Build and optimize information models, physical data layouts, configuration, optimization and monitoring Hadoop environments and improve overall processing efficiencies to support the needs of the business",
                        "Creates actionable strategies and operational plans"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.ecstech.com/",
                    "text": "ecstech.com"
                },
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=inforeliance&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAII1Qo",
                    "text": "See web results for inforeliance"
                }
            ],
            "extensions": [
                "Full-time"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJTZW5pb3IgQ2xvdWQgU29sdXRpb25zIEFyY2hpdGVjdCBTZWNyZXQgQ2xlYXJhbmNlIiwiaHRpZG9jaWQiOiJJcUpLWmctcDh4OEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVVnpOMnBPVkcwd1kzRlpVRk5tYjI5QlltUnJPV3RSV25OUVZHSmpORlZ0VFZScFVXWmZMVUphTm10R1gyUkxjRTlpTkdKR1ZHRjRNbFpxTVZJM2RVMUNiblZzV1c1R1ZEQk9aRUpVZFV0MmMwYzJieTFrT0VsNmNUTnRibVZHYlRoSlV6ZG5abE5IVVVWd1IwOUtWMVZXVVc1S09EWTBaVzVoYUZsMFZuUnNRbGsxWmpadlVrNTZiRXBOUlVSUFFUWjJSMjAwUkRZNUxXcEROa1ZGU1ZKaFRrdHpSMHRwVkdWWFRTMWlOblJEUzNnd2NuaHdRVWxmUW1acWNGWldPVXB4TTNKbU1HdE1kMU5PZEhsM2RYRk5aakZaUWtKR1drZHpVSEEzU21KcFp4SVhjVGRyT1ZwTldHcENMVTlzTlU1dlVIZGpObUV0UVRRYUlrRlBMVEJ5YkRkWU1FcFdVVEYxUTFCck1rOTZTVkJ5TFVkSGJVRkJiVVJpVVhjIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBXYXlVcCIsImxpbmsiOiJodHRwczovL3d3dy53YXl1cC5jb20vaS1qLWluZm9yZWxpYW5jZS05NjU2NDY4NDc1Nzk1ODkvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Cloud Design Engineer",
            "company_name": "Novetta",
            "location": "  Annapolis Junction, MD   ",
            "via": "via Startup Jobs",
            "description": "Accenture Federal Services delivers a range of innovative, tech-enabled services for the U.S. Federal Government to address the complex, sensitive challenges of national security and intelligence missions.\n\nRefer a qualified candidate and earn up to $20K. Learn more here ...\nJob Description:\n\nAccenture Federal Services is seeking a Cloud Design Engineer to develop, maintain, and enhance complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements.\n\nResponsibilities include:\n\n\u2022 Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System\n\u2022 Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies\n\u2022 Implements Graphical Web-Based User Interface with usability, security, and performance in mind\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs\n\u2022 Provides in-depth knowledge of Information Retrieval (IR); assisting the software development team in designing, developing and testing Cloud IR\n\u2022 Propose new ways of analyzing data stored in Cloud Big Table and Cloud Distributed File System\n\nHere's what you need:\n\n\u2022 8+ years software engineering experience\n\u2022 2+ years experience utilizing Big-Data Cloud technologies and/or Distributed Computing\n\u2022 2+ years of Web-Based applications that retrieves/stores data in a Cloud Data System\n\u2022 2+ years of building applications that comply with modern Web 2.0 standards\n\u2022 2+ years of Cloud and/or Distributed Computing IR\n\u2022 1+ years working with data stored in Cloud Big Table\n\u2022 Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing\n\u2022 Interfacing with Cloud and Distributed Computing Technologies (at least one or a combination of the following areas):\n\u2022 Spring MVC\n\u2022 J2EE\n\u2022 HDFS\n\u2022 HBase\n\u2022 JMS\n\u2022 Concurrent Programming\n\u2022 Multi-Node implementation/installation\n\u2022 Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)\n\u2022 Bachelor's degree in Computer Science or related discipline, or 4 additional years of professional experience, in lieu of a degree\n\nSecurity Clearance:\n\n\u2022 Active TS/SCI with Polygraph\n\nCompensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience.\u202fAs required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and\u202finformation on benefits offered is here.\u202f\u202f\u202f\n\nRole Location: Range of Starting Pay for role\u202f\n\nCalifornia: $105,200 - $168,400\n\nColorado: $105,200 - $145,500\n\nNew York City: $121,700 - $168,400\n\nWashington: $112,100 - $154,900\n\nEligibility Requirements\n\nUS Citizenship required.\n\nImportant information\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services\n\nAccenture Federal Services is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. An active security clearance or the ability to obtain one may be required for this role. Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women. Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\n\nWhat We Believe\n\nWe have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment. Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here\n\nEqual Employment Opportunity Statement\n\nAccenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.\n\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women.\n\nFor details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.\n\nRequesting An Accommodation\n\nAccenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.\n\nIf you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.\n\nOther Employment Statements\n\nThe Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "8+ years software engineering experience",
                        "2+ years experience utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "2+ years of Web-Based applications that retrieves/stores data in a Cloud Data System",
                        "2+ years of building applications that comply with modern Web 2.0 standards",
                        "1+ years working with data stored in Cloud Big Table",
                        "Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing",
                        "Interfacing with Cloud and Distributed Computing Technologies (at least one or a combination of the following areas):",
                        "Spring MVC",
                        "J2EE",
                        "HDFS",
                        "Multi-Node implementation/installation",
                        "Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)",
                        "Bachelor's degree in Computer Science or related discipline, or 4 additional years of professional experience, in lieu of a degree",
                        "Active TS/SCI with Polygraph",
                        "US Citizenship required",
                        "Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System",
                        "Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies",
                        "Implements Graphical Web-Based User Interface with usability, security, and performance in mind",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs",
                        "Provides in-depth knowledge of Information Retrieval (IR); assisting the software development team in designing, developing and testing Cloud IR",
                        "Propose new ways of analyzing data stored in Cloud Big Table and Cloud Distributed File System"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Compensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience. As required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and information on benefits offered is here.",
                        "Role Location: Range of Starting Pay for role",
                        "California: $105,200 - $168,400"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.novetta.com/",
                    "text": "novetta.com"
                },
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Novetta&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIIlgs",
                    "text": "See web results for Novetta"
                }
            ],
            "extensions": [
                "Full-time"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBEZXNpZ24gRW5naW5lZXIiLCJodGlkb2NpZCI6InZURUp6cVBFR0RjQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVVWek4ycE9VVlJOWW5OelZGOTBlbWhLYW1wNmRVWnViM0JOUXpkb1VGcGtWRFZFVkdOb1VVMTFiMVZwVjFkMFRFeHllbmgzY1dwYU4zSm9XbGhJZVdWb1JqZHpUMGRRYzNSd1ZVZDJjM1J1Ums5NU5IWm1abmwxZUVkR2RVaFRNbmREWTBwalZVTTBNVTlEUVhoT2QwUnhjRWs0VTNOMlVYTlZTekZQYnpoTE1HRlFVM2sxT0ZkU1VVMUdkRnBHWjBKT00yd3RjMDU0VjFsRFZuUjFjMnN4UjJWUGRWTlVkRzU0Y0dWTGJXRXRkelJMZFhsMlRFSTRWM0Y2YWxaNGVFZEROVTlmZFdRMFVrczFFaGR4TjJzNVdrMVlha0l0VDJ3MVRtOVFkMk0yWVMxQk5Cb2lRVTh0TUhKc05FcEpVbVJTUTI1cVVIbFdVbUZUTjBWMWNWSlhWV1V6WlRRdFp3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTdGFydHVwIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9zdGFydHVwLmpvYnMvY2xvdWQtZGVzaWduLWVuZ2luZWVyLW5vdmV0dGEtMzc3NTIzMj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        },
        {
            "title": "Sr. SDE",
            "company_name": "Amazon.com Services LLC",
            "location": "  Palo Alto, CA   ",
            "via": "via Palo Alto, CA - Geebo",
            "description": "Amazon Web Services (AWS) provides companies of all sizes with an infrastructure web services platform in the cloud.\nWith AWS, you can requisition compute power, , and other services - paying as you go for only the resources you need.\nThis role will be focused on building a new V1 service...\nAWS Glue.\nAWS provides a collection of rapidly growing Big Data services designed for the cloud that span the gamut from EMR to Redshift to RDS Aurora.\nThese services manage all the work needed to set up, operate, and scale data services ranging from big data platforms to data warehouses to operational databases.\nBy automating tedious, labor-intensive administrative tasks, these services enable customers to spend their time focusing on their data and business insights.\nThe AWS Glue team provides a scalable, resilient, highly performant and secure data platform and infrastructure for users running Business Intelligence, Analytics and ML applications.\nThe team is responsible for data orchestration and workflow management service, metadata platform with Glue catalog (lineage, discovery, search, annotations), services that move data around (Apache Spark SQL, data ingestion and dispersal), streaming and batch querying systems (based on Spark SQL and Spark structured streaming), advanced data processing platforms (based on Spark SQL and ML, and other Data Science tools), Data Warehousing, and security (using AWS Lake Formation), and the underlying and resource management infrastructure (with serverless Apache Spark, Amazon S3, Apache Yarn and HDFS).\nJoining the AWS Glue gives you the opportunity to:\nWork on a disruptive product that's still in its early stages Solve challenging problems that will revolutionize computing in the cloud Build a product that will leverage the scale of resources available in the cloud Work for a company that's a recognized leader in the cloud computing space Be involved in the fast growing, big data space We are looking for developers with expertise and passion for building large-scale data-intensive systems and distributed systems.\nIn particular, we are looking for developers that want to work on the next generation big data systems that will transform data management on AWS and across the industry.\nExperience with large scale data analytics, big data platforms, highly available/fault tolerant systems, replicated data , and operating complex services running in the cloud are all pluses.\nIn this role, you will have responsibility for:\nTranslating functional and technical requirements into detailed architecture and design Coding and testing complex system components Participating in code and design reviews to maintain our high development standards Working with other teams to deliver and operate large scale, distributed services in the cloud Overall system architecture, scalability, reliability, and performance Mentoring other engineers, defining our challenging technical culture, and helping to build a fast-growing team.\nEstimated Salary: $20 to $28 per hour based on qualifications",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Experience with large scale data analytics, big data platforms, highly available/fault tolerant systems, replicated data , and operating complex services running in the cloud are all pluses"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "These services manage all the work needed to set up, operate, and scale data services ranging from big data platforms to data warehouses to operational databases",
                        "By automating tedious, labor-intensive administrative tasks, these services enable customers to spend their time focusing on their data and business insights"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Estimated Salary: $20 to $28 per hour based on qualifications"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Amazon.com+Services+LLC&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAII0As",
                    "text": "See web results for Amazon.com Services LLC"
                }
            ],
            "extensions": [
                "4 days ago",
                "20\u201328 an hour",
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "posted_at": "4 days ago",
                "schedule_type": "Full-time",
                "salary": "20\u201328 an hour"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJTci4gU0RFIiwiaHRpZG9jaWQiOiJHb2lDemNhWEJiQUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdmNCQ3JjQlFVVnpOMnBPVkdaRFYzUktRbk5xUkZseVgyRnVkVTFSWTFoTFgxQnhaSHBmZFdScE1FOW1WMkpvU1Y5M1NXZFFTVTVTWlZoQ1ozcDFWM0Z5ZEd4alVIcExibUpxTnpJMlVraDFNWFY1VnpkNE1YZHZkbTVHYTIweFRIazNZbEp6ZUZabllrNWxkalJMT0VSU1JVbFFNMko2UzA1eloxSjZabDlOZDBwQk9UUlZaRk01YVhwTWEwc3hkMjFFY0ROR1QzUmtiR1JLYlVORk1YWnFUV1ZqTTFCSFJqSlZVbWh5YjFwb2FrWmlXVlpYV0hwd00yTlJFaGR4TjJzNVdrMVlha0l0VDJ3MVRtOVFkMk0yWVMxQk5Cb2lRVTh0TUhKc04wcERVMGRIZGxKc1J6ZExTR2hxTTFFd2QyMXhTRU0yUTI1UVVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfOSIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBQYWxvIEFsdG8sIENBIC0gR2VlYm8iLCJsaW5rIjoiaHR0cHM6Ly9wYWxvYWx0by1jYS5nZWViby5jb20vam9icy1vbmxpbmUvdmlldy9pZC83ODIxNTQyMzUtc3Itc2RlLS8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Technical Lead/Architect (Big data Lead with GCP)",
            "company_name": "Zortech Solutions",
            "location": "  San Francisco, CA   ",
            "via": "via Big Country Jobs",
            "description": "Role: Technical Lead/Architect (Big data Lead with GCP)\n\nLocation: CA (Bay Area) Onsite...\n\nDuration: Fulltime\n\nJob Description\n\u2022 Mostly GC or Citizens\n\u2022 Will check and confirm on the H1T but start working now pls\nMinimum Qualifications\n\u2022 Experience with cloud computing concepts such as Big Data, PaaS and IaaS technologies; Experience presenting and delivering technical pitches.\n\u2022 10 years of experience in an analytics or cloud computing environment.\n\u2022 Experience in analytics as it relates to Business Intelligence, Big Data Warehousing, Data Modeling, Data Integration, Data Governance, Data Observability tools.\n\u2022 Have practical/hands-on experience with implementing Big Query in customer environments.\n\u2022 Experience in creating and reviewing Technical Documentation and deep technical assets.\nPreferred Qualifications\n\u2022 Experience with Looker or similar Business Intelligence solutions; Experience with one or more of the following: Hadoop, Spark, Flume, Hive, Impala, SQL, Big Query.\n\u2022 Advanced data modeling expertise, and experience in numerical analysis; Experience manipulating datasets (e.g., SQL, Google BigQuery)\n\u2022 Experience with integrating multiple BI & data integration tools with BigQuery.\n\u2022 Experience with networking concepts including: routing, VPNs, load balancers and firewalls.\n\u2022 Experience architecting and developing software or infrastructure for scalable, distributed systems\nCPE Strategic Work\n\u2022 Help customer deals that has tech / ISV partner dependency\n\u2022 Help partners with GCP onboarding\n\u2022 SME to help ISVs address Data cloud questions and best practices\n\u2022 Coordinating activities across multiple Google & partner teams\n\u2022 Documenting learnings and producing reusable technical documents\n\u2022 Work on technical proof of concepts of partner + google joint/integrated solutions\nOther Work\n\u2022 Manage Simba drivers release cycle\n\u2022 Evaluate/test new features like BYOID, BQ Omni, BI engine support into partner products\n\u2022 Incorporate new features in Google Cloud Ready - Big Query test cases\n\u2022 Validate if features work with the partner products",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Experience with cloud computing concepts such as Big Data, PaaS and IaaS technologies; Experience presenting and delivering technical pitches",
                        "10 years of experience in an analytics or cloud computing environment",
                        "Experience in analytics as it relates to Business Intelligence, Big Data Warehousing, Data Modeling, Data Integration, Data Governance, Data Observability tools",
                        "Have practical/hands-on experience with implementing Big Query in customer environments",
                        "Experience in creating and reviewing Technical Documentation and deep technical assets"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Will check and confirm on the H1T but start working now pls",
                        "Help customer deals that has tech / ISV partner dependency",
                        "Help partners with GCP onboarding",
                        "SME to help ISVs address Data cloud questions and best practices",
                        "Coordinating activities across multiple Google & partner teams",
                        "Documenting learnings and producing reusable technical documents",
                        "Work on technical proof of concepts of partner + google joint/integrated solutions",
                        "Manage Simba drivers release cycle",
                        "Evaluate/test new features like BYOID, BQ Omni, BI engine support into partner products",
                        "Incorporate new features in Google Cloud Ready - Big Query test cases",
                        "Validate if features work with the partner products"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Zortech+Solutions&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIIkww",
                    "text": "See web results for Zortech Solutions"
                }
            ],
            "extensions": [
                "14 days ago",
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "posted_at": "14 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJUZWNobmljYWwgTGVhZC9BcmNoaXRlY3QgKEJpZyBkYXRhIExlYWQgd2l0aCBHQ1ApIiwiaHRpZG9jaWQiOiJhTWhUMEJHZVQ1d0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVVnpOMnBPVTFRdGMxSTBXV3RFTUVkWGVqZEZjVnBZYVcxd1VWbEVkakpzWkZkbFlsVTJNWE42ZVcxWVl6VTNMV1Y2VTJOWE1YRlNla2N3V1VGSVoyNDBNblJJZUdWamJGTklTRzVmY1dOUFdFVm5iRTVOVmtOalFWOWxTbnBpU1hwdllqaDRUVFJ1Y0dWVVJUaG9Ra2x3ZGtFeVgycElWSEk1Ym1sWFVHNDROSFl4ZERVMlltODJOSFZWYlhWcU4wRXpTME5JWDBWTWN6ZDBVMDFKVlhSV2VUQlNlbEJ2WVRWU1RFMWZaakF6ZFhOSVZVeHpOV2xRY2psWlZEZFVNR1pzTFVkSE1tdDZibEZhZVRkM1ZHZzFTV1pMUzJSUE1pMVlaRE55VEc1Vlp4SVhjVGRyT1ZwTldHcENMVTlzTlU1dlVIZGpObUV0UVRRYUlrRlBMVEJ5YkRaWk1GTm9UbVZmVG5Gb2VYQnFZMEZzT1dKVE1UQnhiRjlUVTBFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gQmlnIENvdW50cnkgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMuYmlnY291bnRyeWhvbWVwYWdlLmNvbS9qb2JzL3RlY2huaWNhbC1sZWFkLWFyY2hpdGVjdC1iaWctZGF0YS1sZWFkLXdpdGgtZ2NwLXNhbi1mcmFuY2lzY28tY2FsaWZvcm5pYS85NjcyNDM4ODgtMi8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Cloud Software Engineer HYBRID",
            "company_name": "Limitless Talent Solutions",
            "location": "  Catonsville, MD   ",
            "via": "via ZipRecruiter",
            "description": "We are a recruiting agency recruiting top talent for Fortune 500 and high growth companies.\n\nJob Description...\n\nThe Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements. Directly contributes to all stages of back-end processing, analyzing, and indexing. Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nQualification\n\u2022 Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required.\n\u2022 Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree.\n\u2022 Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\u2022 Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Eight (8) years' experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelor's degree in computer science or related discipline from an accredited college or university is required",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree",
                        "Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Limitless+Talent+Solutions&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAII1gw",
                    "text": "See web results for Limitless Talent Solutions"
                }
            ],
            "extensions": [
                "24 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "24 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciBIWUJSSUQiLCJodGlkb2NpZCI6IkdlSEtxdVp1Yk4wQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVVWek4ycE9WSGwxYkhVMFRVcE5XRmxsUjNnd09VeGlPV2h3U1VoUllqSTJZVVV5UzBaUFQzZ3pPVGRGY1RaeGRDMUZhVXRTTm5aak1ERmhNRTFuT1hKMFdVRkVRMlYzVlhWdmRqUk1RM0ZuUTNoNE1tZFNSMEkwYkZoeVoyOWlSMHhmVjJ4b1MyeDVOSFJYU1daUVdYbEllR1ZKVTBkaloxWklSMVp4Y0U4NFNGaGZia0V3U0haSGIwY3dka0kwV0hCaWIxcHRRMmRETUdjelEzUmhXbnBWVnpKUlJqZEhkVXRwV1ZObWJXMVhiMEpwTjI1eFEwMVRjbU51YUdSM09YRkNaalpyYkVSUU0yMVBFaGR4TjJzNVdrMVlha0l0VDJ3MVRtOVFkMk0yWVMxQk5Cb2lRVTh0TUhKc05tMW1UWHBNY1hRM2MwVTVZemR4YjAxWmFWTkpMWFpXVTBadWR3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTIiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgZGlyZWN0bHkgb24gWmlwUmVjcnVpdGVyIiwibGluayI6Imh0dHBzOi8vd3d3LnppcHJlY3J1aXRlci5jb20vYy9MaW1pdGxlc3MtVGFsZW50LVNvbHV0aW9ucy9Kb2IvQ2xvdWQtU29mdHdhcmUtRW5naW5lZXItSFlCUklELy1pbi1DYXRvbnN2aWxsZSxNRD9qaWQ9YzZiOWQ4YzBlYWIyNGRkM1x1MDAyNnV0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Java Springboot Cloud developer",
            "company_name": "HexaQuest Global",
            "location": "  Weehawken, NJ   ",
            "via": "via WRBL Jobs",
            "description": "\u2022 participate in design and development of a complex strategic Risk Aggregation platform using Core java, Big-Data, Grid computing and caching technologies\n\u2022 interact with globally distributed Market Risk Officers, Quants and IT Dev/QA team\n\u2022 design and develop high quality software solutions for the Market Risk VaR (Value-at-Risk) platform...\n\u2022 develop new applications to meet regulatory commitments (e.g: FRTB, GMETH)\n\u2022 develop applications using Scala and Java programming languages\n\u2022 implement scalable solutions to meet the ever increasing data volumes, using Big Data/Cloud technologies Apache Spark, Hadoop, Microsoft Azure Cloud computing etc.\n\u2022 migrate on-prem apps or build new Apps into Azure Cloud (or) using Big Data Technologies i.e. Azure Data Lakes, Databricks, Redis Cache, Azure Data Factory, Azure Batch\n\u2022 design and develop Micro-services using Spring Boot and Azure Kubernetes Service (PKS) cluster\nYour expertise\n\u2022 BS or MS (preferred) in Computer Science or Information Technology\n\u2022 hands-on expertise with Java & Scala programming languages\n\u2022 experience with Big Data technologies; Spark and Hadoop platform is a must\n\u2022 experience in any one of the Cloud platform; Azure (Preferred), AWS or Google\n\u2022 experience working on any one-of following Hadoop Platforms i.e. Databricks (Preferred), Cloudera, Hortonworks, EMR\n\u2022 experience building data lakes and data pipelines in cloud using Azure and Databricks or similar tools\n\u2022 Spark Developer certification from any of (Databricks, MAPR, Cloudera or Hortonworks) is added advantage but not required\n\u2022 RDBMS or Hive fundamentals, Practice with Unix command line tools, knowledge of Data Structure & Algorithms\n\u2022 understanding of the Agile SDLC process",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "hands-on expertise with Java & Scala programming languages",
                        "experience with Big Data technologies; Spark and Hadoop platform is a must",
                        "experience working on any one-of following Hadoop Platforms i.e"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "participate in design and development of a complex strategic Risk Aggregation platform using Core java, Big-Data, Grid computing and caching technologies",
                        "interact with globally distributed Market Risk Officers, Quants and IT Dev/QA team",
                        "design and develop high quality software solutions for the Market Risk VaR (Value-at-Risk) platform",
                        "develop new applications to meet regulatory commitments (e.g: FRTB, GMETH)",
                        "develop applications using Scala and Java programming languages",
                        "implement scalable solutions to meet the ever increasing data volumes, using Big Data/Cloud technologies Apache Spark, Hadoop, Microsoft Azure Cloud computing etc",
                        "migrate on-prem apps or build new Apps into Azure Cloud (or) using Big Data Technologies i.e",
                        "design and develop Micro-services using Spring Boot and Azure Kubernetes Service (PKS) cluster"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=HexaQuest+Global&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIIlA0",
                    "text": "See web results for HexaQuest Global"
                }
            ],
            "extensions": [
                "14 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "14 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJKYXZhIFNwcmluZ2Jvb3QgQ2xvdWQgZGV2ZWxvcGVyIiwiaHRpZG9jaWQiOiJzaEkxTVl0X3RqY0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVVnpOMnBPVTFoVVpuQkhTRlJ2YWtRM2RXSlhVVVpYV0U1WllXMHdSMEV6U1hwWlZWcFpiMGgzZGswdFRtTjNhMHBxZFcweE9FNVNZVGxLYlU5WmJHbG1URzlqUWxoRFJXaDNlRWt3YUhWMlNGVXlNMDF6WWxCdmRrdEVUVGREYUhCT1dHZ3laVWN4VEd4NVdUTmFTbWREZDBscGVUbExlWGhzVFZKcmVsbzNlVk01VjJOSVYxQlplbVZ0UXpWVWExTlRMVVZFYkVGbVFXeHpSWGRDY1cwdGNFbDNiakp0VFVsclpucHBZMEZDYUZweFZEQldiVXBHY2xZeU1sSnRNQzAzZDBFelZrbFFSM1ZLRWhkeE4yczVXazFZYWtJdFQydzFUbTlRZDJNMllTMUJOQm9pUVU4dE1ISnNOV1ZNVld4eVFYZGtVRjlXZGs5bWJtMUJkbVJmVjB4NGRtTndkdyIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEzIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFdSQkwgSm9icyIsImxpbmsiOiJodHRwczovL2pvYnMud3JibC5jb20vam9icy9qYXZhLXNwcmluZ2Jvb3QtY2xvdWQtZGV2ZWxvcGVyLXdlZWhhd2tlbi1uZXctamVyc2V5Lzk2NzI0OTA0NS0yLz91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        },
        {
            "title": "Cloud Software Engineer 3",
            "company_name": "Avid Technology Professionals, LLC",
            "location": "  Annapolis, MD   ",
            "via": "via JobLeads",
            "description": "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements. Directly contributes to all stages of back-end processing, analyzing, and indexing. Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object Oriented... Design. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nMANDATORY SKILLS: 1. Eight (8) years experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing. Bachelors degree in Computer Science or related discipline from an accredited college or university is required. Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree. Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience. Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n2. The following Cloud related experiences are required:\n3. a. Two (2) years of Cloud and Distributed Computing Information Retrieval (IR).\n4. b. One (1) year of experience with implementing code that interacts with implementation of Cloud Big Table.\n5. c. One (1) year of experience with implementing code that interacts with implementation of Cloud Distributed File System.\n6. d. One (1) year of experience with implementing complex MapReduce analytics.\n7. e. One (1) year of experience with implementing code that interacts with Cloud Distributed Coordination Frameworks.\n8. Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing 2. Multi Node Management and Installation: Management and installation of Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies.\n9. Experience with Information Assurance: Securing Cloud Based and Distributed applications through industry standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)\n10. Experience with Information Technology:\n11. a. Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n12. b. Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n13. c. Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n14. d. Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n15. e. Aspect Oriented Design and Development\n16. f. Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications\n17. g. UNIX/LINUX, CentOS\n18. Experience with signals processing:\n19. a. Experience with at least one signals processing collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, and ELINT)\n20. b. Geolocation, emitter identification, and signal applications. 3. Joint program collection platforms and dataflow architectures; signals characterization analysis\n21. Experience with Other:\n22. a. CentOS and Linux/RedHat\n23. b. Configuration management tools such as Subversion, ClearQuest, or Razor\n\nAbout AvidTechnology Professionals\nAvid Technology Professionals, LLC (ATP) is a premiere provider of software and systems engineering, and acquisition program management services for the community. ATP is actively seeking to pursue contract opportunities with other departments and agencies in the federal government, in state governments, and in the commercial sectors. Delivered by seasoned experts in the IT field, ATP solutions adeptly address the IT concerns manifesting in both the federal and commercial sectors.\nEmployee Benefits\nThe ATP Employee Benefits package includes:\n\u2022 A Supportive and Equitable Working Environment that is both Stimulating and Challenging\n\u2022 Competitive Hourly Salary\n\u2022 Unique Employee Success Sharing Program that allows ATP employees to Share in Company's Successes\n\u2022 Automatic Approved Overtime (as long as contract permits)\n\u2022 Retirement Pay (401K); 100% company paid, immediately vested with Profit-Sharing Component\n\u2022 Company Medical Coverage Plans - HMO, Open Access, PPO plans\n\u2022 Company Dental Plan - widely accepted, comprehensive, and flexible\n\u2022 Progressive Overtime Policy\n\u2022 Flexible Spending Account benefit\n\u2022 Lucrative Referral Bonus Policy\n\u2022 Holiday Scheduling that Coincides with Government Holidays\n\u2022 Robust Professional Expenses & Training Program\n\u2022 Computer Allowance\n\u2022 Internet Allowance\n\u2022 Short and Long Term Disability\n\u2022 Life Insurance",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Eight (8) years experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelors degree in Computer Science or related discipline from an accredited college or university is required",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree",
                        "Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Two (2) years of Cloud and Distributed Computing Information Retrieval (IR)",
                        "One (1) year of experience with implementing code that interacts with implementation of Cloud Distributed File System",
                        "One (1) year of experience with implementing complex MapReduce analytics",
                        "Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing 2",
                        "Multi Node Management and Installation: Management and installation of Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies",
                        "Experience with Information Assurance: Securing Cloud Based and Distributed applications through industry standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "b",
                        "f",
                        "Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications",
                        "Experience with at least one signals processing collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, and ELINT)",
                        "Configuration management tools such as Subversion, ClearQuest, or Razor"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "e",
                        "Joint program collection platforms and dataflow architectures; signals characterization analysis"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "The ATP Employee Benefits package includes:",
                        "A Supportive and Equitable Working Environment that is both Stimulating and Challenging",
                        "Competitive Hourly Salary",
                        "Unique Employee Success Sharing Program that allows ATP employees to Share in Company's Successes",
                        "Automatic Approved Overtime (as long as contract permits)",
                        "Retirement Pay (401K); 100% company paid, immediately vested with Profit-Sharing Component",
                        "Company Medical Coverage Plans - HMO, Open Access, PPO plans",
                        "Company Dental Plan - widely accepted, comprehensive, and flexible",
                        "Progressive Overtime Policy",
                        "Flexible Spending Account benefit",
                        "Lucrative Referral Bonus Policy",
                        "Holiday Scheduling that Coincides with Government Holidays",
                        "Robust Professional Expenses & Training Program",
                        "Computer Allowance",
                        "Internet Allowance",
                        "Short and Long Term Disability",
                        "Life Insurance"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=Avid+Technology+Professionals,+LLC&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAII1w0",
                    "text": "See web results for Avid Technology Professionals, LLC"
                }
            ],
            "extensions": [
                "19 days ago",
                "Full-time",
                "Health insurance"
            ],
            "detected_extensions": {
                "posted_at": "19 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciAzIiwiaHRpZG9jaWQiOiItbkVKbVdWZWJXa0FBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFcUlDQ3VJQlFVVnpOMnBPVTB0dlRVVnJZWHB5TlZGd2NVdERSSEJDZDNWbk0xZ3djVXRwVld3MmFuUmtNeTFmV1RGWVFuWklUVmhoUkVaeGJDMWFTMlprVFROTlFVNVJSemROTjFkUVVITkxaVm94VTBKd2VqZG1UVkZyU21SZloyTkRZVFE0UlRBeFRtY3hPSGxyTVV3eWNrbDJVRVEyVWkxTGVUaHNhRE5FZWpKa2J6QjVaa1pNWlVoRExXRk9URzlLV1Vkd2IzRkxVemRtVkhwWFZYWTFiVkZNTkhwcVNHbHJiMDlyU1ZCeFFuaFZXVGRWZEhWMFFYb3RXbTEwT1dnelNFNWZhblJpTVY4M2RtMUVZVFp4YVZwYWJqZHhhRkpMV0hoTk9UVkpZemxtU1RKTFp4SVhjVGRyT1ZwTldHcENMVTlzTlU1dlVIZGpObUV0UVRRYUlrRlBMVEJ5YkRScVYxSTVZazl1U1VkNVYyaHdjR2xqUjBKd2JUQXdVbFJZZEdjIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTQiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gSm9iTGVhZHMiLCJsaW5rIjoiaHR0cHM6Ly93d3cuam9ibGVhZHMuY29tL2VuLXVzL2pvYi9lNjE1YTJmYzM3YzVmYWE3ZjJkYjQ5ODJmZmI1YmZjYTY/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Cloud Design Engr (CDE2)- TS/SCI with Poly",
            "company_name": "CACI",
            "location": "  Annapolis Junction, MD   ",
            "via": "via Indeed",
            "description": "Cloud Design Engr (CDE2)- TS/SCI with Poly\n\nJob Category: Engineering...\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI with Polygraph\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\nWhat You\u2019ll Get to Do:\n\nWe're looking to hire a Cloud Design Engineer around the Fort Meade, Maryland area.\n\nResponsibilities:\n\u2022 The Cloud Design Engineer develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements.\n\u2022 Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System.\n\u2022 Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies.\n\u2022 Cloud Designer implements Graphical Web-Based User Interface with usability, security, and performance in mind.\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse.\n\nYou\u2019ll Bring These Qualifications:\n\nEight (8) years software engineering experience in programs and contracts of similar scope, type, and complexity are required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\nFour (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree.\n\nBachelors degree in Computer Science or related discipline from an accredited college or university is required. Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience. Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\nThe following Cloud related experiences are required:\n\u2022 Two (2) year of Web-Based applications that retrieves/stores data in a Cloud Data System\n\u2022 Two (2) year of building applications that comply with modern Web 2.0 standards\n\u2022 Two (2) years of Cloud and/or Distributed Computing Information Retrieval (IR)\n\u2022 One (1) year working with data stored in Cloud Big Table\n\u2022 One (1) year of analyzing data stored in Cloud Distributed File System\n\u2022 Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing\n\u2022 Experience in Information Assurance - Securing User Interfaces based on Cloud and Distributed applications that contain disparate data sources and classifications through industry standard techniques such as Firewalls, PKI Certificate, and Server Authentication with experience in Corporate authentication service(s)\n\nExperience in Information Technology:\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services\n\u2022 Interfacing with Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - Spring MVC, J2EE, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications\n\nExperience in SIGINT:\n\u2022 Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)\n\u2022 Geolocation, emitter identification, and signal applications\n\u2022 Joint program collection platforms and dataflow architectures; signals characterization analysis\n\nExperience with CentOS, Linux/RedHat; Configuration management tools such as Subversion, ClearQuest, or Razor\n\nWhat We Can Offer You:\n\u2022 We\u2019ve been named a Best Place to Work by the Washington Post.\n\nOur employees value the flexibility at CACI that allows them to balance quality work and their personal lives.\n\u2022 We offer competitive benefits and learning and development opportunities.\n\u2022 We are mission-oriented and ever vigilant in aligning our solutions with the nation\u2019s highest priorities.\n\u2022 For over 55 years, the principles of CACI\u2019s unique, character-based culture have been the driving force behind our success.\n\nCompany Overview: At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.\n\nAs a federal contractor, CACI is subject to any federal vaccine mandates or other customer vaccination requirements. All new hires are required to report their vaccination status",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum Clearance Required to Start: TS/SCI with Polygraph",
                        "Eight (8) years software engineering experience in programs and contracts of similar scope, type, and complexity are required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree",
                        "Bachelors degree in Computer Science or related discipline from an accredited college or university is required",
                        "Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Two (2) year of Web-Based applications that retrieves/stores data in a Cloud Data System",
                        "Two (2) year of building applications that comply with modern Web 2.0 standards",
                        "Two (2) years of Cloud and/or Distributed Computing Information Retrieval (IR)",
                        "One (1) year working with data stored in Cloud Big Table",
                        "One (1) year of analyzing data stored in Cloud Distributed File System",
                        "Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing",
                        "Experience in Information Assurance - Securing User Interfaces based on Cloud and Distributed applications that contain disparate data sources and classifications through industry standard techniques such as Firewalls, PKI Certificate, and Server Authentication with experience in Corporate authentication service(s)",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Interfacing with Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - Spring MVC, J2EE, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications",
                        "Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Percentage of Travel Required: Up to 10%",
                        "The Cloud Design Engineer develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System",
                        "Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies",
                        "Cloud Designer implements Graphical Web-Based User Interface with usability, security, and performance in mind",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse",
                        "Joint program collection platforms and dataflow architectures; signals characterization analysis"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "We offer competitive benefits and learning and development opportunities"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.caci.com/",
                    "text": "caci.com"
                },
                {
                    "link": "https://www.google.com/search?hl=en&gl=us&q=CACI&sa=X&ved=0ahUKEwiF5c3S7bH-AhXjElkFHUGnBu84KBCYkAIImA4",
                    "text": "See web results for CACI"
                }
            ],
            "extensions": [
                "25 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "25 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBEZXNpZ24gRW5nciAoQ0RFMiktIFRTL1NDSSB3aXRoIFBvbHkiLCJodGlkb2NpZCI6ImZHczFRcDktbllJQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVVWek4ycE9WREJLWkU1aWRrTTJiRFJRYzBGZlFuRkpXamR3YVZsNFRIaFZPVEl4V0U5dWMxQmZTMWxUV0ZaVlFtNHdUVmhOU0haellrUjFZMGR6WW1sNFduUjZTVkkyYVZsZlpsRTNSbVk1Uld4V1owMVJiVlZGVDB0elVsSjVVMjlvY1VOWVdrWlZUVU0yTWpoUlVreEZOV0UzWTNGb2VFeERkVlk0UTJWRmNtb3lTVUp6UzJ0V01XZDVUVXh5WkdSSFUwSklWVXhWU21Ga1gwaFhjVU50Tm1KRGVFaEhTMkprVW10NFRsWXRVVTVvWjBwUVpYUkdXVzFSWWpOTVkyOTBRVTVJWmtwdVIxbEpSbXhoY0RWTlEwOWhORFJxVGtKRk5HdHlSM0l4ZHhJWGNUZHJPVnBOV0dwQ0xVOXNOVTV2VUhkak5tRXRRVFFhSWtGUExUQnliRFl6VUcxT01VOXBZVTg1VEhkS2VsUTVNVXROTVRReFRGRnZMV2MiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBJbmRlZWQiLCJsaW5rIjoiaHR0cHM6Ly93d3cuaW5kZWVkLmNvbS92aWV3am9iP2prPThjYWZmN2M1MmUxMGU5NGJcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        }
    ],
    "chips": [
        {
            "type": "Title",
            "param": "job_family_1",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Software engineer",
                    "value": "software engineer"
                },
                {
                    "text": "Design engineer",
                    "value": "design engineer"
                },
                {
                    "text": "Data architect",
                    "value": "data architect"
                },
                {
                    "text": "Customer engineer",
                    "value": "customer engineer"
                },
                {
                    "text": "Support engineer",
                    "value": "support engineer"
                },
                {
                    "text": "Data consultant",
                    "value": "data consultant"
                },
                {
                    "text": "Sales engineer",
                    "value": "sales engineer"
                },
                {
                    "text": "Senior",
                    "value": "senior"
                },
                {
                    "text": "Solutions architect",
                    "value": "solutions architect"
                },
                {
                    "text": "Analyst",
                    "value": "analyst"
                },
                {
                    "text": "Cloud architect",
                    "value": "cloud architect"
                },
                {
                    "text": "Cloud consultant",
                    "value": "cloud consultant"
                },
                {
                    "text": "Cloud engineer",
                    "value": "cloud engineer"
                },
                {
                    "text": "Data engineer",
                    "value": "data engineer"
                },
                {
                    "text": "Data scientist",
                    "value": "data scientist"
                },
                {
                    "text": "Engineering",
                    "value": "engineering"
                },
                {
                    "text": "Manager",
                    "value": "manager"
                },
                {
                    "text": "Solution manager",
                    "value": "solution manager"
                },
                {
                    "text": "Technical",
                    "value": "technical"
                }
            ]
        },
        {
            "type": "Location",
            "param": "city",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Annapolis Junction, MD",
                    "value": "zW-xYyLnt4mqAms5YL-SKQ=="
                },
                {
                    "text": "Annapolis, MD",
                    "value": "1S9ncGX2t4lLJ6jT_VT4Qw=="
                },
                {
                    "text": "Atlanta, GA",
                    "value": "jQmTaV0E9YgLYwuZL97-Zg=="
                },
                {
                    "text": "Baltimore, MD",
                    "value": "t4P01q4DyIlY5yNCqJZIBA=="
                },
                {
                    "text": "Salt Lake City, UT",
                    "value": "7THRiJQ9UofKMU1IoLdTWw=="
                },
                {
                    "text": "Washington, DC",
                    "value": "W-T2Wt7Gt4kqXYjUIkVSwg=="
                },
                {
                    "text": "Catonsville, MD",
                    "value": "TYwOyT0cyImNcyTcDrP1IQ=="
                },
                {
                    "text": "Herndon, VA",
                    "value": "Q6ZdDwY4tol9NWwctSKAkg=="
                },
                {
                    "text": "Palo Alto, CA",
                    "value": "ORy6nXuwj4DPdvU1UvUfDg=="
                },
                {
                    "text": "Reston, VA",
                    "value": "5WUWJkdAtomfrnGo6K_fYw=="
                },
                {
                    "text": "San Francisco, CA",
                    "value": "IQBpAG2ahYD_rXbwZxNQSg=="
                },
                {
                    "text": "Weehawken, NJ",
                    "value": "AdCFFTBYwomUmggtWZ9PJQ=="
                },
                {
                    "text": "Austin, TX",
                    "value": "LwPMoJm1RIZ61WnUS0abXQ=="
                },
                {
                    "text": "Boston, MA",
                    "value": "GzE9DS1l44mg6GIBJL98eA=="
                },
                {
                    "text": "Chantilly, VA",
                    "value": "GXJnGVZBtomDrRZD_PBBQA=="
                },
                {
                    "text": "Charlotte, NC",
                    "value": "gRo4_MQfVIhk0UO_5lBGiA=="
                },
                {
                    "text": "Chicago, IL",
                    "value": "7cv00DwsDogAwMAJrabgrw=="
                },
                {
                    "text": "Columbia, MD",
                    "value": "UaBpY7Dft4ldY4e2Zb3W8A=="
                },
                {
                    "text": "Crownsville, MD",
                    "value": "tds0e1_wt4lD8Gl4tkPWrw=="
                },
                {
                    "text": "Dallas, TX",
                    "value": "S5dFe_cZTIaPZ0f2pJvsuQ=="
                },
                {
                    "text": "Dearing, KS",
                    "value": "OfJxMhSCt4eyx6-l5eqDwg=="
                },
                {
                    "text": "Edison, NJ",
                    "value": "maG-aH_Tw4nq1INvpsUr8g=="
                },
                {
                    "text": "Fort Meade, MD",
                    "value": "jdor14Tmt4l3A9bF4c3sbg=="
                },
                {
                    "text": "Hanover, MD",
                    "value": "CR8SmSTit4kd1ecDfu3Bcw=="
                },
                {
                    "text": "Laurel, MD",
                    "value": "0dxJ6BDdt4n8ks39Ll7NmA=="
                },
                {
                    "text": "Los Gatos, CA",
                    "value": "PwN3UzY0joCmjHSsAVNn7w=="
                },
                {
                    "text": "Moline, IL",
                    "value": "a0TjeKAw4ocnMg_Pp6fQLg=="
                },
                {
                    "text": "New York, NY",
                    "value": "Owg_06VPwoli_nfhBo8LyA=="
                },
                {
                    "text": "Ohio, IL",
                    "value": "4a34ENmeCYiVXj8uMgu1Jg=="
                },
                {
                    "text": "San Jose, CA",
                    "value": "9T_5iuTKj4B7cZ_KCoyduQ=="
                },
                {
                    "text": "St. Louis, MO",
                    "value": "-Y7t-qm02Idb4Lsiyuo5vg=="
                },
                {
                    "text": "White Plains, NY",
                    "value": "2TWj4iKUwols_FsaEAQUVA=="
                },
                {
                    "text": "Wilmington, DE",
                    "value": "b69GXBgPx4kAjDB3UNoWhQ=="
                }
            ]
        },
        {
            "type": "Date posted",
            "param": "date_posted",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Past day",
                    "value": "today"
                },
                {
                    "text": "Past 3 days",
                    "value": "3days"
                },
                {
                    "text": "Past week",
                    "value": "week"
                },
                {
                    "text": "Past month",
                    "value": "month"
                }
            ]
        },
        {
            "type": "Requirements",
            "param": "requirements",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "No degree",
                    "value": "no_degree"
                },
                {
                    "text": "No experience",
                    "value": "no_experience"
                },
                {
                    "text": "Under 3 years of experience",
                    "value": "years3under"
                },
                {
                    "text": "3+ years of experience",
                    "value": "years3plus"
                }
            ]
        },
        {
            "type": "Type",
            "param": "employment_type",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Full-time",
                    "value": "FULLTIME"
                },
                {
                    "text": "Contractor",
                    "value": "CONTRACTOR"
                },
                {
                    "text": "Internship",
                    "value": "INTERN"
                },
                {
                    "text": "Part-time",
                    "value": "PARTTIME"
                }
            ]
        },
        {
            "type": "Company type",
            "param": "industry.id",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Computer Services",
                    "value": "/business/naics2007/5415"
                },
                {
                    "text": "Information",
                    "value": "/business/naics2007/51"
                },
                {
                    "text": "Consulting",
                    "value": "/business/naics2007/5416"
                },
                {
                    "text": "Health Care",
                    "value": "/business/naics2007/62"
                },
                {
                    "text": "Finance",
                    "value": "/business/naics2007/52"
                },
                {
                    "text": "Manufacturing",
                    "value": "/business/naics2007/31"
                },
                {
                    "text": "Rental",
                    "value": "/business/naics2007/532"
                }
            ]
        },
        {
            "type": "Employer",
            "param": "organization_mid",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Google",
                    "value": "/m/045c7b"
                },
                {
                    "text": "ARSIEM",
                    "value": "/g/11fy22b_1s"
                },
                {
                    "text": "Amazon Web Services, Inc.",
                    "value": "/m/0rznzt1"
                },
                {
                    "text": "Elevance Health",
                    "value": "/m/04xtkp"
                },
                {
                    "text": "NiSUS Technologies Corporation",
                    "value": "/g/11g705zkln"
                },
                {
                    "text": "Amazon.com Services LLC",
                    "value": "/g/11f00sjtl5"
                },
                {
                    "text": "Base-2 Solutions",
                    "value": "/g/11gxm4c0tt"
                },
                {
                    "text": "CACI",
                    "value": "/m/0310bt"
                },
                {
                    "text": "IntelliGenesis LLC",
                    "value": "/g/11c73hfqj8"
                },
                {
                    "text": "Raytheon Technologies",
                    "value": "/g/11c6qvm0kj"
                },
                {
                    "text": "Avid Technology Professionals, LLC",
                    "value": "/g/11g9n060lk"
                },
                {
                    "text": "Booz Allen Hamilton",
                    "value": "/m/05jlg3"
                },
                {
                    "text": "BrainTrust Holdings",
                    "value": "/g/11fy267mw4"
                },
                {
                    "text": "Castaway Research",
                    "value": "/g/11jp54p9k7"
                },
                {
                    "text": "JPMorgan Chase",
                    "value": "/m/01hlwv"
                },
                {
                    "text": "Johnson Technology Systems Inc.",
                    "value": "/g/11f7p9xc6j"
                },
                {
                    "text": "Keylent",
                    "value": "/g/11rvbr_y2l"
                },
                {
                    "text": "ManTech International",
                    "value": "/m/03crmnd"
                },
                {
                    "text": "Netflix",
                    "value": "/m/017rf_"
                },
                {
                    "text": "Novetta",
                    "value": "/g/11g9m_jqt2"
                },
                {
                    "text": "Open Systems Technologies",
                    "value": "/g/11b7c7x3lx"
                },
                {
                    "text": "Orion Consortium",
                    "value": "/g/11g9mp3gx4"
                },
                {
                    "text": "Rakuten USA, Inc.",
                    "value": "/g/11f00sztwj"
                },
                {
                    "text": "Snowflake Computing",
                    "value": "/g/11b8krtt2g"
                },
                {
                    "text": "Super Micro Computer",
                    "value": "/m/03p3m28"
                },
                {
                    "text": "Synechron Inc.",
                    "value": "/m/027hdqs"
                },
                {
                    "text": "The DarkStar Group",
                    "value": "/g/11fy1qp5kx"
                },
                {
                    "text": "Trigyn",
                    "value": "/m/0cp7t9v"
                },
                {
                    "text": "Triumph Tech",
                    "value": "/g/11ry5h_t46"
                },
                {
                    "text": "WayUp",
                    "value": "/g/11gfj67hvn"
                },
                {
                    "text": "Inforeliance",
                    "value": "/g/1dv3111b"
                }
            ]
        }
    ]
}
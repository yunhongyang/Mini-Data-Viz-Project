{
    "search_metadata": {
        "id": "643db9a30574f5e1af908539",
        "status": "Success",
        "json_endpoint": "https://serpapi.com/searches/5be777e9f66f4766/643db9a30574f5e1af908539.json",
        "created_at": "2023-04-17 21:26:59 UTC",
        "processed_at": "2023-04-17 21:26:59 UTC",
        "google_jobs_url": "https://www.google.com/search?q=big+data+and+cloud+computing&ibp=htl;jobs&uule=w+CAIQICINVW5pdGVkIFN0YXRlcw&hl=en&gl=us&start=20",
        "raw_html_file": "https://serpapi.com/searches/5be777e9f66f4766/643db9a30574f5e1af908539.html",
        "total_time_taken": 1.6
    },
    "search_parameters": {
        "q": "big data and cloud computing",
        "engine": "google_jobs",
        "uule": "w+CAIQICINVW5pdGVkIFN0YXRlcw",
        "google_domain": "google.com",
        "hl": "en",
        "gl": "us",
        "start": 20
    },
    "jobs_results": [
        {
            "title": "Cloud Software Engineer (Hybrid)",
            "company_name": "PerunHR",
            "location": "  Catonsville, MD   ",
            "via": "via Jobs By Workable",
            "description": "Since our inception, PerunHR has been focused on building a strategic, quality outsourcing practice. We offer recruitment process outsourcing services by implementing a modern recruitment system, using the latest recruiting and screening solutions, modern online job boards, and Applicant Tracking Systems. We help our clients find perfect fits for their vacancies and support candidates to connect... with our clients and achieve their goals together. In a market with numerous service providers, by nurturing our core values, our staff apply and improve specialized knowledge in the required field while ensuring high expertise in providing services.\n\nFor our client, a company that provides outstanding program management, consulting, and infrastructure support to both private and commercial businesses, we are looking for a Cloud Software Engineer to support the current and future projects.\n\nJob Description:\n\u2022 Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements.\n\u2022 Directly contributes to all stages of back-end processing, analyzing, and indexing.\n\u2022 Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\u2022 Works individually or as part of a team.\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\u2022 Candidates must sit in the Washington DC metro area or within in 90 mins driving time (include Maryland, Virginia, and Washington DC).\n\u2022 Security Clearance: Active TS/SCI FS Poly is required at the time of hire or if the clearance has been inactive for less than 2 years, the candidates will be consider. The candidates must complete a security verification and their start date would be pending the reactivation of their clearance.\n\u2022 U.S. citizenship.\n\u2022 8 years of experience in software engineering, in programs and contracts of similar scope, type, and complexity is required; 2 years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelor's degree in computer science or related discipline from an accredited college or university is required; 4 years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree; Master in Computer Science or related discipline from an accredited college or university may be substituted for 2 years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for 1 year of Cloud experience.\n\u2022 Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB.\n\u2022 Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies.\n\u2022 Aspect Oriented Design and Development.\n\u2022 Debugging and Profiling Cloud and Distributed Installations.\n\u2022 Salary: $131,000 - $140,000 / yearly",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Security Clearance: Active TS/SCI FS Poly is required at the time of hire or if the clearance has been inactive for less than 2 years, the candidates will be consider",
                        "The candidates must complete a security verification and their start date would be pending the reactivation of their clearance",
                        "U.S. citizenship",
                        "8 years of experience in software engineering, in programs and contracts of similar scope, type, and complexity is required; 2 years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelor's degree in computer science or related discipline from an accredited college or university is required; 4 years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree; Master in Computer Science or related discipline from an accredited college or university may be substituted for 2 years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for 1 year of Cloud experience",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Salary: $131,000 - $140,000 / yearly"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=PerunHR&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIygk",
                    "text": "See web results for PerunHR"
                }
            ],
            "extensions": [
                "13 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "13 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciAoSHlicmlkKSIsImh0aWRvY2lkIjoiRzZOaGFVcUdhS1FBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WVzVwZEdWa0lGTjBZWFJsY3ciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXZjQkNyY0JRVVZ6TjJwT1UwRmtZV2xOT1dOSkxVVndNVlJ3YlhSd1YxZFBWbFozT1RsUGFVUk9WSHBYT1dVelMyeFRjM2RGTjBwTlJEQnlTR2hmVVdGelIxVjJPSFkyYVVoaE9VSmpSVmQzVjBWaWIwbDBMVWRxV1cxV2JXUjJkV3BSWmtVMFgzbG1ZVTFaZVc4dFFUWlZOMWhVWDBaR1Z6QnFSRkpYT0dOZlQwVnVORGhOVFZkSk16STFSVk5sU0ZKQ1IwSkJZVlY1TVVKNE5GVjZiakpFVERZMlEzbHhMV28wTm1wSWIxOHdlVGg1VlZkSE1UQmtiRm8wRWhkdk4yczVXa3htT0VsZkxUUXljbTlRYW5STFlUWkJPQm9pUVU4dE1ISnNOaTF5VUZjNFh6SjNOVWgwUldwTkxWQmlSelZTTXpGU1RXcFRRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiLm5GZzJlYntmb250LXdlaWdodDo1MDB9LkJpNkRkY3tmb250LXdlaWdodDo1MDB9QXBwbHkgZGlyZWN0bHkgb24gSm9icyBCeSBXb3JrYWJsZSIsImxpbmsiOiJodHRwczovL2FwcGx5LndvcmthYmxlLmNvbS9wZXJ1bmhyL2ovMjFDRkRCQjI0Ni8/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Big Data Architect",
            "company_name": "Triumph Tech",
            "location": "  United States   ",
            "via": "via Startup Jobs",
            "description": "Triumph Tech solves business problems with AWS Cloud Technology which allows our customers to focus on what they excel at. We accomplish this through our Core Values:\n\n\u2022 Urgency Bias...\n\u2022 People Obsession\n\u2022 Standard of Excellence\n\u2022 Servant Leadership\n\u2022 Deliver Impactful Results\n\nWe are a fully remote global company with employees in Canada, the United States, Philippines and Latin America. We celebrate the culture of each of our team members and foster a community of collaboration. Come talk to us to learn more about what it means to be a part of the Triumph Tech family!\n\nThe Role\n\nThe role of cloud computing has changed the shape of business and as a Premier Partner of AWS, Triumph is at the forefront of helping customers take advantage of its agility, scalability, and availability.\n\nThe Big Data Architect works as an integral part of a cross-functional delivery team to implement and design data management solutions on the AWS cloud for our customers. You will design and document the big data and NoSQL solutions, and provide guidance to the engineers performing the hands-on implementation of your design. You will participate in daily standup meetings with your team and bi-weekly agile ceremonies with the customer. Your manager will have a weekly 1:1 with you to help guide you in your career and make the most of your time at Triumph Tech. Come disrupt the technology world by joining the Triumph Tech team!\n\nJob Responsibilities\n\n\u2022 Owning technical engagements, ensuring timely and successful value delivery.\n\u2022 Owning the planning, execution, technical engagement, and outcomes of specific implementation projects and assignments.\n\u2022 Work with a team to deliver top-quality data solutions on AWS for customers\n\u2022 Participate in daily standup meetings and address technical issues\n\u2022 Design, optimization and migration of web-scale data processing operations\n\u2022 Lead and help engineers without any direct supervision\n\u2022 Work daily on code and problem solve in code (not tickets): 65% hands-on, 35% architecture/R&D/meetings\n\u2022 Understanding the AWS market segments, industry verticals, and customer base.\n\u2022 Developing a deep understanding and expertise of AWS technologies\n\u2022 Gaining technological knowledge of the construction of applications and services using the AWS platform.\n\u2022 Engage in a highly collaborative team environment where your expertise is required to suggest best options to lay foundations for cloud data architecture, scaling, and data development opportunities, cost savings, and vulnerabilities\n\u2022 Kickoff new client engagements\n\u2022 Build enterprise technology solutions in Big Data\n\u2022 Take on work already in-line with projects and deliverables and research new projects (R&D)\n\u2022 Develop long range plans with customer to adopt cloud best practices\n\u2022 Ensure high quality of project delivery\n\nYour Qualifications\n\n\u2022 Design and implementation of at least two of these:\n\n\u2022 ETL, Orchestration and CI/CD pipelines\n\u2022 Data Lakes, Data Warehouses\n\u2022 Analytics and visualization\n\n\u2022 Design and implementation of at least two of these:\n\n\u2022 Data processing: eg. Hadoop, Spark, EMR\n\u2022 AWS Native Data processing: Eg. EMR, Glue, Lambda\n\u2022 Streaming/Messaging: eg. Kafka, RabbitMQ, Kinesis\n\u2022 NoSQL DBs like KeyValue stores, Document Databases, Graph Databases\n\u2022 Caching: eg. Redis, Memcache\n\u2022 Search: eg. ElasticSearch, Solr\n\n\u2022 Design and implementation of at least one of these:\n\n\u2022 Large scale application migration and modernization with a heavy focus on data\n\u2022 Security, access controls and governance on cloud\n\n\u2022 Experience with IaC tools such as CloudFormation, Serverless Framework, CDK, Terraform, and CI/CD tools\n\u2022 Excellent written and verbal communication skills\n\u2022 Great verbal and written communication skills\n\u2022 Enthusiasm for working in a startup environment and the ability to be cross-functional\n\u2022 Possess a natural curiosity and excitement for learning new technology\n\u2022 Ability to lead and work well with others\n\nPreferred Qualifications\n\n\u2022 Experience with highly-available, fault-tolerant architectures\n\u2022 Experience with Serverless and Containers-based architectures\n\u2022 Experience with IT compliance frameworks and requirements (e.g. PCI, HIPAA, GDPR, security)\n\u2022 AWS Data and Analytics Certification\n\u2022 A bachelor's degree in Computer Science, Mathematics, Engineering, or a related field of study; or equivalent experience.\n\u2022 5+ years experience working with AWS Cloud Data and Analytics\n\u2022 3+ years of experience designing, implementing or consulting in Big Data Infrastructure\n\u2022 Experience communicating with technical and non-technical audiences and executive-level stakeholders and clients.\n\u2022 2+ years of hands-on Big Data Solution Development\n\nBenefits\n\n\u2022 Medical Insurance for you and eligible dependents\n\u2022 401k plan with company match up to 4% after 90 days\n\u2022 State of the art laptop and remote collaboration tools\n\u2022 Dental and Vision insurance\n\u2022 Flexible Spending Account\n\u2022 Equipment & Office Stipend\n\u2022 Annual stipend for Learning and Development\n\u2022 Generous and flexible PTO\n\u2022 8 Paid Holidays\n\nNOTE: We are unable to provide sponsorship for this position.\n\nTriumph Tech is an inclusive workforce where everyone belongs. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our approach helps us to build a winning team that represents a variety of backgrounds, perspectives, and abilities. So, regardless of how your diversity expresses itself, you can find a family here at Triumph Tech.\n\nTriumph Tech is an Equal Opportunity Employer and we prohibit discrimination and harassment of any kind based on race, color, religion, national origin, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, veteran status, genetic information, disability, or other applicable legally protected characteristics. If you would like to request an accommodation due to a disability, please contact us at hr@triumphtech.com",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Design and implementation of at least two of these:",
                        "ETL, Orchestration and CI/CD pipelines",
                        "Data Lakes, Data Warehouses",
                        "Analytics and visualization",
                        "Hadoop, Spark, EMR",
                        "AWS Native Data processing: Eg",
                        "NoSQL DBs like KeyValue stores, Document Databases, Graph Databases",
                        "Caching: eg",
                        "Large scale application migration and modernization with a heavy focus on data",
                        "Security, access controls and governance on cloud",
                        "Experience with IaC tools such as CloudFormation, Serverless Framework, CDK, Terraform, and CI/CD tools",
                        "Excellent written and verbal communication skills",
                        "Enthusiasm for working in a startup environment and the ability to be cross-functional",
                        "Possess a natural curiosity and excitement for learning new technology",
                        "Ability to lead and work well with others"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "You will design and document the big data and NoSQL solutions, and provide guidance to the engineers performing the hands-on implementation of your design",
                        "You will participate in daily standup meetings with your team and bi-weekly agile ceremonies with the customer",
                        "Owning technical engagements, ensuring timely and successful value delivery",
                        "Owning the planning, execution, technical engagement, and outcomes of specific implementation projects and assignments",
                        "Work with a team to deliver top-quality data solutions on AWS for customers",
                        "Participate in daily standup meetings and address technical issues",
                        "Design, optimization and migration of web-scale data processing operations",
                        "Lead and help engineers without any direct supervision",
                        "Work daily on code and problem solve in code (not tickets): 65% hands-on, 35% architecture/R&D/meetings",
                        "Understanding the AWS market segments, industry verticals, and customer base",
                        "Developing a deep understanding and expertise of AWS technologies",
                        "Gaining technological knowledge of the construction of applications and services using the AWS platform",
                        "Engage in a highly collaborative team environment where your expertise is required to suggest best options to lay foundations for cloud data architecture, scaling, and data development opportunities, cost savings, and vulnerabilities",
                        "Kickoff new client engagements",
                        "Build enterprise technology solutions in Big Data",
                        "Take on work already in-line with projects and deliverables and research new projects (R&D)",
                        "Develop long range plans with customer to adopt cloud best practices",
                        "Ensure high quality of project delivery"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Medical Insurance for you and eligible dependents",
                        "401k plan with company match up to 4% after 90 days",
                        "State of the art laptop and remote collaboration tools",
                        "Dental and Vision insurance",
                        "Flexible Spending Account",
                        "Equipment & Office Stipend",
                        "Annual stipend for Learning and Development",
                        "Generous and flexible PTO",
                        "8 Paid Holidays"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.triumphtech.com/",
                    "text": "triumphtech.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Triumph+Tech&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIjwo",
                    "text": "See web results for Triumph Tech"
                }
            ],
            "extensions": [
                "Full-time",
                "Health insurance",
                "Dental insurance",
                "Paid time off"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBBcmNoaXRlY3QiLCJodGlkb2NpZCI6InRWazdVdnRXS2ZvQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkV2Y0JDcmNCUVVWek4ycE9WSE55Y20xSE5sTlFXRmt3U3pWaFRDMVZjRkY1VFZZeVNVUmlTVVo0UmtSalVrWXpNa2hmWXpCaFFqVktXVE5aYm1wMk9HTXhaWGt0WkV0alMzWk1aMVZrVGxoU1pIUnJkSGt6YzJwQlNUaFhaM1ZoYmw5Sk1qUmhXVEJWUXpRNVJtcFVZa0psWVZOaFFrMTRabGhwVERWSGIzaExlVUpaVldKcVpUVlRORFJ1TUhGelFVeDJRVGhzUkU1YVUyOXVOMFpKYXpaVmRYa3dSM1pzZUVkcGVuTnRSRE5OVW5kUmRWTlZXRGxqZVVvMEVoZHZOMnM1V2t4bU9FbGZMVFF5Y205UWFuUkxZVFpCT0JvaVFVOHRNSEpzTlZGbllrVmlRbGRwU1dkVVdYRlJURnBwTWs5QldtcHJZV2cwVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18yIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIFN0YXJ0dXAgSm9icyIsImxpbmsiOiJodHRwczovL3N0YXJ0dXAuam9icy9iaWctZGF0YS1hcmNoaXRlY3QtdHJpdW1waC10ZWNoLTQyMzA5MTM/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Technical Support Engineer (L5) - Data Platform, Big Data / Analytics",
            "company_name": "Netflix",
            "location": "  Los Gatos, CA   ",
            "via": "via Startup Jobs",
            "description": "Netflix is the world\u2019s leading streaming entertainment service with 220 million paid memberships in over 190 countries, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. Members can watch as much as they want, anytime, anywhere, on any internet-connected screen.\n\nAbout the Engineering Support Organization...\nThe aim of the Engineering Support Organization is to enable Platform Engineering to effectively and sustainably scale the support they provide to their customers. The team is the frontline resource for the engineering support needs of our customers (i.e., our workforce) - handling, troubleshooting, and resolving customer requests and issues. In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education.\n\nOur Mission\nDeliver an excellent support experience to Netflix\u2019s developer community. To advocate for our customers, follow through on issues and resolve them in a reasonable time. If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay.\n\nProvide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity and Data Platform Engineering. Partner with Product Management, Developer Education and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized.\n\nDrive collaboration efforts to reduce product friction and increase usability so that Platform Engineering can build, deploy and deliver highly functional solutions for the Developer Community.\n\nThe Role\nWe are looking for a Technical Support Engineer with a passion for data platform infrastructure and tooling, customer service, and automation. You will be responsible for monitoring and handling our customers\u2019 requests, troubleshooting, solving issues, automating support needs, developing support documentation and runbooks, improving and maintaining support tools and automation, understanding our product offerings, and continuously looking for ways to improve the engineering support experience.\n\nOur ideal team member has first-hand experience working in customer-facing, engineering support roles, writing and building a comprehensive self-service knowledge base and has knowledge of infrastructure, internal tooling, platforms, and cloud computing. You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement. As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions.\nLocation\n\n\u2022 Our offices are located in Los Gatos.\n\nWhat you\u2019ll need to be successful:\n\n\u2022 You are skilled in providing superior customer support across a complex organization, ideally as part of a central team\n\u2022 You are passionate about customer experience\n\u2022 You are a data-driven decision-maker\n\u2022 You have excellent written and verbal communications skills and appreciate the importance of comprehensive documentation\n\u2022 You are comfortable with at least one programming language; preferably Python and/or Java\n\u2022 Ability to read and comprehend log files and Unix processes to identify and troubleshoot root causes of issues\n\u2022 Prior experience supporting platforms built using open source technologies such as, Jupyter, Hadoop, Apache Airflow (or other workflow orchestration platform), Presto/Trino\n\u2022 You have worked with big data warehouse storage systems (e.g. Iceberg or Hive)\n\u2022 You have experience working with data pipelines using Apache Spark framework or technologies such as Flink, Kafka, Druid or Presto\n\u2022 Ability to read and write SQL queries to pull required complex data to support any reported issues/product defects\n\u2022 Experience with cloud infrastructure and/or container orchestration platform is a plus\n\u2022 You have the desire and aptitude to learn how the pieces of big data platform work together\n\nOur culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Platform Engineering, feel free to listen to this podcast.\n\nWe are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\nAt Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.\n\nThe overall market range for roles in this area of Netflix is typically $100,000 - $700,000\n\nThis market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement",
                        "As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions",
                        "You are skilled in providing superior customer support across a complex organization, ideally as part of a central team",
                        "You are passionate about customer experience",
                        "You are a data-driven decision-maker",
                        "You have excellent written and verbal communications skills and appreciate the importance of comprehensive documentation",
                        "You are comfortable with at least one programming language; preferably Python and/or Java",
                        "Ability to read and comprehend log files and Unix processes to identify and troubleshoot root causes of issues",
                        "Prior experience supporting platforms built using open source technologies such as, Jupyter, Hadoop, Apache Airflow (or other workflow orchestration platform), Presto/Trino",
                        "You have worked with big data warehouse storage systems (e.g",
                        "You have experience working with data pipelines using Apache Spark framework or technologies such as Flink, Kafka, Druid or Presto",
                        "Ability to read and write SQL queries to pull required complex data to support any reported issues/product defects",
                        "You have the desire and aptitude to learn how the pieces of big data platform work together"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The team is the frontline resource for the engineering support needs of our customers (i.e., our workforce) - handling, troubleshooting, and resolving customer requests and issues",
                        "In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education",
                        "To advocate for our customers, follow through on issues and resolve them in a reasonable time",
                        "If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay",
                        "Provide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity and Data Platform Engineering",
                        "Partner with Product Management, Developer Education and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized",
                        "Drive collaboration efforts to reduce product friction and increase usability so that Platform Engineering can build, deploy and deliver highly functional solutions for the Developer Community",
                        "We are looking for a Technical Support Engineer with a passion for data platform infrastructure and tooling, customer service, and automation",
                        "You will be responsible for monitoring and handling our customers\u2019 requests, troubleshooting, solving issues, automating support needs, developing support documentation and runbooks, improving and maintaining support tools and automation, understanding our product offerings, and continuously looking for ways to improve the engineering support experience"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right",
                        "The overall market range for roles in this area of Netflix is typically $100,000 - $700,000"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.netflix.com/",
                    "text": "netflix.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Netflix&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAII0wo",
                    "text": "See web results for Netflix"
                }
            ],
            "extensions": [
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJUZWNobmljYWwgU3VwcG9ydCBFbmdpbmVlciAoTDUpIC0gRGF0YSBQbGF0Zm9ybSwgQmlnIERhdGEgLyBBbmFseXRpY3MiLCJodGlkb2NpZCI6Imd0aDVTWGpNS0pRQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVyY0NDdmNCUVVWek4ycE9VVVJMTjJGTWFrVmtlRE5RUVMxSVRuTlNaV3RWY1dFelFqSm9VRVIyUkZCTlpsbFJXRTlQUnpKWmF5MDBMVGRzVUdzNVQyRk9RMmxpVmpCVFIxaFhUVWMyVjBjeFRuQkhPR0ZVWjNNd1VsQldVV013UzNoeldWUlRlV0pFUVRsSVRsVnBlRzQzZVV0U1ZXbFJTemMwTkhSNU1FOUNlbVUwVm1OWU1XeFlSREJHUWxSc2JYWlVNMmQxVkZwdWFVMURSR3RuU3pSV1l6ZGlNVmRaWW5FeVgwdFdVR2wyYlhGNGNEUlFibUpEZFVoNWNsWTNlR0pOUTBoSmFHOVhiMGhQTjFkWFNHVkpObEZWTmpjMk9XazBia2h6VERabU1GUTBVbFpEZFdnMlVWb3hTRFkxYWtKcFZsSnlOV0p5TFVsSVp4SVhiemRyT1ZwTVpqaEpYeTAwTW5KdlVHcDBTMkUyUVRnYUlrRlBMVEJ5YkRWR2RFOVNRblZoWjNCVGEwdE5kR0ZETlc1dlZWSlVVRXRHV1ZFIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNCIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTdGFydHVwIEpvYnMiLCJsaW5rIjoiaHR0cHM6Ly9zdGFydHVwLmpvYnMvdGVjaG5pY2FsLXN1cHBvcnQtZW5naW5lZXItbDUtZGF0YS1wbGF0Zm9ybS1iaWctZGF0YS1hbmFseXRpY3MtbmV0ZmxpeC00MjAzNjIyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Big Data Engineer",
            "company_name": "Kanini",
            "location": "  Dearing, KS   ",
            "via": "via Jooble",
            "description": "About Kanini\n\nKanini provides Agile Software Development, Cloud Computing, Data Science, and Location Intelligence services to public and private organizations. We have successfully served our clients in government, finance, transportation, utility, and software industries since 2003...\n\nWhy you should join\n\nWorking at Kanini is flexible and personal. We are a highly motivated, collaborative team experimenting with the latest technologies. We are committed to everyone having a healthy work/life balance, and we provide extensive mentorship and training resources to help you succeed.\n\nKanini is looking for a Big Data Engineer who has a deep experience in Data Engineering, AWS, Python, Data Lakes.\n\nRequired Skills\n\u2022 At least 10 years software development experience\n\u2022 At least 5 years leading at least one Scrum team of data engineers building data-intensive products with a modern tech stack.\n\u2022 Significant experience with big data ETL pipeline development with Spark, Hive, and related technologies\n\u2022 Significant experience with a general-purpose programming language such as Python, Scala, or Java\n\u2022 Experience with Spark framework and related tools (PySpark, Scala, SparkR, Spark SQL, Spark UI)\n\u2022 Experience with Hadoop ecosystem using HDFS, ADLS Gen2, or AWS S3\n\u2022 Experience with data visualization development using Python, Tableau, or PowerBI\n\u2022 Experience with Azure, AWS or GCP\n\u2022 Solid understanding of performance tuning concepts for relational and distributed database systems\n\u2022 Familiarity with distributed programming, big data concepts, and cloud computing\n\nEducation Qualifications\n\nBachelor\u2019s degree in computer science/Engineering or Technology related field or possess equivalent work experience.\n\nPreferred Qualifications\n\u2022 Cloud certifications from Azure, AWS or GCP\n\u2022 Big data, data engineering or data science certifications from recognized vendors such as Databricks & Cloudera\n\nKanini Software Solutions, Inc. does not discriminate in employment matters based on race, gender, religion, age, national origin, citizenship, veteran status, family status, disability status, or any other protected class. We support workplace diversity. If you have a disability, please let us know if there is anything we can do to improve the interview process for you; we\u2019re happy to accommodate.\n\nKanini Software Solutions, Inc., 25 Century Blvd., Ste. 602, Nashville, TN 37214\n\u2022 Dice Id: 10125806\n\u2022 Position Id: 7854032\n\u2022 Posted 13 hours ago",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "At least 10 years software development experience",
                        "At least 5 years leading at least one Scrum team of data engineers building data-intensive products with a modern tech stack",
                        "Significant experience with big data ETL pipeline development with Spark, Hive, and related technologies",
                        "Significant experience with a general-purpose programming language such as Python, Scala, or Java",
                        "Experience with Spark framework and related tools (PySpark, Scala, SparkR, Spark SQL, Spark UI)",
                        "Experience with Hadoop ecosystem using HDFS, ADLS Gen2, or AWS S3",
                        "Experience with data visualization development using Python, Tableau, or PowerBI",
                        "Experience with Azure, AWS or GCP",
                        "Solid understanding of performance tuning concepts for relational and distributed database systems",
                        "Familiarity with distributed programming, big data concepts, and cloud computing",
                        "Bachelor\u2019s degree in computer science/Engineering or Technology related field or possess equivalent work experience"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Kanini&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIjgs",
                    "text": "See web results for Kanini"
                }
            ],
            "extensions": [
                "4 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "4 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBFbmdpbmVlciIsImh0aWRvY2lkIjoiTFZxV3psQmpkNHNBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WVzVwZEdWa0lGTjBZWFJsY3ciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXVJQkNxSUJRVVZ6TjJwT1VUaElhV2hYYW5SV0xVSk9kWGhCV1ROcFJHbFJkRGhWVW5WNFdXMWFibXRxVURWaFlUZE1iR0ZxUW05VlpWZEllbXN6Y25KUFQxRnpVakYzV2tzM01TMTNTakZUYjIxTU9GSktSVnAzWHpod2RUVTRaMUZCWlZsMU1URkdVRVkzZHpKVmJIaFZkMk5qVFUxM1EzTjNTR2xhZGxGeVlUVTJNbk5hYzJodU0zSTVZbnBXUWtKV1JrOXdMVmw2ZDB0RlUwNVNTRzVNY25FdFdtOTNFaGR2TjJzNVdreG1PRWxmTFRReWNtOVFhblJMWVRaQk9Cb2lRVTh0TUhKc05scHlhVGhvUVVKd00yZDVaRlF4VDNkTFMxQjFlRlYwYXpOblVRIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNiIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBkaXJlY3RseSBvbiBKb29ibGUiLCJsaW5rIjoiaHR0cHM6Ly9qb29ibGUub3JnL2pkcC8yNTkwMDI2NTE5Njg3NDU0NDEyL0JpZy1EYXRhLUVuZ2luZWVyLURlYXJpbmclMkMtS1M/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Big Data Architect",
            "company_name": "Open Systems Technologies",
            "location": "  New York, NY   ",
            "via": "via SmartRecruiters Job Search",
            "description": "Company Description\n\nJob Description...\n\nOur vision is twofold: First, to architect a reliable and scalable data platform. Second, to provision standardized interfaces to query and support analytics for our large security related data sets that are transparent, efficient and easy to access by our varied applications. YThis is a unique opportunity to join a talented group of engineers and data scientists in start-up like environment, using cutting-edge technologies on a greenfield project.\n\nYour responsibilities will include:\n\nArchitecting and building and implementing a data platform over Big Data technologies.\n\nLeading innovation by exploring, investigating, recommending, benchmarking and implementing data-centric technologies for the platform.\n\nBeing the technical architect and point person for the data platform\n\nCollaborating with application engineering teams and providing platform support for applications in a very agile environment.\n\nBig Data Experience Required:\n\nPassion and interest for all things distributed - file systems, databases and computational frameworks.\n\nHands on programming and development experience; excellent problem solving skills; proven technical leadership and communication skills\n\nHaving a solid track record building large scale, fault-tolerant systems over the whole lifecycle of the project - you have spent significant time and effort observing large-scale systems in production and learning from it.\n\nStrong understanding of how the various technical pieces fit together: you can explain why you made architectural/design decisions and chose certain tools/products.\n\nHaving made active contributions to open source projects like Apache Hadoop or Cassandra.\n\nExperience in large scale Stream processing frameworks such as Storm, Streambase and S4 is a strong plus.\n\nExperience in analytic frameworks such as Impala, Phoenix (for HBase), Berkeley Analytics stack (Spark/Shark) and Pandas/NumPy is a strong plus.\n\nPrior experience with large scale distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, Vertica) is a plus.\n\nKnowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2/S3/EMR, RackSpace Cloud, OpenStack) is a plus.\n\nTechnical Stack Required:\n\n5+ years of programming experience (Java and Python on Linux)\n\n3+ years of hands-on experience with key-value store technologies such as HBase and/or Cassandra.\n\n2+ years of experience with the Hadoop stack - MapReduce, Pig, Oozie, Scribe/Flume etc.\n\n2+ years of hands-on experience doing production troubleshooting and performance tuning of the Hadoop stack.\n\nDesirable Technical Skills:\n\nExperience in large scale Stream processing frameworks such as Storm, Streambase and S4 is a strong plus.\n\nExperience in analytic frameworks such as Impala, Phoenix (for HBase), Berkeley Analytics stack (Spark/Shark) and Pandas/NumPy is a strong plus.\n\nPrior experience with large scale distributed RDBMS (Teradata, Netezza, Greenplum, Aster Data, Vertica) is a plus.\n\nKnowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2/S3/EMR, RackSpace Cloud, OpenStack) is a plus.\n\nAdditional Information\n\nAll your information will be kept confidential according to EEO guidelines",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Passion and interest for all things distributed - file systems, databases and computational frameworks",
                        "Hands on programming and development experience; excellent problem solving skills; proven technical leadership and communication skills",
                        "Having a solid track record building large scale, fault-tolerant systems over the whole lifecycle of the project - you have spent significant time and effort observing large-scale systems in production and learning from it",
                        "Strong understanding of how the various technical pieces fit together: you can explain why you made architectural/design decisions and chose certain tools/products",
                        "Having made active contributions to open source projects like Apache Hadoop or Cassandra",
                        "Experience in large scale Stream processing frameworks such as Storm, Streambase and S4 is a strong plus",
                        "Experience in analytic frameworks such as Impala, Phoenix (for HBase), Berkeley Analytics stack (Spark/Shark) and Pandas/NumPy is a strong plus",
                        "5+ years of programming experience (Java and Python on Linux)",
                        "3+ years of hands-on experience with key-value store technologies such as HBase and/or Cassandra",
                        "2+ years of experience with the Hadoop stack - MapReduce, Pig, Oozie, Scribe/Flume etc",
                        "2+ years of hands-on experience doing production troubleshooting and performance tuning of the Hadoop stack"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Architecting and building and implementing a data platform over Big Data technologies",
                        "Leading innovation by exploring, investigating, recommending, benchmarking and implementing data-centric technologies for the platform",
                        "Being the technical architect and point person for the data platform",
                        "Collaborating with application engineering teams and providing platform support for applications in a very agile environment"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Open+Systems+Technologies&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIzgs",
                    "text": "See web results for Open Systems Technologies"
                }
            ],
            "extensions": [
                "Full-time",
                "No degree mentioned"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJCaWcgRGF0YSBBcmNoaXRlY3QiLCJodGlkb2NpZCI6Im02TExOTk5QNlh3QUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVvd0NDc3dCUVVWek4ycE9VbVJKTlZoa01Va3hUQzFzUjBaa09ESklWMlozZFdZNWIyaEtjMVpITTJkR1QydERVMjFoYWpGSFRqbDZUa1Y2UjFGdGJIRk5NVlV5WVhCS2NpMWFaRjlNWlVabVNXVk9WR3RIYVZjdFoxSkRMVXQwTVMwMk5HZDFXRUZHVWpWT1FteHljRGhOUldOdWJqbE9RMFJVUVVkWllXaFpVbkI2VWxsRVoyRnNUREl0U21neVJuRkVRVVo1V0VsRWFESlRjMFZaVkhFeVlXUmxWVkZwU3prM1VqVkNNVWRHZVhoTFMwazJhVFprU2pGRVFtUkpSVFF5UjJaT01WcE9OMmhqYjBJelpUbFNFaGR2TjJzNVdreG1PRWxmTFRReWNtOVFhblJMWVRaQk9Cb2lRVTh0TUhKc05sOVNaVGwwTlZkV1NWSnFTR0Y0VUY5NlFrcG1ka1pUTm5oM1p3IiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBTbWFydFJlY3J1aXRlcnMgSm9iIFNlYXJjaCIsImxpbmsiOiJodHRwczovL2pvYnMuc21hcnRyZWNydWl0ZXJzLmNvbS9PcGVuU3lzdGVtc1RlY2hub2xvZ2llcy84MTQ0MDAxNi1iaWctZGF0YS1hcmNoaXRlY3Q/dXRtX2NhbXBhaWduPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX3NvdXJjZT1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9tZWRpdW09b3JnYW5pYyJ9fQ=="
        },
        {
            "title": "Cloud Design Engineer",
            "company_name": "Castaway Research",
            "location": "  Annapolis Junction, MD   ",
            "via": "via Castaway Research",
            "description": "We are an extraordinary bunch of engineers who explore with creative technology and applied research. We love to craft solutions on the giant workbench of computer tech, and this propels us to be recognized for our hands-on keyboard critical path deliveries. We develop software and solve complex problems using technology.\n\nCastaway Research was founded by a creative engineer. We do natural... language processing, machine learning, mobile dev, data science, and exotic data structures. To our partners and customers, we provide general software, systems engineering, radio frequency, big data engineering, mobile development and test engineering.\n\nDescription:\n\nThe Cloud Design Engineer develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements. Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System. Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies. Cloud Designer implements Graphical Web-Based User Interface with usability, security, and performance in mind. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse.\n\nRequirements:\n\nA current Top-Secret/SCI with polygraph security clearance is required.\n\n1. Eight (8) years software engineering experience in programs and contracts of similar scope, type, and complexity are required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing. Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree.\n\n2. Bachelors degree in Computer Science or related discipline from an accredited college or university is required. Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience. Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\n3. The following Cloud related experiences are required:\n\n4. a. Two (2) year of Web-Based applications that retrieves/stores data in a Cloud Data System\n\n5. b. Two (2) year of building applications that comply with modern Web 2.0 standards\n\n6. c. Two (2) years of Cloud and/or Distributed Computing Information Retrieval (IR)\n\n7. d. One (1) year working with data stored in Cloud Big Table\n\n8. e. One (1) year of analyzing data stored in Cloud Distributed File System\n\n9. Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing\n\n10. Experience in Information Assurance - Securing User Interfaces based on Cloud and Distributed applications that contain disparate data sources and classifications through industry standard techniques such as Firewalls, PKI Certificate, and Server Authentication with experience in Corporate authentication service(s)\n\n11. Experience in Information Technology:\n\n12. a. Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services\n\n13. b. Interfacing with Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - Spring MVC, J2EE, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies\n\n14. c. Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\n15. d. AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy\n\n16. e. Aspect Oriented Design and Development\n\n17. f. Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications\n\n18. Experience in SIGINT:\n\n19. a. Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)\n\n20. b. Geolocation, emitter identification, and signal applications\n\n21. c. Joint program collection platforms and dataflow architectures; signals characterization analysis\n\n22. Experience with CentOS, Linux/RedHat; Configuration management tools such as Subversion, ClearQuest, or Razor\n\nOptional Skills:\n\n1. Provides in-depth knowledge of Information Retrieval; assisting the software development team in designing, developing and testing Cloud Information Retrieval\n\n2. Propose new ways of analyzing data stored in Cloud Big Table\n\n3. Propose new ways of analyzing data stored in Cloud Distributed File System\n\n4. Oversees one or more software development tasks and ensures the work is completed in accordance with the constraints of the software development process being used on any particular project\n\n5. Ensure quality control of all developed and modified software\n\n6. Make recommendations for improving documentation and software development process standards\n\nWorking at Castaway Research:\n\u2022 We offer fun, lasting, highly compensated positions in our industry and develop your career.\n\u2022 Company-paid life, short and long-term disability.\n\u2022 401k plan with a roth or traditional option.\n\u2022 Work time is flexible over the month. Time off during the year.\n\u2022 We have telework options.\n\u2022 CareFirst BlueCross medical benefits, dental and vision.\n\u2022 Direct access to the owner",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "A current Top-Secret/SCI with polygraph security clearance is required",
                        "Eight (8) years software engineering experience in programs and contracts of similar scope, type, and complexity are required; two (2) years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree",
                        "Bachelors degree in Computer Science or related discipline from an accredited college or university is required",
                        "Master in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Two (2) year of Web-Based applications that retrieves/stores data in a Cloud Data System",
                        "Two (2) year of building applications that comply with modern Web 2.0 standards",
                        "c. Two (2) years of Cloud and/or Distributed Computing Information Retrieval (IR)",
                        "One (1) year of analyzing data stored in Cloud Distributed File System",
                        "Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "b",
                        "d. AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy",
                        "e",
                        "f",
                        "Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications",
                        "Experience with at least one SIGINT collection discipline areas (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)",
                        "Experience with CentOS, Linux/RedHat; Configuration management tools such as Subversion, ClearQuest, or Razor",
                        "Provides in-depth knowledge of Information Retrieval; assisting the software development team in designing, developing and testing Cloud Information Retrieval",
                        "Propose new ways of analyzing data stored in Cloud Big Table",
                        "Propose new ways of analyzing data stored in Cloud Distributed File System",
                        "Oversees one or more software development tasks and ensures the work is completed in accordance with the constraints of the software development process being used on any particular project",
                        "Ensure quality control of all developed and modified software",
                        "Make recommendations for improving documentation and software development process standards"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "The Cloud Design Engineer develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System",
                        "Provides expertise in Cloud Technologies, Distributed Computing and how to best display data produced by these technologies",
                        "Cloud Designer implements Graphical Web-Based User Interface with usability, security, and performance in mind",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse",
                        "Experience in SIGINT:"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "We offer fun, lasting, highly compensated positions in our industry and develop your career",
                        "Company-paid life, short and long-term disability",
                        "401k plan with a roth or traditional option",
                        "Work time is flexible over the month",
                        "Time off during the year",
                        "We have telework options",
                        "CareFirst BlueCross medical benefits, dental and vision",
                        "Direct access to the owner"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Castaway+Research&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIkQw",
                    "text": "See web results for Castaway Research"
                }
            ],
            "extensions": [
                "Full-time",
                "Health insurance",
                "Dental insurance"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBEZXNpZ24gRW5naW5lZXIiLCJodGlkb2NpZCI6ImR1ZEtLdkxicHpzQUFBQUFBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lOVlc1cGRHVmtJRk4wWVhSbGN3IiwiZ2wiOiJ1cyIsImhsIjoiZW4iLCJmYyI6IkVxSUNDdUlCUVVWek4ycE9VVWRCYVVKYWVsZHljMVY1ZVhGeFVVUndTVmhqYmpKa1lUVTJRbmRUV1hsRlZVbHRPRTFpV1hkZmJWcEdZa2t6YkdGcE9YaGphbXRuWm5rNWFsWkNNV3hpWDJObVlsUXpiVEIyTUhObUxVNXdTVUZvT1V0SFVtVjJjVEZDTlhoNWRHdHlVVEpLTFZwMFoyWnNhbHBLZFV4Qk5sSmpPSFYzYWt4QmJrYzFjVjh4YmxCcFl6VldPRGhKY0dWV1FtVnVVVFprVjNsVU1rSnNXSGxrU1VoS1ZVcGtVM1pKVERjeVQxcHFTVzFoVmtsdlMyMXBNa1IyZURaVVdGOU5Va2c0YmpWVVNWRklObXAxTjBVMmNEZzFZVTlJUjFwWFZuUXpiMGhhWnhJWGJ6ZHJPVnBNWmpoSlh5MDBNbkp2VUdwMFMyRTJRVGdhSWtGUExUQnliRFpGTVZRMk5tZG1iMlZXZUZJMWIyaG9UbUYxVkVGZk9HcElTR2MiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY185IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIENhc3Rhd2F5IFJlc2VhcmNoIiwibGluayI6Imh0dHBzOi8vY2FyZWVycy5jYXN0YXdheXJlc2VhcmNoLmNvbS9jYXJlZXJzLzEwMDcxMi1HZW5lcmFsL2pvYnMvMTU1NDM1ODEtQ2xvdWQtRGVzaWduLUVuZ2luZWVyP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "65 Cloud Design Engineer 2 - Security Clearance Required",
            "company_name": "Arsiem Corporation",
            "location": "  Annapolis Junction, MD   ",
            "via": "via KLFY Jobs",
            "description": "About ARSIEM Corporation\n\nAt ARSIEM Corporation we are committed to fostering a proven and trusted partnership with our government clients. We provide support to multiple agencies across the United States Government. ARSIEM has an experienced workforce of qualified professionals committed to providing the best possible support...\n\nAs demand increases, ARSIEM continues to provide reliable and cutting-edge technical solutions at the best value to our clients. That means a career packed with opportunities to grow and the ability to have an impact on every client you work with.\n\nARSIEM is currently looking for a Cloud Design Engineer. The position will support one of our Government clients in Annapolis Junction, MD.\n\nResponsibilities\n\u2022 Develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements.\n\u2022 Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System.\n\u2022 Provides expertise in Cloud Technologies, Distributed Computing and how to display best data produced by these technologies.\n\u2022 Implements Graphical Web-Based User Interface with usability, security, and performance in mind. Reviews and tests software components to adhere to design requirements and document test results.\n\u2022 Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design, including hardware/software trade-offs and software reuse.\n\nMinimum Qualifications\n\u2022 Eight (8) years of software engineering experience in programs and contracts of similar scope, type, and complexity are required;\n\u2022 Two (2) years in programs utilizing Big-Data Cloud technologies and Distributed Computing.\n\u2022 Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree.\n\u2022 A Bachelor's degree in Computer Science or a related discipline from an accredited college or university is required.\n\u2022 A Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience.\n\u2022 Two (2) years of Web-Based applications that retrieve/store data in a Cloud Data System\n\u2022 Two (2) years of building applications that comply with modern Web 2.0 standards\n\u2022 Two (2) years of Cloud or Distributed Computing Information Retrieval (IR)\n\u2022 One (1) year working with data stored in Cloud Big Table\n\u2022 One (1) year of analyzing data stored in Cloud Distributed File System\n\u2022 Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing\n\u2022 Experience in Information Assurance - Securing User Interfaces based on Cloud and Distributed applications that contain disparate data sources and classifications through industry-standard techniques such as Firewalls, PKI Certificate, and Server Authentication with experience in Corporate authentication service(s)\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services\n\u2022 Interfacing with Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - Spring MVC, J2EE, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy\n\u2022 Aspect Oriented Design and Development\n\u2022 Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications\n\u2022 Experience with at least one SIGINT collection discipline area (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)\n\u2022 Geolocation, emitter identification, and signal applications\n\u2022 Joint program collection platforms and dataflow architectures; signals characterization analysis\n\u2022 Experience with CentOS, Linux/RedHat; Configuration management tools such as Subversion, ClearQuest, or Razor\n\nPreferred Qualifications\n\u2022 Provides in-depth knowledge of Information Retrieval; assisting the software development team in designing, developing and testing Cloud Information Retrieval\n\u2022 Propose new ways of analyzing data stored in Cloud Big Table\n\u2022 Propose new ways of analyzing data stored in Cloud Distributed File System\n\u2022 Oversees one or more software development tasks and ensures the work ifollowingordance with the constraints of the software development process being used on any particular project\n\u2022 Ensure quality control of all developed and modified software\n\u2022 Make recommendations for improving documentation and software development process standards\n\nClearance Requirement: This position requires an active TS/SCI with a polygraph. You must be a US Citizen for consideration.\n\nCandidate Referral: Do you know someone who would be GREAT at this role? If you do, ARSIEM has a way for you to earn a bonus through our referral program for persons presenting NEW (not in our resume database) candidates who are successfully placed on one of our projects. The bonus for this position is $10,000, and the referrer is eligible to receive the sum for any applicant we place within 12 months of referral. The bonus is paid after the referred employee reaches 6 months of employment.\n\nARSIEM is proud to be an Equal Opportunity and Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age, or any other federally protected class",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Eight (8) years of software engineering experience in programs and contracts of similar scope, type, and complexity are required;",
                        "Two (2) years in programs utilizing Big-Data Cloud technologies and Distributed Computing",
                        "Four (4) years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelor's degree",
                        "A Bachelor's degree in Computer Science or a related discipline from an accredited college or university is required",
                        "A Master's in Computer Science or related discipline from an accredited college or university may be substituted for two (2) years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one (1) year of Cloud experience",
                        "Two (2) years of Web-Based applications that retrieve/store data in a Cloud Data System",
                        "Two (2) years of building applications that comply with modern Web 2.0 standards",
                        "Two (2) years of Cloud or Distributed Computing Information Retrieval (IR)",
                        "One (1) year working with data stored in Cloud Big Table",
                        "One (1) year of analyzing data stored in Cloud Distributed File System",
                        "Experience in Computer Network Operations - Utility Computing, Network Management, Virtualizations (VMWare or VirtualBox), Cloud Computing",
                        "Experience in Information Assurance - Securing User Interfaces based on Cloud and Distributed applications that contain disparate data sources and classifications through industry-standard techniques such as Firewalls, PKI Certificate, and Server Authentication with experience in Corporate authentication service(s)",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services",
                        "Interfacing with Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - Spring MVC, J2EE, HDFS, HBase, JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies",
                        "Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB",
                        "AJAX Cross Browser support: HTML, CSS, JavaScript, JSP/Servlets, Groovy",
                        "Aspect Oriented Design and Development",
                        "Debugging and Profiling Cloud and Distributed Installations: Java Virtual Machine (JVM) memory management, Profiling Java Applications",
                        "Experience with at least one SIGINT collection discipline area (FORNSAT, CABLE, Terrestrial/Microwave, Overhead, ELINT)",
                        "Geolocation, emitter identification, and signal applications",
                        "Joint program collection platforms and dataflow architectures; signals characterization analysis",
                        "Experience with CentOS, Linux/RedHat; Configuration management tools such as Subversion, ClearQuest, or Razor",
                        "Clearance Requirement: This position requires an active TS/SCI with a polygraph",
                        "You must be a US Citizen for consideration"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Develops, maintains, and enhances complex and diverse Web-Based User Interfaces that interact with Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of designing, implementing and testing Web-Based User Interfaces that expose data for Big-Data Cloud Based infrastructure using Hadoop Eco-System",
                        "Provides expertise in Cloud Technologies, Distributed Computing and how to display best data produced by these technologies",
                        "Implements Graphical Web-Based User Interface with usability, security, and performance in mind",
                        "Reviews and tests software components to adhere to design requirements and document test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design, including hardware/software trade-offs and software reuse"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "The bonus for this position is $10,000, and the referrer is eligible to receive the sum for any applicant we place within 12 months of referral"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.arsiem.com/",
                    "text": "arsiem.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=Arsiem+Corporation&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAII0gw",
                    "text": "See web results for Arsiem Corporation"
                }
            ],
            "extensions": [
                "7 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "7 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiI2NSBDbG91ZCBEZXNpZ24gRW5naW5lZXIgMiAtIFNlY3VyaXR5IENsZWFyYW5jZSBSZXF1aXJlZCIsImh0aWRvY2lkIjoiSTNSOHBGbTJlRDRBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WVzVwZEdWa0lGTjBZWFJsY3ciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRXN3Q0Nvd0NRVVZ6TjJwT1VURjRWVVZ4WVZWVWFIcG1SMHhZZVRnelluZzNkV2xqVUVWYVUydDFOalF4UlVKS1RXODVkRmhvVmxONFZGWkVXbEZhT1dOaE1VZERkMkpEWjI1TmJYWlFUSFZOTW1WVVVWTnlOekZyVDBaWWVYVkZVR3RvWjI1d1ZIVjJiRTVEY1VVNWJXNTRRVzFaY21wRFJHVndUalU0U201dWJUQkVWbGt3VVZnNGEwZ3pTbXRaWVVOT2FtRkhSQzFFZWxRd2FtSktPQzF4WkhKVGVYVjRVbWcwUkVFdE9FNHpRVUZzUlZSYVpYWk1NRjl5ZVVad1EyWnVObFZCUTB0dE1XOWFNVkExY21oV1VYUkRZM1JLY3poRWEzVkRPVlIzY0cxTGVrTjFOMk5oWlMxMU9WbHphM1ZhZG1Nd2VVMW9NSGQzYWtGblozTkZaMkZmTldFMGVHcDNNMWxDYkhWVWRoSVhiemRyT1ZwTVpqaEpYeTAwTW5KdlVHcDBTMkUyUVRnYUlrRlBMVEJ5YkRkZmMxbGtlbUoxWVdnNVFWaGtRMGhEYkhnM1ExbFVlVEZsY0djIiwiZmN2IjoiMyIsImZjX2lkIjoiZmNfMTEiLCJhcHBseV9saW5rIjp7InRpdGxlIjoiQXBwbHkgb24gS0xGWSBKb2JzIiwibGluayI6Imh0dHBzOi8vam9icy5rbGZ5LmNvbS9qb2JzLzY1LWNsb3VkLWRlc2lnbi1lbmdpbmVlci0yLXNlY3VyaXR5LWNsZWFyYW5jZS1yZXF1aXJlZC1hbm5hcG9saXMtanVuY3Rpb24tbWFyeWxhbmQvOTc0MDQwMjc3LTIvP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Cloud Software Engineer Jobs",
            "company_name": "ManTech International",
            "location": "  Hanover, MD   ",
            "via": "via Clearance Jobs",
            "description": "Secure our Nation, Ignite your Future\n\nAre you interested in detecting internal and external threats? Do you have the ability to protect and defend the most coveted targets in the world to ensure the safety of information systems assets, and protect systems from intentional or inadvertent access or destruction? ManTech International Corporation is seeking individuals who are interested in joining... our team and helping protect our national security, while working on innovative projects that offer opportunities for advancement.\n\nManTech is currently looking for Cloud Software Engineers to join our team in the Ft. Meade, MD area. In this role, you will develop, maintain, and enhance complex and diverse Big-Data cloud systems based upon documented requirements and provide expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object-Oriented Design.\n\nResponsibilities include, but are not limited to:\n\u2022 Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports.\n\u2022 Utilizes software development and software design methodologies appropriate to the development environment.\n\u2022 Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the-shelf (COTS)/Government Offthe-shelf (GOTS).\n\nNOTE: Multiple levels of seniority are available dependent on qualifications/experience.\n\nMinimum Qualifications:\n\u2022 5 years of related experience. A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience.\n\u2022 4 years of experience developing software with high level languages such as Java, C, C++\n\u2022 3 years of experience in each of the following:\n\u2022 Developing software for Windows or UNIX/Linux/RH operating systems\n\u2022 Software integration and software testing, to include developing and implementing test plans and test scripts.\n\u2022 Ability to work with OpenSource (NoSQL) products that support highly distributed, massively parallel computation needs such as Hbase, CloudBase/Acumulo, Big Table, etc.\n\u2022 Demonstrated experience with the Map Reduce programming model and technologies such as Hadoop, Hive, Pig, etc\n\u2022 Demonstrated experience with the following\n\u2022 Hadoop Distributed File System (HDFS)\n\u2022 Serialization, such as JSON and/or BSON\n\u2022 Developing Restful services\n\u2022 Design and development of at least one Object Oriented system.\n\u2022 Developing solutions integrating and extending FOSS/COTS products.\n\u2022 Technical writing skills and shall have generated technical documents in support of a software development project\n\u2022 Source Code Management (e.g. Git, Stash, or Subversion, etc.)\n\u2022 Demonstrated experience or college level courses in at least 2 of the following:\n\u2022 Experience deploying applications in a cloud environment\n\u2022 Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)\n\u2022 Hadoop/Cloud Developer Certification\n\u2022 Experience designing and developing automated analytic software, techniques, and algorithms. Experience with taxonomy construction for analytic disciplines, knowledge areas and skills. Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines\n\u2022 Experience with linguistics (grammar, morphology, concepts\n\u2022 Experience developing and deploying analytics that discover and exploit social networks\n\u2022 Experience documenting ontologies, data models, schemas, formats, data element\n\nPreferred Qualifications:\n\u2022 8 years of related experience. A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience.\n\u2022 6 years of experience developing software with high level languages such as Java, C, C++\n\u2022 4 years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloubBase/Accumulo, Big Table, etc.\n\u2022 3 years of experience in each of the following:\n\u2022 Developing software for UNIX/Linux/RH operating systems and in software integration and software testing, to include developing and implementing test plans and test scripts\n\u2022 Software integration and software testing, to include developing and implementing test plans and test scripts.\n\u2022 2 years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc.\n\u2022 Demonstrated experience with Source Code Management (e.g. Git, Stash, or Subversion, etc.)\n\u2022 Demonstrated experience in at least 4 of the following:\n\u2022 Experience deploying applications in a cloud environment\n\u2022 Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)\n\u2022 Hadoop/Cloud Developer Certification\n\u2022 Experience designing and developing automated analytic software, techniques, and algorithms. Experience with taxonomy construction for analytic disciplines, knowledge areas and skills. Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines\n\u2022 Experience with linguistics (grammar, morphology, concepts\n\u2022 Experience developing and deploying analytics that discover and exploit social networks\n\u2022 Experience documenting ontologies, data models, schemas, formats, data element\n\nSecurity Clearance Requirements:\n\u2022 Current/Active TS/SCI with Polygraph.\n\nPhysical Requirements:\n\u2022 Must be able to remain in a stationary position 50%.\n\u2022 Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.\n\u2022 The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations.\n\nFor all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license.The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone.\n\nManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.\n\nIf you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.\n\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access http://www.mantech.com/careers/Pages/careers.aspx as a result of your disability. To request an accommodation please click careers@mantech.com and provide your name and contact information",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "5 years of related experience",
                        "A Bachelor's degree in computer science, engineering, mathematics or a related discipline may count as 4 years of related experience",
                        "4 years of experience developing software with high level languages such as Java, C, C++",
                        "3 years of experience in each of the following:",
                        "Ability to work with OpenSource (NoSQL) products that support highly distributed, massively parallel computation needs such as Hbase, CloudBase/Acumulo, Big Table, etc",
                        "Serialization, such as JSON and/or BSON",
                        "Design and development of at least one Object Oriented system",
                        "Demonstrated experience or college level courses in at least 2 of the following:",
                        "Experience deploying applications in a cloud environment",
                        "Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)",
                        "Hadoop/Cloud Developer Certification",
                        "Experience designing and developing automated analytic software, techniques, and algorithms",
                        "Experience with taxonomy construction for analytic disciplines, knowledge areas and skills",
                        "Experience developing and deploying: data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines",
                        "Experience developing and deploying analytics that discover and exploit social networks",
                        "4 years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloubBase/Accumulo, Big Table, etc",
                        "Developing software for UNIX/Linux/RH operating systems and in software integration and software testing, to include developing and implementing test plans and test scripts",
                        "2 years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc",
                        "Demonstrated experience with Source Code Management (e.g",
                        "Experience with linguistics (grammar, morphology, concepts",
                        "Current/Active TS/SCI with Polygraph",
                        "Must be able to remain in a stationary position 50%",
                        "Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer",
                        "For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "In this role, you will develop, maintain, and enhance complex and diverse Big-Data cloud systems based upon documented requirements and provide expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object-Oriented Design",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the-shelf (COTS)/Government Offthe-shelf (GOTS)",
                        "Developing Restful services",
                        "The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.mantech.com/",
                    "text": "mantech.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=ManTech+International&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIIlg0",
                    "text": "See web results for ManTech International"
                }
            ],
            "extensions": [
                "2 days ago",
                "Full-time"
            ],
            "detected_extensions": {
                "posted_at": "2 days ago",
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciBKb2JzIiwiaHRpZG9jaWQiOiJBNmxvcUF3eFdZSUFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFb3dDQ3N3QlFVVnpOMnBPVW01a2VITlRSMFoxVDE5M2FHNVBlV2RPVURGSVNXNXNibVZQUmxCVWJFTXpOR1ZoYTAwNWQyb3RkbWxmZWxWcVRsTlhSa2xGUVV4bmRWWjFUVGh3VldodFFVMUtZVWx0YzFjNWJGOW5PR2wzTVdjMFMyUjZiVGxKWWpKUlUxVnJRekpWVG5wRk1qbENaeTAyY205SkxYaFVlbFJVZDNKbVYwcEpUR1ZIZG5sWk5sWjRValkzUW0wNFJUZ3haR1JHWkZaQ1ducGxNMVZvVG5kS1FTMXBhR2t5YUZadVRFTXdkUzFMYVY5UU5uSlFNazgwTUU1NWVGSXpjRVp4T0ZaWlpWQnVUM0oyRWhkdk4yczVXa3htT0VsZkxUUXljbTlRYW5STFlUWkJPQm9pUVU4dE1ISnNOMHBPWkVGZlYyMUlSbWh4ZUhwSVExSkZTRGR4TjE5MWRtZGhRUSIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzEzIiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIENsZWFyYW5jZSBKb2JzIiwibGluayI6Imh0dHBzOi8vd3d3LmNsZWFyYW5jZWpvYnMuY29tL2pvYnMvNzEyNTQzNC9jbG91ZC1zb2Z0d2FyZS1lbmdpbmVlcj91dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        },
        {
            "title": "IC12CSWE3 - Sr. Level Cloud Software Engineer - Cleared",
            "company_name": "NiSUS Technologies Corporation",
            "location": "  Annapolis Junction, MD   ",
            "via": "via Monster",
            "description": "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data cloud systems. Provides expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object Oriented Design. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and... documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the- shelf (COTS).\n\nRequirements\nTS/SCI with poly required\n\u2022 Eight (8) years of general experience in software development/engineering, including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing, and problem diagnosis/resolution.\n\u2022 A bachelor\u2019s degree in computer science, engineering, mathematics or a related discipline may be substituted for four (4) years of general experience.\n\u2022 Shall have at least six (6) years of experience developing software with high level languages, such as Java, C, C++.\n\u2022 Shall have at least four (4) years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloudBase/Accumulo, Big Table, etc., as well as four (4) years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc.\n\u2022 Shall have demonstrated work experience with Serialization, such as JSON and/or BSON.\n\u2022 Shall have demonstrated work experience with developing restful services and Ruby on Rails framework.\n\u2022 Shall have at least three (3) years of experience developing software in UNIX/Linux (Red Hat versions 3-5+) operating systems.\n\u2022 Shall have demonstrated work experience in the design and development of at least one Object Oriented system.\n\u2022 Shall have demonstrated work experience developing solutions integrating and extending FOSS/COTS products.\n\u2022 Shall have at least three (3) years of experience in software integration and software testing, to include developing and implementing test plans and test scripts.\n\u2022 Shall have demonstrated technical writing skills and shall have generated technical documents in support of a software development project.\n\u2022 In addition, the candidate will have demonstrated experience, work or college level courses in at least four (4) of the desired characteristics.\n\u2022 Shall have demonstrated work experience with Source Code Management (e.g. Git, Stash, or Subversion, etc.).\n\u2022 * Experience deploying applications in a cloud environment\n\u2022 Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)\n\u2022 Hadoop/Cloud Developer Certification\n\u2022 Experience designing and developing automated analytic software, techniques, and algorithms.\n\u2022 Experience with taxonomy construction for analytic disciplines, knowledge areas and skills.\n\u2022 Experience developing and deploying data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines\n\u2022 Experience with linguistics (grammar, morphology, concepts\n\u2022 Experience developing and deploying analytics that utilize social networks\n\u2022 Experience documenting ontologies, data models, schemas, formats, data element\n\u2022 LDAP protocol configuration management and cluster performance management (e.g. Nagios)\n\nBenefits\n\u2022 Health & Life Insurance\n\u2022 Dental Insurance\n\u2022 Disability Insurance\n\u2022 401K Retirement Plan with Matching\n\u2022 Tuition Assistance\n\u2022 Vacation and Sick Leave\n\u2022 Hiring Bonuses\n\u2022 Referral Recruitment Program",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "TS/SCI with poly required",
                        "Eight (8) years of general experience in software development/engineering, including requirements analysis, software development, installation, integration, evaluation, enhancement, maintenance, testing, and problem diagnosis/resolution",
                        "A bachelor\u2019s degree in computer science, engineering, mathematics or a related discipline may be substituted for four (4) years of general experience",
                        "Shall have at least six (6) years of experience developing software with high level languages, such as Java, C, C++",
                        "Shall have at least four (4) years of experience with distributed scalable Big Data Store (NoSQL), such as HBase, CloudBase/Accumulo, Big Table, etc., as well as four (4) years of experience with the Map Reduce programming model, the Distributed File System (HDFS), and technologies such as Hadoop, Hive, Pig, etc",
                        "Shall have demonstrated work experience with Serialization, such as JSON and/or BSON",
                        "Shall have demonstrated work experience with developing restful services and Ruby on Rails framework",
                        "Shall have at least three (3) years of experience developing software in UNIX/Linux (Red Hat versions 3-5+) operating systems",
                        "Shall have demonstrated work experience in the design and development of at least one Object Oriented system",
                        "Shall have demonstrated work experience developing solutions integrating and extending FOSS/COTS products",
                        "Shall have at least three (3) years of experience in software integration and software testing, to include developing and implementing test plans and test scripts",
                        "Shall have demonstrated technical writing skills and shall have generated technical documents in support of a software development project",
                        "Shall have demonstrated work experience with Source Code Management (e.g",
                        "Git, Stash, or Subversion, etc.)",
                        "Experience deploying applications in a cloud environment",
                        "Understanding of Big-Data Cloud Scalability (Amazon, Google, Facebook)",
                        "Hadoop/Cloud Developer Certification",
                        "Experience designing and developing automated analytic software, techniques, and algorithms",
                        "Experience with taxonomy construction for analytic disciplines, knowledge areas and skills",
                        "Experience developing and deploying data driven analytics; event driven analytics; sets of analytics orchestrated through rules engines",
                        "Experience developing and deploying analytics that utilize social networks",
                        "Experience documenting ontologies, data models, schemas, formats, data element"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Provides expertise in cloud computing, Eco-System, including implementing applications, distributed Computing, Information Retrieval (IR), and Object Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off the- shelf (COTS)"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Health & Life Insurance",
                        "Dental Insurance",
                        "Disability Insurance",
                        "401K Retirement Plan with Matching",
                        "Tuition Assistance",
                        "Vacation and Sick Leave",
                        "Hiring Bonuses",
                        "Referral Recruitment Program"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=NiSUS+Technologies+Corporation&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAII2g0",
                    "text": "See web results for NiSUS Technologies Corporation"
                }
            ],
            "extensions": [
                "Full-time",
                "Health insurance",
                "Dental insurance",
                "Paid time off"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJJQzEyQ1NXRTMgLSBTci4gTGV2ZWwgQ2xvdWQgU29mdHdhcmUgRW5naW5lZXIgLSBDbGVhcmVkIiwiaHRpZG9jaWQiOiJ2M1VpVWJ5eUVLNEFBQUFBQUFBQUFBPT0iLCJ1dWxlIjoidytDQUlRSUNJTlZXNXBkR1ZrSUZOMFlYUmxjdyIsImdsIjoidXMiLCJobCI6ImVuIiwiZmMiOiJFdUlDQ3FJQ1FVVnpOMnBPVXpSRE5uSTVhWEUzZGtoMVdVNVZSVEppUjJZeFgwczNkbGxDWkU4MmQzaFhRM0pXZUV0U1ZEUk1UVTlXV2taSlpuZEtVbEpPY0ROTldqRjFXVkZOT1VabU0yRTJlWE5GVUc1R2EyRm9UekJRZGxWdU9WVmpRVTlmYURsZk5UWnpkbkZWUXpKTGVGUTJaVXBzUmpKYVZFUlpZM0ZYYmxCak5YcFVaVk56VVhaa1RUTlVjRmR1YUUxT1dtMWlNbU5oY0hCYWJVTnlkV1JpYXpRMFFtOVdTMW96U1ZsclozbEdXa0ZyYWxCQlpHUXlNbVZSYVdwU05rSkhhblJ1TkMwNE1tdHlRVzlKWTJaTGVXNTNkRTVCU2taeGJsOWpaRzgwWjBjMGFHeEVPSGxDV0VkWk5HZDBNblpGV21wSmRXNVhkV050VFcxa1FWOU9aSGN0ZFZKcVYwRm1MVkI2ZEVkMk1WSllRVVYyWkZoellWVldkMlZ6WkU5aVkxRVNGMjgzYXpsYVRHWTRTVjh0TkRKeWIxQnFkRXRoTmtFNEdpSkJUeTB3Y213MWFrcEJjVFJpYkdwMFdVUkNiR1YwUlRsMllreHNRek50YUhGbiIsImZjdiI6IjMiLCJmY19pZCI6ImZjXzE1IiwiYXBwbHlfbGluayI6eyJ0aXRsZSI6IkFwcGx5IG9uIE1vbnN0ZXIiLCJsaW5rIjoiaHR0cHM6Ly93d3cubW9uc3Rlci5jb20vam9iLW9wZW5pbmdzL2ljMTJjc3dlMy1zci1sZXZlbC1jbG91ZC1zb2Z0d2FyZS1lbmdpbmVlci1jbGVhcmVkLWFubmFwb2xpcy1qdW5jdGlvbi1tZC0tNjg2MmRmZDYtYWJkNy00NTMxLWFjNmUtNzZlZTAyYzdjYjFlP3V0bV9jYW1wYWlnbj1nb29nbGVfam9ic19hcHBseVx1MDAyNnV0bV9zb3VyY2U9Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fbWVkaXVtPW9yZ2FuaWMifX0="
        },
        {
            "title": "Cloud Software Engineer -TS/SCI with Poly",
            "company_name": "CACI",
            "location": "  Fort Meade, MD   ",
            "via": "via Indeed",
            "description": "Cloud Software Engineer -TS/SCI with Poly\n\nJob Category: Engineering...\n\nTime Type: Full time\n\nMinimum Clearance Required to Start: TS/SCI with Polygraph\n\nEmployee Type: Regular\n\nPercentage of Travel Required: Up to 10%\n\nType of Travel: Local\n\nWhat You\u2019ll Get to Do:\n\nBy applying for this requisition, you will get to support the U.S. government in their cryptology mission that encompasses both signals intelligence (SIGINT) insights and cybersecurity products and services and enables computer network operations to gain a decisive advantage for the nation and our allies. You will become part of a diverse team of professionals working to prevent foreign adversaries from gaining access to classified national security information, support our military members with critical information, and protect our cybersecurity infrastructure and communication systems. Come work and support our team in Annapolis Junction, Maryland.\n\nMore About the Role:\n\nThe Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements. Directly contributes to all stages of back-end processing, analyzing, and indexing. Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object Oriented Design. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components.\n\nYou\u2019ll Bring These Qualifications:\n\u2022 Eight years experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing.\n\u2022 Bachelors degree in Computer Science or related discipline from an accredited college or university is required. Four years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree. Master in Computer Science or related discipline from an accredited college or university may be substituted for two years of experience.\n\u2022 Cloudera Certified Hadoop Developer certification may be substituted for one year of Cloud experience.\n\nThese Qualifications Would be Nice to Have:\n\u2022 The following Cloud related experiences are required:\n\u2022 Two years of Cloud and Distributed Computing Information Retrieval (IR).\n\u2022 One year of experience with implementing code that interacts with implementation of Cloud Big Table.\n\u2022 One year of experience with implementing code that interacts with implementation of Cloud Distributed File System.\n\u2022 One year of experience with implementing complex MapReduce analytics.\n\u2022 One year of experience with implementing code that interacts with Cloud Distributed Coordination Frameworks.\n\u2022 Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing 2. Multi Node Management and Installation: Management and installation of Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies.\n\u2022 Experience with Information Assurance: Securing Cloud Based and Distributed applications through industry standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)\n\u2022 Experience with Information Technology:\n\u2022 Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services.\n\u2022 Cloud and Distributed Computing Technologies: at least one or a combination of several of the following areas - YARN, J2EE, MapReduce, Zookeeper, HDFS, HBase , JMS, Concurrent Programming, Multi-Node implementation/installation and other applicable technologies.\n\u2022 Cloud and Distributed Computing Information Retrieval: at least one or a combination of several of the following areas - HDFS, HBASE, Apache Lucene, Apache Solr, MongoDB\n\u2022 Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies\n\u2022 Aspect Oriented Design and Development\n\nWhat We Can Offer You:\n\u2022 We\u2019ve been named a Best Place to Work by the Washington Post.\n\u2022 Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.\n\u2022 We offer competitive benefits and learning and development opportunities.\n\u2022 We are mission-oriented and ever vigilant in aligning our solutions with the nation\u2019s highest priorities.\n\u2022 For over 60 years, the principles of CACI\u2019s unique, character-based culture have been the driving force behind our success.\n\nCompany Overview: At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.\n\nAs a federal contractor, CACI is subject to any federal vaccine mandates or other customer vaccination requirements. All new hires are required to report their vaccination status",
            "job_highlights": [
                {
                    "title": "Qualifications",
                    "items": [
                        "Minimum Clearance Required to Start: TS/SCI with Polygraph",
                        "Eight years experience software engineering experience in programs and contracts of similar scope, type, and complexity is required; two years of which must be in programs utilizing Big-Data Cloud technologies and/or Distributed Computing",
                        "Bachelors degree in Computer Science or related discipline from an accredited college or university is required",
                        "Four years of cloud software engineering experience on projects with similar Big-Data systems may be substituted for a bachelors degree",
                        "Master in Computer Science or related discipline from an accredited college or university may be substituted for two years of experience",
                        "Cloudera Certified Hadoop Developer certification may be substituted for one year of Cloud experience",
                        "The following Cloud related experiences are required:",
                        "Two years of Cloud and Distributed Computing Information Retrieval (IR)",
                        "One year of experience with implementing code that interacts with implementation of Cloud Distributed File System",
                        "One year of experience with implementing complex MapReduce analytics",
                        "Experience with Computer Network Operations: Utility Computing, Network Management, Virtualization (VMWare or VirtualBox), Cloud Computing 2",
                        "Multi Node Management and Installation: Management and installation of Cloud and Distributed Computing on multiple nodes, Python, CFEngine, Bash, Ruby or related technologies",
                        "Experience with Information Assurance: Securing Cloud Based and Distributed applications through industry standard techniques such as Firewalls, PKI Certificate and Server Authentication with experience in Corporate authentication service(s)",
                        "Object Oriented Design and Programming, Java, Eclipse or similar development environment, MAVEN, RESTful web services"
                    ]
                },
                {
                    "title": "Responsibilities",
                    "items": [
                        "Percentage of Travel Required: Up to 10%",
                        "The Cloud Software Engineer develops, maintains, and enhances complex and diverse Big-Data Cloud systems based upon documented requirements",
                        "Directly contributes to all stages of back-end processing, analyzing, and indexing",
                        "Provides expertise in Cloud Computing, Hadoop Eco-System including implementing Java applications, Distributed Computing, Information Retrieval (IR), and Object Oriented Design",
                        "Works individually or as part of a team",
                        "Reviews and tests software components for adherence to the design requirements and documents test results",
                        "Resolves software problem reports",
                        "Utilizes software development and software design methodologies appropriate to the development environment",
                        "Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components",
                        "Ingesting, Parsing and Analysis of Disparate Data-sources and formats: XML, JSON, CSV, Binary Formats, Sequence or Map Files, Avro and related technologies",
                        "Aspect Oriented Design and Development"
                    ]
                },
                {
                    "title": "Benefits",
                    "items": [
                        "Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives",
                        "We offer competitive benefits and learning and development opportunities"
                    ]
                }
            ],
            "related_links": [
                {
                    "link": "http://www.caci.com/",
                    "text": "caci.com"
                },
                {
                    "link": "https://www.google.com/search?gl=us&hl=en&q=CACI&sa=X&ved=0ahUKEwj32YHP7bH-AhV_nFYBHQ6pBv04FBCYkAIInQ4",
                    "text": "See web results for CACI"
                }
            ],
            "extensions": [
                "Full-time"
            ],
            "detected_extensions": {
                "schedule_type": "Full-time"
            },
            "job_id": "eyJqb2JfdGl0bGUiOiJDbG91ZCBTb2Z0d2FyZSBFbmdpbmVlciAtVFMvU0NJIHdpdGggUG9seSIsImh0aWRvY2lkIjoiZ3lxcXBWbEVLcUlBQUFBQUFBQUFBQT09IiwidXVsZSI6IncrQ0FJUUlDSU5WVzVwZEdWa0lGTjBZWFJsY3ciLCJnbCI6InVzIiwiaGwiOiJlbiIsImZjIjoiRW93Q0Nzd0JRVVZ6TjJwT1UycDBYMGhLUzB3d2JWTTJTM0l0ZDNSNlV6ZHBWRzk0T0cxV1gyMHhjUzAzWm5GdlMydE5OV3BqU0daa2FsaHJjemh5V2xsWVVtbzVPR1ZVUkUweGJ6bHNaV3BHVFRGc1NrbzVjbTh0VG5ZeE9FVmpiM2RmZW1aSVJtbGFRMGs0VjJkR1JHaEVlbTE0UW1GNU0zWTVabGREWlVwemNHeE5iVmQwY25OSk5HaEhRM2wxYzJ0MmJGSTJkelZRU1VORk1HeFVPV05qT1dSUk9ETnNMVGhITlRCS2JsRmhRelpPWWtWd2EzbEdSelpFYjIxb2JUSXpMVXBqWlVoUWJHMVFjbGRaYVZSbEVoZHZOMnM1V2t4bU9FbGZMVFF5Y205UWFuUkxZVFpCT0JvaVFVOHRNSEpzTlMwd2VUVk5kbkpLUkdGVU4xODBVbVIxVkZOdlVVRkhlREoxVVEiLCJmY3YiOiIzIiwiZmNfaWQiOiJmY18xNyIsImFwcGx5X2xpbmsiOnsidGl0bGUiOiJBcHBseSBvbiBJbmRlZWQiLCJsaW5rIjoiaHR0cHM6Ly93d3cuaW5kZWVkLmNvbS92aWV3am9iP2prPTE1MjA5MjFlN2Q4Njg0NDZcdTAwMjZ1dG1fY2FtcGFpZ249Z29vZ2xlX2pvYnNfYXBwbHlcdTAwMjZ1dG1fc291cmNlPWdvb2dsZV9qb2JzX2FwcGx5XHUwMDI2dXRtX21lZGl1bT1vcmdhbmljIn19"
        }
    ],
    "chips": [
        {
            "type": "Title",
            "param": "job_family_1",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Software engineer",
                    "value": "software engineer"
                },
                {
                    "text": "Design engineer",
                    "value": "design engineer"
                },
                {
                    "text": "Data architect",
                    "value": "data architect"
                },
                {
                    "text": "Customer engineer",
                    "value": "customer engineer"
                },
                {
                    "text": "Support engineer",
                    "value": "support engineer"
                },
                {
                    "text": "Cloud architect",
                    "value": "cloud architect"
                },
                {
                    "text": "Data consultant",
                    "value": "data consultant"
                },
                {
                    "text": "Sales engineer",
                    "value": "sales engineer"
                },
                {
                    "text": "Senior",
                    "value": "senior"
                },
                {
                    "text": "Solutions architect",
                    "value": "solutions architect"
                },
                {
                    "text": "Analyst",
                    "value": "analyst"
                },
                {
                    "text": "Cloud consultant",
                    "value": "cloud consultant"
                },
                {
                    "text": "Cloud engineer",
                    "value": "cloud engineer"
                },
                {
                    "text": "Data engineer",
                    "value": "data engineer"
                },
                {
                    "text": "Engineering",
                    "value": "engineering"
                },
                {
                    "text": "Manager",
                    "value": "manager"
                },
                {
                    "text": "Solution manager",
                    "value": "solution manager"
                },
                {
                    "text": "Technical",
                    "value": "technical"
                }
            ]
        },
        {
            "type": "Location",
            "param": "city",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Annapolis Junction, MD",
                    "value": "zW-xYyLnt4mqAms5YL-SKQ=="
                },
                {
                    "text": "Annapolis, MD",
                    "value": "1S9ncGX2t4lLJ6jT_VT4Qw=="
                },
                {
                    "text": "Atlanta, GA",
                    "value": "jQmTaV0E9YgLYwuZL97-Zg=="
                },
                {
                    "text": "Baltimore, MD",
                    "value": "t4P01q4DyIlY5yNCqJZIBA=="
                },
                {
                    "text": "Salt Lake City, UT",
                    "value": "7THRiJQ9UofKMU1IoLdTWw=="
                },
                {
                    "text": "Washington, DC",
                    "value": "W-T2Wt7Gt4kqXYjUIkVSwg=="
                },
                {
                    "text": "Catonsville, MD",
                    "value": "TYwOyT0cyImNcyTcDrP1IQ=="
                },
                {
                    "text": "Herndon, VA",
                    "value": "Q6ZdDwY4tol9NWwctSKAkg=="
                },
                {
                    "text": "Palo Alto, CA",
                    "value": "ORy6nXuwj4DPdvU1UvUfDg=="
                },
                {
                    "text": "Reston, VA",
                    "value": "5WUWJkdAtomfrnGo6K_fYw=="
                },
                {
                    "text": "San Francisco, CA",
                    "value": "IQBpAG2ahYD_rXbwZxNQSg=="
                },
                {
                    "text": "Weehawken, NJ",
                    "value": "AdCFFTBYwomUmggtWZ9PJQ=="
                },
                {
                    "text": "Boston, MA",
                    "value": "GzE9DS1l44mg6GIBJL98eA=="
                },
                {
                    "text": "Chantilly, VA",
                    "value": "GXJnGVZBtomDrRZD_PBBQA=="
                },
                {
                    "text": "Charlotte, NC",
                    "value": "gRo4_MQfVIhk0UO_5lBGiA=="
                },
                {
                    "text": "Chicago, IL",
                    "value": "7cv00DwsDogAwMAJrabgrw=="
                },
                {
                    "text": "Columbia, MD",
                    "value": "UaBpY7Dft4ldY4e2Zb3W8A=="
                },
                {
                    "text": "Crownsville, MD",
                    "value": "tds0e1_wt4lD8Gl4tkPWrw=="
                },
                {
                    "text": "Dallas, TX",
                    "value": "S5dFe_cZTIaPZ0f2pJvsuQ=="
                },
                {
                    "text": "Dearing, KS",
                    "value": "OfJxMhSCt4eyx6-l5eqDwg=="
                },
                {
                    "text": "Edison, NJ",
                    "value": "maG-aH_Tw4nq1INvpsUr8g=="
                },
                {
                    "text": "Fort Meade, MD",
                    "value": "jdor14Tmt4l3A9bF4c3sbg=="
                },
                {
                    "text": "Hanover, MD",
                    "value": "CR8SmSTit4kd1ecDfu3Bcw=="
                },
                {
                    "text": "Laurel, MD",
                    "value": "0dxJ6BDdt4n8ks39Ll7NmA=="
                },
                {
                    "text": "Los Gatos, CA",
                    "value": "PwN3UzY0joCmjHSsAVNn7w=="
                },
                {
                    "text": "Moline, IL",
                    "value": "a0TjeKAw4ocnMg_Pp6fQLg=="
                },
                {
                    "text": "New York, NY",
                    "value": "Owg_06VPwoli_nfhBo8LyA=="
                },
                {
                    "text": "Ohio, IL",
                    "value": "4a34ENmeCYiVXj8uMgu1Jg=="
                },
                {
                    "text": "San Jose, CA",
                    "value": "9T_5iuTKj4B7cZ_KCoyduQ=="
                },
                {
                    "text": "San Mateo, CA",
                    "value": "RVWp72Cej4CnG8wt9PyO_Q=="
                },
                {
                    "text": "White Plains, NY",
                    "value": "2TWj4iKUwols_FsaEAQUVA=="
                },
                {
                    "text": "Wilmington, DE",
                    "value": "b69GXBgPx4kAjDB3UNoWhQ=="
                }
            ]
        },
        {
            "type": "Date posted",
            "param": "date_posted",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Past day",
                    "value": "today"
                },
                {
                    "text": "Past 3 days",
                    "value": "3days"
                },
                {
                    "text": "Past week",
                    "value": "week"
                },
                {
                    "text": "Past month",
                    "value": "month"
                }
            ]
        },
        {
            "type": "Requirements",
            "param": "requirements",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "No degree",
                    "value": "no_degree"
                },
                {
                    "text": "No experience",
                    "value": "no_experience"
                },
                {
                    "text": "Under 3 years of experience",
                    "value": "years3under"
                },
                {
                    "text": "3+ years of experience",
                    "value": "years3plus"
                }
            ]
        },
        {
            "type": "Type",
            "param": "employment_type",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Full-time",
                    "value": "FULLTIME"
                },
                {
                    "text": "Contractor",
                    "value": "CONTRACTOR"
                },
                {
                    "text": "Internship",
                    "value": "INTERN"
                },
                {
                    "text": "Part-time",
                    "value": "PARTTIME"
                }
            ]
        },
        {
            "type": "Company type",
            "param": "industry.id",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Computer Services",
                    "value": "/business/naics2007/5415"
                },
                {
                    "text": "Information",
                    "value": "/business/naics2007/51"
                },
                {
                    "text": "Consulting",
                    "value": "/business/naics2007/5416"
                },
                {
                    "text": "Health Care",
                    "value": "/business/naics2007/62"
                },
                {
                    "text": "Finance",
                    "value": "/business/naics2007/52"
                },
                {
                    "text": "Manufacturing",
                    "value": "/business/naics2007/31"
                },
                {
                    "text": "Rental",
                    "value": "/business/naics2007/532"
                }
            ]
        },
        {
            "type": "Employer",
            "param": "organization_mid",
            "options": [
                {
                    "text": "All"
                },
                {
                    "text": "Google",
                    "value": "/m/045c7b"
                },
                {
                    "text": "ARSIEM",
                    "value": "/g/11fy22b_1s"
                },
                {
                    "text": "Amazon Web Services, Inc.",
                    "value": "/m/0rznzt1"
                },
                {
                    "text": "Base-2 Solutions",
                    "value": "/g/11gxm4c0tt"
                },
                {
                    "text": "NiSUS Technologies Corporation",
                    "value": "/g/11g705zkln"
                },
                {
                    "text": "Amazon.com Services LLC",
                    "value": "/g/11f00sjtl5"
                },
                {
                    "text": "CACI",
                    "value": "/m/0310bt"
                },
                {
                    "text": "Elevance Health",
                    "value": "/m/04xtkp"
                },
                {
                    "text": "IntelliGenesis LLC",
                    "value": "/g/11c73hfqj8"
                },
                {
                    "text": "Raytheon Technologies",
                    "value": "/g/11c6qvm0kj"
                },
                {
                    "text": "Snowflake Computing",
                    "value": "/g/11b8krtt2g"
                },
                {
                    "text": "Avid Technology Professionals, LLC",
                    "value": "/g/11g9n060lk"
                },
                {
                    "text": "Booz Allen Hamilton",
                    "value": "/m/05jlg3"
                },
                {
                    "text": "BrainTrust Holdings",
                    "value": "/g/11fy267mw4"
                },
                {
                    "text": "Castaway Research",
                    "value": "/g/11jp54p9k7"
                },
                {
                    "text": "JPMorgan Chase",
                    "value": "/m/01hlwv"
                },
                {
                    "text": "Johnson Technology Systems Inc.",
                    "value": "/g/11f7p9xc6j"
                },
                {
                    "text": "Keylent",
                    "value": "/g/11rvbr_y2l"
                },
                {
                    "text": "ManTech International",
                    "value": "/m/03crmnd"
                },
                {
                    "text": "Netflix",
                    "value": "/m/017rf_"
                },
                {
                    "text": "Novetta",
                    "value": "/g/11g9m_jqt2"
                },
                {
                    "text": "Open Systems Technologies",
                    "value": "/g/11b7c7x3lx"
                },
                {
                    "text": "Orion Consortium",
                    "value": "/g/11g9mp3gx4"
                },
                {
                    "text": "Rakuten USA, Inc.",
                    "value": "/g/11f00sztwj"
                },
                {
                    "text": "Super Micro Computer",
                    "value": "/m/03p3m28"
                },
                {
                    "text": "Synechron Inc.",
                    "value": "/m/027hdqs"
                },
                {
                    "text": "The DarkStar Group",
                    "value": "/g/11fy1qp5kx"
                },
                {
                    "text": "Trigyn",
                    "value": "/m/0cp7t9v"
                },
                {
                    "text": "Triumph Tech",
                    "value": "/g/11ry5h_t46"
                },
                {
                    "text": "WayUp",
                    "value": "/g/11gfj67hvn"
                },
                {
                    "text": "Inforeliance",
                    "value": "/g/1dv3111b"
                }
            ]
        }
    ]
}
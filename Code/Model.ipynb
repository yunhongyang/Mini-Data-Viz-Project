{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation for Job by LSH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hi who is reiewing this page,\n",
    "#### This is the code for the model part of the project. The model is based on the LSH algorithm. Since my computers' have problems in rendering php files, I use this html file to display the model. If you wanna try, you can directly download and type \"keywords\" in title. I will also remind you in the following part. I would fix this problem in the future as soon as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impart Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datasketch import MinHash, MinHashLSHForest\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../2023-04-14-job-search/Clean_Data/combined_data_final.csv')\n",
    "\n",
    "# replace nan with empty string\n",
    "df['Responsibilities'] = df['Responsibilities'].fillna('')\n",
    "df['Benefits'] = df['Benefits'].fillna('')\n",
    "df['detected_extensions.schedule_type'] = df['detected_extensions.schedule_type'].fillna('')\n",
    "df['detected_extensions.work_from_home'] = df['detected_extensions.work_from_home'].fillna('')\n",
    "df['detected_extensions.posted_at'] = df['detected_extensions.posted_at'].fillna('')\n",
    "df['detected_extensions.salary'] = df['detected_extensions.salary'].fillna('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'\\s\\s+',' ',text)\n",
    "    text = text.strip()\n",
    "    tokens = text.lower()\n",
    "    tokens = tokens.split()\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MinHash Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data, perms):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    minhash = []\n",
    "    \n",
    "    for text in data['text']:\n",
    "        tokens = preprocess(text)\n",
    "        m = MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)\n",
    "        \n",
    "    forest = MinHashLSHForest(num_perm=perms)\n",
    "    \n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "        \n",
    "    forest.index()\n",
    "    \n",
    "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, database, perms, num_results, forest):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    tokens = preprocess(text)\n",
    "    m = MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "        \n",
    "    idx_array = np.array(forest.query(m, num_results))\n",
    "    if len(idx_array) == 0:\n",
    "        return None # if your query is empty, return none\n",
    "    \n",
    "    result = database.iloc[idx_array]\n",
    "    # select columns in the result\n",
    "    result = result[['title', 'company_name', 'location', 'via', 'description', \n",
    "                     'detected_extensions.schedule_type', 'detected_extensions.work_from_home',\n",
    "                     'detected_extensions.posted_at', 'detected_extensions.salary',\n",
    "                     'Qualifications', 'Responsibilities', 'Benefits'\n",
    "                     ]]\n",
    "    result.columns = ['Job Title', 'Company Name', 'Location', 'Platform', 'Description',\n",
    "                      'Schedule Type', 'Work from Home', 'Posted at', 'Salary',\n",
    "                      'Qualifications', 'Responsibilities', 'Benefits']\n",
    "    \n",
    "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommandation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Permutations\n",
    "permutations = 128\n",
    "\n",
    "#Number of Recommendations to return\n",
    "num_recommendations = 5\n",
    "\n",
    "# Keywords to search\n",
    "title = 'Data Analysis in DC'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model and Make Recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 7.447729110717773 seconds to build forest.\n",
      "It took 0.0031728744506835938 seconds to query forest.\n",
      "\n",
      " Top Recommendation(s) is(are) \n",
      "                                              Job Title Company Name  \\\n",
      "365                 Research Intern - Machine Learning    Microsoft   \n",
      "82   Online R, NLP, Natural Language Processing tea...    TeacherOn   \n",
      "178  Expert on Graph Neural Networks applied to Soc...       Upwork   \n",
      "374  Need an expert to consult on GNNs (graph neura...       Upwork   \n",
      "317  Reinforcement Learning Developer for Stock Tra...       Upwork   \n",
      "\n",
      "                   Location               Platform  \\\n",
      "365          Redmond, WA     via Microsoft Careers   \n",
      "82     Silver Spring, MD                via Jooble   \n",
      "178               Anywhere              via Upwork   \n",
      "374               Anywhere              via Upwork   \n",
      "317               Anywhere              via Upwork   \n",
      "\n",
      "                                           Description Schedule Type  \\\n",
      "365  Research Internships at Microsoft provide a dy...    Internship   \n",
      "82                 Homework assignment on NLP using R.     Part-time   \n",
      "178  We are looking for an expert in Graph Neural N...    Contractor   \n",
      "374  Hello,\\n\\nI am looking to explore GNNs (graph ...    Contractor   \n",
      "317  We are looking for an experienced reinforcemen...    Contractor   \n",
      "\n",
      "    Work from Home    Posted at         Salary  \\\n",
      "365                 24 days ago                  \n",
      "82                  12 days ago                  \n",
      "178           True   3 days ago  35â€“50 an hour   \n",
      "374           True  10 days ago                  \n",
      "317           True  28 days ago                  \n",
      "\n",
      "                                        Qualifications Responsibilities  \\\n",
      "365  Help develop machine learning-based bandwidth ...                    \n",
      "82                 Homework assignment on NLP using R.                    \n",
      "178  Develop and implement GNN models using PyG for...                    \n",
      "374  Perhaps a combination with reinforcement learn...                    \n",
      "317  Review and understand the existing RL model an...                    \n",
      "\n",
      "    Benefits  \n",
      "365           \n",
      "82            \n",
      "178           \n",
      "374           \n",
      "317           \n"
     ]
    }
   ],
   "source": [
    "db = df.copy()\n",
    "db['text'] = df['title'] + ' ' + df['company_name'] + ' ' + df['location'] + ' ' + df['description'] + ' ' + df['Qualifications'] + ' ' + df['Responsibilities'] + ' ' + df['Benefits']\n",
    "forest = get_forest(db, permutations)\n",
    "result = predict(title, db, permutations, num_recommendations, forest)\n",
    "print('\\n Top Recommendation(s) is(are) \\n', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anly503",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
